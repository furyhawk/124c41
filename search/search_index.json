{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-124c41","title":"Welcome to 124c41","text":"<p>type: short summary</p> <p>\u2502\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502</p> <p>\u2502\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2514\u2500\u2af8 Summary in present tense. Not capitalized.</p> <p>\u2502</p> <p>\u2514\u2500\u2af8 Commit Type: build|cicd|docs|feat|fix|node|refactor|test</p>"},{"location":"#agi","title":"AGI","text":"<ul> <li>Humanity achieve AGI.</li> <li>Basic computing skills lost.</li> <li>NSFW content filtered for everyone.</li> <li>1 Human decide to learn computing skills.</li> <li>NSFW content accessed.</li> </ul>"},{"location":"#home-server","title":"Home Server","text":"<ul> <li>Chat: Chat with AI, RAG chatbot. </li> <li>Bot: AI assistant using GROQ, llama3 70B, RAG and web search.</li> <li>Stock Analysis Assistant: AI assistant using GROQ and llama3.</li> <li>~~Redlib: Reddit libre.~~ (killed by bots)</li> <li>Blog</li> <li>Ghost: Ghost blog.</li> <li>Beyond All Information: analyse your Beyond All Reason games.</li> <li>CheatSheets: Collection of cheatsheets.</li> <li>Cookbook: Collection of tech recipes.</li> <li>~~Forum: Host your own forum.~~ (deprecated)</li> <li>Neural Network Playground: Understand neural network visually.</li> <li>Note: Notepad Online. Use cookie storage only.</li> <li>linx: Image pastebin.</li> <li>pastebin: text/file Pastebin.</li> <li>speedtest: Speedtest.</li> <li>Home server: Build for ARM64 platform using Docker swarm mode.</li> <li>Team Fight Tactics ML: Analyse the current meta.</li> </ul>"},{"location":"#team-fight-tactics-strategy-application","title":"Team Fight Tactics Strategy Application","text":"<p>http://tftchamp.duckdns.org:3000/</p>"},{"location":"#datasets","title":"Datasets","text":"<p>publish @ https://www.kaggle.com/datasets/teckmengwong/team-fight-tactics-matches</p> <p></p> <p>furyhawk/tftchamp: teamfight-tactics Data Analysis (github.com)</p>"},{"location":"#about-this-dataset","title":"About this dataset","text":"<p>Team Fight Tactics highest ELO challengers games scrape by https://github.com/furyhawk/tftchamp.</p> <p>Using https://developer.riotgames.com/ API.</p> <ul> <li> <p>8 players FFA in one game.</p> </li> <li> <p>Target Label: placement</p> </li> <li> <p>1 is best. Lower is better.</p> </li> <li> <p>Top 4 placement is a Win.</p> </li> <li> <p>Alternative prediction is to group Top 4 placement as Binary Win, bottom 4 as Binary Lost.</p> </li> <li> <p>Only team traits and augments/items chosen included in datasets.</p> </li> <li> <p>Stats like game_length, players_eliminated are excluded. This is to prevent the model from learning obvious predictor.</p> </li> </ul> <pre><code>sudo ./scripts/run_pipeline.sh -nrci\n</code></pre>"},{"location":"#web-scraping-with-python","title":"Web Scraping With Python","text":""},{"location":"#objective","title":"Objective","text":"<p>This tutorial aims to show how to use the Python programming language to web scrape a website. Specifically, we will use the <code>requests</code> and <code>Beautiful Soup</code> libraries to scrape and parse data from companiesmarketcap.com and retrieve the \u201cLargest Companies by Market Cap\u201d. Finance details are scrape and parse from finance.yahoo.com.</p> <p>We will learn how to scale the web scraping process by first retrieving the first company/row of the table, then all companies on the website\u2019s first page, and finally, all 6024 companies from multiple pages. Once the scraping process is complete, we will preprocess the dataset and transform it into a more readable format before using <code>matplotlib</code> to visualise the most important information.</p>"},{"location":"about/","title":"Cervix defendite in atque","text":""},{"location":"about/#et-caesar-ignes-aspera-polymestoris-dilectos-obvius","title":"Et Caesar ignes aspera Polymestoris dilectos obvius","text":"<p>Lorem markdownum veli fratri tum illum coeptis, plagae? In armiferae rogum.</p> <p>Quas orsa Aeacide digitis huic solent moenia properata saetis, exitus dare gerunt viget ambage hac tamen terrae longe. Aura alvum, e requiescere, inrita ille foret cedere ego siquid deprensa culpetne ausa reparet, epota aequor ope. Ad sumptas medio, est cecidit more coniuge, viam. Est signaque parte, rogumque ensem, ubi bracchia Armeniae petis. Est nunc dicta terrae noluit.</p>"},{"location":"about/#nisi-et-caeco-speciem-expellam-dolens-praeceps","title":"Nisi et caeco speciem expellam dolens praeceps","text":"<p>Monstri collibus preces. Flavescunt tenuere Aegeus.</p> <pre><code>click = alignment_point(rupSnapshot(vleOptic)) + uddiTooltipSnmp;\nif (leopardDriveE &lt;= upTypeface(touchscreen - dvi, footer,\n        cBootText.bar_heat.server(xhtmlWebcamAsp))) {\n    compatibleMultithreadingTorrent.menu_pci(desktop_in, xmp_word,\n            chipMashupDriver);\n    browserUser = hypermedia_digitize_checksum(gigaflops_logic_winsock,\n            cmos_pcb / clock_cron_drag, processor_cycle(\n            keyboardOsJavascript, tweakCellListserv, control));\n}\ntype_kilohertz.standby_ram(microphone_null_osi, metaMedia);\n</code></pre>"},{"location":"about/#adhibent-cuius-gentesque-durasse-dixit-sterilique","title":"Adhibent cuius gentesque durasse dixit sterilique","text":"<p>Meis me saxo; corpore pedibus. Undis Diomede! Se tellus ut sic illa et facti quamquam qualis fraudesque, conditus.</p> <p>Ulmo rurigenae proles prosiluit et plus movit. Titubantem inpono. Animalia pede, Minos nisi. Dixi stabat, curam curat vota sanguine Laestrygonis, ab materque finierat audes Thaumantias, terrae ulla, ego cetera. Serpentibus omnes exspectatum videre Aeneae thyrsos undae pietatis ulterius trementi agendum crudelis domitae.</p>"},{"location":"about/#fodiebant-caenis-altae-et-caeneus-omnia-ardor","title":"Fodiebant Caenis altae et Caeneus omnia ardor","text":"<p>Consolor orbem tumentem, anguigenae sanguine tectis, lea glaebam guttae fuit valens caput, desubito te cursus aegre. Momordit misit solidumve Cereris cornu, illo dubiae: me est patris vias, mihi.</p> <p>Temptat spatiosi, cornu mater: cum Iris deus conchae tellusAndros tellus coniunx: sedes. Causa natorumque perque deponendique motu hoc facitote, lea quid quorum et multi venisse vox epulis nurusque? Duobus et corpora inerti, dea calamis equi quo iuncti thalamique starent suis est placido euntem ecce tertia. Nunc terrae flammas nec fuit minimamque, effugit ecce fulgentis in inter fertur: est sic colles ponderibus.</p>"},{"location":"anomaly_detection/","title":"anomaly_detection","text":"<pre><code>pip install -e .\npip install GitPython\npip install onnx \npip install openvino-dev\n</code></pre>"},{"location":"anomaly_detection/#deep-learning-for-anomaly-detection-a-survey","title":"Deep Learning for Anomaly Detection: A survey","text":"<p>1901.03407.pdf (arxiv.org) https://arxiv.org/pdf/1901.03407.pdf</p>"},{"location":"anomaly_detection/#type-of-anomaly","title":"Type of Anomaly","text":"<ul> <li> <p>Point Anomalies</p> <ul> <li>represent an irregularity or deviation that happens randomly and may have no particular interpretation.</li> </ul> </li> <li> <p>Contextual Anomaly Detection</p> <ul> <li> <p>conditional anomaly is a data instance that could be considered as anomalous in some specific context.</p> </li> <li> <p>Contextual anomaly is identified by considering both contextual and behavioural features. The contextual features, normally used are time and space. While the behavioral features may be a pattern of spending money, the occurrence of system log events or any feature used to describe the normal behavior.</p> </li> </ul> </li> <li> <p>Collective or Group Anomaly Detection.</p> <ul> <li>Anomalous collections of individual data points are known as collective or group anomalies, wherein each of the individual points in isolation appears as normal data instances while observed in a group exhibit unusual characteristics.</li> </ul> </li> <li> <p>Output of DAD Techniques</p> <ul> <li> <p>Anomaly Score</p> </li> <li> <p>Labels</p> </li> </ul> </li> </ul>"},{"location":"anomaly_detection/#diversity-measurable-anomaly-detection-papers-with-code","title":"Diversity-Measurable Anomaly Detection | Papers With Code","text":"<p>https://paperswithcode.com/paper/diversity-measurable-anomaly-detection</p> <p>Improvement of Autoencoders and Generative Adversarial Networks.</p> <p>Limitations. Focuses on anomaly with measurable geometrical diversity, the most common type in anomaly detection. However, as for anomaly with other kind of diversities, e.g. colors, the proposed diversity measure may not be positively correlated to anomaly severity.</p>"},{"location":"anomaly_detection/#attribute-based-representations-for-accurate-and-interpretable-video-anomaly-detection-papers-with-code","title":"Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection | Papers With Code","text":"<p>https://paperswithcode.com/paper/attribute-based-representations-for-accurate</p> <ul> <li> <p>Video anomaly detection</p> </li> <li> <p>Use object detection to extract features:</p> <ul> <li> <p>Velocity</p> </li> <li> <p>Pose</p> </li> <li> <p>Deep features(pre-trained CLIP)</p> </li> </ul> </li> <li> <p>Use kNN to detect anomaly on the extracted features.</p> </li> </ul> <p>Could use similar approach to extract detective features.</p>"},{"location":"anomaly_detection/#dsr-a-dual-subspace-re-projection-network-for-surface-anomaly-detection-papers-with-code","title":"DSR -- A dual subspace re-projection network for surface anomaly detection | Papers With Code","text":"<p>https://paperswithcode.com/paper/dsr-a-dual-subspace-re-projection-network-for</p> <p>Proposes an architecture based on quantized feature space representation with dual decoders, DSR, that avoids the image-level anomaly synthesis requirement. Without making any assumptions about the visual properties of anomalies, DSR generates the anomalies at the feature level by sampling the learned quantized feature space, which allows a controlled generation of near-in-distribution anomalies.</p>"},{"location":"ceph/","title":"Manual install of a Ceph Cluster.","text":""},{"location":"ceph/#daemon-container","title":"Daemon container","text":"<p>This Dockerfile may be used to bootstrap a Ceph cluster with all the Ceph daemons running. To run a certain type of daemon, simply use the name of the daemon as <code>$1</code>. Valid values are:</p> <ul> <li><code>mon</code> deploys a Ceph monitor</li> <li><code>osd</code> deploys an OSD using the method specified by <code>OSD_TYPE</code></li> <li><code>osd_directory</code> deploys one or multiple OSDs in a single container using a prepared directory (used in scenario where the operator doesn't want to use <code>--privileged=true</code>)</li> <li><code>osd_directory_single</code> deploys an single OSD per container using a prepared directory (used in scenario where the operator doesn't want to use <code>--privileged=true</code>)</li> <li><code>osd_ceph_disk</code> deploys an OSD using ceph-disk, so you have to provide a whole device (ie: /dev/sdb)</li> <li><code>mds</code> deploys a MDS</li> <li><code>rgw</code> deploys a Rados Gateway</li> </ul>"},{"location":"ceph/#usage","title":"Usage","text":"<p>You can use this container to bootstrap any Ceph daemon.</p> <ul> <li><code>CLUSTER</code> is the name of the cluster (DEFAULT: ceph)</li> </ul>"},{"location":"ceph/#selinux","title":"SELinux","text":"<p>If SELinux is enabled, run the following commands:</p> <pre><code>sudo chcon -Rt svirt_sandbox_file_t /etc/ceph\nsudo chcon -Rt svirt_sandbox_file_t /var/lib/ceph\n</code></pre>"},{"location":"ceph/#kv-backends","title":"KV backends","text":"<p>We currently support one KV backend to store our configuration flags, keys and maps: etcd.</p> <p>There is a <code>ceph.defaults</code> config file in the image that is used for defaults to bootstrap daemons. It will add the keys if they are not already present. You can either pre-populate the KV store with your own settings, or provide a ceph.defaults config file. To supply your own defaults, make sure to mount the /etc/ceph/ volume and place your ceph.defaults file there.</p> <p>Important variables in <code>ceph.defaults</code> to add/change when you bootstrap an OSD:</p> <ul> <li><code>/osd/osd_journal_size</code></li> <li><code>/osd/cluster_network</code></li> <li><code>/osd/public_network</code></li> </ul> <p>Note: <code>cluster_network</code> and <code>public_network</code> are currently not populated in the defaults, but can be passed as environment variables with <code>-e CEPH_PUBLIC_NETWORK=...</code> for more flexibility</p>"},{"location":"ceph/#populate-key-value-store","title":"Populate Key Value store","text":"<pre><code>docker run -d --net=host \\\n-e KV_TYPE=etcd \\\n-e KV_IP=127.0.0.1 \\\n-e KV_PORT=2379 \\\nceph/daemon populate_kvstore\n</code></pre>"},{"location":"ceph/#zap-a-device","title":"Zap a device","text":"<p>Sometimes you might want to destroy partition tables from a disk. For this you can use the <code>zap_device</code> scenario that works as follow:</p> <pre><code>docker run -d --privileged=true \\\n-v /dev/:/dev/ \\\n-e OSD_DEVICE=/dev/sdd \\\nceph/daemon zap_device\n</code></pre>"},{"location":"ceph/#deploy-a-monitor","title":"Deploy a monitor","text":"<p>A monitor requires some persistent storage for the docker container. If a KV store is used, <code>/etc/ceph</code> will be auto-generated from data kept in the KV store. <code>/var/lib/ceph</code>, however, must be provided by a docker volume. The ceph mon will periodically store data into <code>/var/lib/ceph</code>, including the latest copy of the CRUSH map. If a mon restarts, it will attempt to download the latest monmap and CRUSH map from other peer monitors. However, if all mon daemons have gone down, monitors must be able to recover their previous maps. The docker volume used for <code>/var/lib/ceph</code> should be backed by some durable storage, and must be able to survive container and node restarts.</p> <p>Without KV store, run:</p> <pre><code>docker run -d --net=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-e MON_IP=192.168.0.20 \\\n-e CEPH_PUBLIC_NETWORK=192.168.0.0/24 \\\nceph/daemon mon\n</code></pre> <p>With KV store, run:</p> <pre><code>docker run -d --net=host \\\n-v /var/lib/ceph:/var/lib/ceph \\\n-e MON_IP=192.168.0.20 \\\n-e CEPH_PUBLIC_NETWORK=192.168.0.0/24 \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon mon\n</code></pre> <p>List of available options:</p> <ul> <li><code>MON_NAME</code>: name of the monitor (default to hostname)</li> <li><code>CEPH_PUBLIC_NETWORK</code>: CIDR of the host running Docker, it should be in the same network as the <code>MON_IP</code></li> <li><code>CEPH_CLUSTER_NETWORK</code>: CIDR of a secondary interface of the host running Docker. Used for the OSD replication traffic</li> <li><code>MON_IP</code>: IP address of the host running Docker</li> <li><code>NETWORK_AUTO_DETECT</code>: Whether and how to attempt IP and network autodetection. Meant to be used without <code>--net=host</code>.</li> <li> <p><code>NEW_USER_KEYRING</code>: if specified, it will be imported to keyrings. Works in demo mode only.</p> </li> <li> <p>0 = Do not detect (default)</p> </li> <li>1 = Detect IPv6, fallback to IPv4 (if no globally-routable IPv6 address detected)</li> <li>4 = Detect IPv4 only</li> <li>6 = Detect IPv6 only</li> </ul>"},{"location":"ceph/#deploy-a-manager-daemon","title":"Deploy a Manager daemon","text":"<p>Since luminous, a manager daemon is mandatory, see docs</p> <p>Without KV store, run:</p> <pre><code>docker run -d --net=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\nceph/daemon mgr\n</code></pre> <p>With KV store, run:</p> <pre><code>docker run -d --net=host \\\n-v /var/lib/ceph:/var/lib/ceph \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon mgr\n</code></pre>"},{"location":"ceph/#deploy-an-osd","title":"Deploy an OSD","text":"<p>There are four available <code>OSD_TYPE</code> values:</p> <ul> <li><code>&lt;none&gt;</code> - if no <code>OSD_TYPE</code> is set; one of <code>disk</code>, <code>activate</code> or <code>directory</code> will be used based on autodetection of the current OSD bootstrap state</li> <li><code>activate</code> - the daemon expects to be passed a block device of a <code>ceph-disk</code>-prepared disk (via the <code>OSD_DEVICE</code> environment variable); no bootstrapping will be performed</li> <li><code>directory</code> - the daemon expects to find the OSD filesystem(s) already mounted in <code>/var/lib/ceph/osd/</code></li> <li><code>disk</code> - the daemon expects to be passed a block device via the <code>OSD_DEVICE</code> environment variable</li> <li><code>prepare</code> - the daemon expects to be passed a block device and run <code>ceph-disk</code> prepare to bootstrap the disk (via the <code>OSD_DEVICE</code> environment variable)</li> </ul> <p>Options for OSDs (TODO: consolidate these options between the types):</p> <ul> <li><code>JOURNAL_DIR</code> - if provided, new OSDs will be bootstrapped to use the specified directory as a common journal area. This is usually used to store the journals for more than one OSD on a common, separate disk. This currently only applies to the <code>directory</code> OSD type.</li> <li><code>JOURNAL</code> - if provided, the new OSD will be bootstrapped to use the specified journal file (if you do not wish to use the default). This is currently only supported by the <code>directory</code> OSD type</li> <li><code>OSD_DEVICE</code> - mandatory for <code>activate</code> and <code>disk</code> OSD types; this specifies which block device to use as the OSD</li> <li><code>OSD_JOURNAL</code> - optional override of the OSD journal file. this only applies to the <code>activate</code> and <code>disk</code> OSD types</li> <li><code>OSD_FORCE_EXT4</code> - in case the osd data on ext4 is not automatically recognized (i.e. hidden by overlayfs) you can force them by settings this to <code>yes</code>.</li> </ul>"},{"location":"ceph/#without-osd_type","title":"Without OSD_TYPE","text":"<p>If the operator does not specify an <code>OSD_TYPE</code> autodetection happens:</p> <ul> <li><code>disk</code> is used if no bootstrapped OSD is found.</li> <li><code>activate</code> is used if a bootstrapped OSD is found and <code>OSD_DEVICE</code> is also provided.</li> <li><code>directory</code> is used if a bootstrapped OSD is found and no <code>OSD_DEVICE</code> is provided.</li> </ul> <p>Without KV backend:</p> <pre><code>docker run -d --net=host \\\n--pid=host \\\n--privileged=true \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\nceph/daemon osd\n</code></pre> <p>With KV backend:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon osd\n</code></pre>"},{"location":"ceph/#ceph-disk","title":"Ceph disk","text":"<p>Without KV backend:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\nceph/daemon osd\n</code></pre> <p>Using bluestore:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\n-e OSD_BLUESTORE=1 \\\nceph/daemon osd\n</code></pre> <p>Using dmcrypt:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\n-e OSD_DMCRYPT=1 \\\nceph/daemon osd\n</code></pre> <p>With KV backend:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon osd\n</code></pre> <p>Using bluestore with KV backend:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\n-e OSD_BLUESTORE=1 \\\nceph/daemon osd\n</code></pre> <p>Using dmcrypt with KV backend:</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=disk \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\n-e OSD_DMCRYPT=1 \\\nceph/daemon osd\n</code></pre> <p>List of available options:</p> <ul> <li><code>OSD_DEVICE</code> is the OSD device</li> <li><code>OSD_JOURNAL</code> is the journal for a given OSD</li> <li><code>HOSTNAME</code> is used to place the OSD in the CRUSH map</li> </ul> <p>If you do not want to use <code>--privileged=true</code>, please fall back on the second example.</p>"},{"location":"ceph/#ceph-disk-activate","title":"Ceph disk activate","text":"<p>This function is balance between ceph-disk and osd directory where the operator can use ceph-disk outside of the container (directly on the host) to prepare the devices. Devices will be prepared with <code>ceph-disk prepare</code>, then they will get activated inside the container. A priviledged container is still required as ceph-disk needs to access /dev/. So this has minimum value compare to the ceph-disk but might fit some use cases where the operators want to prepare their devices outside of a container.</p> <pre><code>docker run -d --net=host \\\n--privileged=true \\\n--pid=host \\\n-v /etc/ceph:/etc/ceph \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /dev/:/dev/ \\\n-v /run/udev/:/run/udev/ \\\n-e OSD_DEVICE=/dev/vdd \\\n-e OSD_TYPE=activate \\\nceph/daemon osd\n</code></pre>"},{"location":"ceph/#ceph-osd-directory","title":"Ceph OSD directory","text":"<p>There are a number of environment variables which are used to configure the execution of the OSD:</p> <ul> <li><code>CLUSTER</code> is the name of the ceph cluster (defaults to <code>ceph</code>)</li> </ul> <p>If the OSD is not already created (key, configuration, OSD data), the following environment variables will control its creation:</p> <ul> <li><code>WEIGHT</code> is the of the OSD when it is added to the CRUSH map (default is <code>1.0</code>)</li> <li><code>JOURNAL</code> is the location of the journal (default is the <code>journal</code> file inside the OSD data directory)</li> <li><code>HOSTNAME</code> is the name of the host; it is used as a flag when adding the OSD to the CRUSH map</li> </ul> <p>The old option <code>OSD_ID</code> is now unused. Instead, the script will scan for each directory in <code>/var/lib/ceph/osd</code> of the form <code>&lt;cluster&gt;-&lt;osd_id&gt;</code>.</p> <p>To create your OSDs simply run the following command:</p> <p><code>docker exec &lt;mon-container-id&gt; ceph osd create</code>.</p> <p>Note that we now default to dropping root privileges, so it is important to set the proper ownership for your OSD directories. The Ceph OSD runs as UID:167, GID:167, so:</p> <p><code>chown -R 167:167 /var/lib/ceph/osd/</code></p>"},{"location":"ceph/#multiple-osds","title":"Multiple OSDs","text":"<p>There is a problem when attempting run run multiple OSD containers on a single docker host. See issue #19.</p> <p>There are two workarounds, at present:</p> <ul> <li>Run each OSD with the <code>--pid=host</code> option</li> <li>Run multiple OSDs within the same container</li> </ul> <p>To run multiple OSDs within the same container, simply bind-mount each OSD datastore directory:</p> <ul> <li><code>docker run -v /osds/1:/var/lib/ceph/osd/ceph-1 -v /osds/2:/var/lib/ceph/osd/ceph-2</code></li> </ul>"},{"location":"ceph/#ceph-osd-directory-single","title":"Ceph OSD directory single","text":"<p>Ceph OSD directory single has a similar design to Ceph OSD directory since they both aim to run OSD processes from an already bootstrapped directory. So we assume the OSD directory has been populated already. The major different is that Ceph OSD directory single has a much simpler implementation since it only runs a single OSD process per container. It doesn't do anything with the journal as it assumes journal's symlink was provided during the initialization sequence of the OSD.</p> <p>This scenario goes through the OSD directory (<code>/var/lib/ceph/osd</code>) and looks for OSDs that don't have a lock held by any other OSD. If no lock is found, the OSD process starts. If all the OSDs are already running, we gently exit 0 and explain that all the OSDs are already running.</p> <p>Important note: if you are aiming at running multiple OSD containers on a same machine (things that you will likely do with Ceph anyway), you must enable <code>--pid=host</code>. However if you are running Docker 1.12 (based on https://github.com/docker/docker/pull/22481), you can just share the same PID namespace for the OSD containers only using: <code>--pid=container:&lt;id&gt;</code>.</p>"},{"location":"ceph/#btrfs-and-journal","title":"BTRFS and journal","text":"<p>If your OSD is BTRFS and you want to use PARALLEL journal mode, you will need to run this container with <code>--privileged</code> set to true. Otherwise, <code>ceph-osd</code> will have insufficient permissions and it will revert to the slower WRITEAHEAD mode.</p>"},{"location":"ceph/#note","title":"Note","text":"<p>Re: [https://github.com/Ulexus/docker-ceph/issues/5]</p> <p>A user has reported a consterning (and difficult to diagnose) problem wherein the OSD crashes frequently due to Docker running out of sufficient open file handles. This is understandable, as the OSDs use a great many ports during periods of high traffic. It is, therefore, recommended that you increase the number of open file handles available to Docker.</p> <p>On CoreOS (and probably other systemd-based systems), you can do this by creating the a file named <code>/etc/systemd/system/docker.service.d/limits.conf</code> with content something like:</p> <pre><code>[Service]\nLimitNOFILE=4096\n</code></pre>"},{"location":"ceph/#deploy-a-mds","title":"Deploy a MDS","text":"<p>By default, the MDS does NOT create a ceph filesystem. If you wish to have this MDS create a ceph filesystem (it will only do this if the specified <code>CEPHFS_NAME</code> does not already exist), you must set, at a minimum, <code>CEPHFS_CREATE=1</code>. It is strongly recommended that you read the rest of this section, as well.</p> <p>For most people, the defaults for the following optional environment variables are fine, but if you wish to customize the data and metadata pools in which your CephFS is stored, you may override the following as you wish:</p> <ul> <li><code>CEPHFS_CREATE</code>: Whether to create the ceph filesystem (0 = no / 1 = yes), if it doesn't exist. Defaults to 0 (no)</li> <li><code>CEPHFS_NAME</code>: The name of the new ceph filesystem and the basis on which the later variables are created. Defaults to <code>cephfs</code></li> <li><code>CEPHFS_DATA_POOL</code>: The name of the data pool for the ceph filesystem. If it does not exist, it will be created. Defaults to <code>${CEPHFS_NAME}_data</code></li> <li><code>CEPHFS_DATA_POOL_PG</code>: The number of placement groups for the data pool. Defaults to <code>8</code></li> <li><code>CEPHFS_METADATA_POOL</code>: The name of the metadata pool for the ceph filesystem. If it does not exist, it will be created. Defaults to <code>${CEPHFS_NAME}_metadata</code></li> <li><code>CEPHFS_METADATA_POOL_PG</code>: The number of placement groups for the metadata pool. Defaults to <code>8</code></li> </ul> <p>Without KV backend, run:</p> <pre><code>docker run -d --net=host \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /etc/ceph:/etc/ceph \\\n-e CEPHFS_CREATE=1 \\\nceph/daemon mds\n</code></pre> <p>With KV backend, run:</p> <pre><code>docker run -d --net=host \\\n-e CEPHFS_CREATE=1 \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon mds\n</code></pre> <p>List of available options:</p> <ul> <li><code>MDS_NAME</code> is the name the MDS server (DEFAULT: mds-$(hostname)). One thing to note is that metadata servers are not machine-restricted. They are not bound by their data directories and can move around the cluster. As a result, you can run more than one MDS on a single machine. If you plan to do so, you better set this variable and do something like: <code>mds-$(hostname)-a</code>, <code>mds-$(hostname)-b</code>etc...</li> </ul>"},{"location":"ceph/#deploy-a-rados-gateway","title":"Deploy a Rados Gateway","text":"<p>For the Rados Gateway, we deploy it with <code>civetweb</code> enabled by default. However it is possible to use different CGI frontends by simply giving remote address and port.</p> <p>Without kv backend, run:</p> <pre><code>docker run -d --net=host \\\n-v /var/lib/ceph/:/var/lib/ceph/ \\\n-v /etc/ceph:/etc/ceph \\\nceph/daemon rgw\n</code></pre> <p>With kv backend, run:</p> <pre><code>docker run -d --net=host \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon rgw\n</code></pre> <p>List of available options:</p> <ul> <li><code>RGW_CIVETWEB_PORT</code> is the port to which civetweb is listening on (DEFAULT: 8080)</li> <li><code>RGW_NAME</code>: default to hostname</li> </ul> <p>Administration via radosgw-admin from the Docker host if the <code>RGW_NAME</code> variable hasn't been supplied:</p> <p><code>docker exec &lt;containerId&gt; radosgw-admin -n client.rgw.$(hostname) -k /var/lib/ceph/radosgw/$(hostname)/keyring &lt;commands&gt;</code></p> <p>If otherwise, <code>$(hostname)</code> has to be replaced by the value of <code>RGW_NAME</code>.</p> <p>To enable an external CGI interface instead of civetweb set:</p> <ul> <li><code>RGW_REMOTE_CGI=1</code></li> <li><code>RGW_REMOTE_CGI_HOST=192.168.0.1</code></li> <li><code>RGW_REMOTE_CGI_PORT=9000</code></li> </ul> <p>And run the container like this <code>docker run -d -v /etc/ceph:/etc/ceph -v /var/lib/ceph/:/var/lib/ceph -e CEPH_DAEMON=RGW -e RGW_NAME=myrgw -p 9000:9000 -e RGW_REMOTE_CGI=1 -e RGW_REMOTE_CGI_HOST=192.168.0.1 -e RGW_REMOTE_CGI_PORT=9000 ceph/daemon</code></p>"},{"location":"ceph/#deploy-a-rest-api","title":"Deploy a REST API","text":"<p>This is pretty straightforward. The <code>--net=host</code> is not mandatory, if you don't use it do not forget to expose the <code>RESTAPI_PORT</code>. Only available in luminous.</p> <pre><code>docker run -d --net=host \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon restapi\n</code></pre> <p>List of available options:</p> <ul> <li><code>RESTAPI_IP</code> is the IP address to listen on (DEFAULT: 0.0.0.0)</li> <li><code>RESTAPI_PORT</code> is the listening port of the REST API (DEFAULT: 5000)</li> <li><code>RESTAPI_BASE_URL</code> is the base URL of the API (DEFAULT: /api/v0.1)</li> <li><code>RESTAPI_LOG_LEVEL</code> is the log level of the API (DEFAULT: warning)</li> <li><code>RESTAPI_LOG_FILE</code> is the location of the log file (DEFAULT: /var/log/ceph/ceph-restapi.log)</li> </ul>"},{"location":"ceph/#deploy-a-rbd-mirror","title":"Deploy a RBD mirror","text":"<p>This is pretty straightforward. The <code>--net=host</code> is not mandatory, with KV we do:</p> <pre><code>docker run -d --net=host \\\n-e KV_TYPE=etcd \\\n-e KV_IP=192.168.0.20 \\\nceph/daemon rbd_mirror\n</code></pre> <p>Without KV we do:</p> <pre><code>docker run -d --net=host \\\nceph/daemon rbd_mirror\n</code></pre>"},{"location":"ceph/#fetching-software","title":"Fetching software.","text":"<p>First of I want to check that I have all the latest packages in my debian system.</p> <pre><code>apt update\napt upgrade\n</code></pre> <p>Next we fetch the keys and ceph packages, in this case we download the pacific packages for buster.</p> <pre><code>wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add -\necho deb https://download.ceph.com/debian-pacific/ buster main | sudo tee /etc/apt/sources.list.d/ceph.list\napt update\napt install ceph ceph-common\n</code></pre> <p>Last we need to download the smartmontools for our nodes. This is so we can monitor our hard drives for hardware issues.</p> <pre><code>echo deb http://deb.debian.org/debian buster-backports main &gt;&gt; /etc/apt/sources.list\napt update\napt install smartmontools/buster-backports\n</code></pre> <p>A reboot when you have installed packages is always a good thing and if you need to do some extra hardware changes this is a good place to do so.</p> <pre><code>shutdown -r now\n</code></pre>"},{"location":"ceph/#configure-node-1","title":"Configure node 1","text":"<p>First we will create a ceph configuration file.</p> <pre><code>sudo vi /etc/ceph/ceph.conf\n</code></pre> <p>The most important things to specify is the id and ips of your cluster monitors. A unique cluster id that you will reuse for all your nodes. And lastly a public network range that you want your monitors to be available over. The cluster network is a good addition if you have the resources to route the recovery traffic on a backbone network.</p> <pre><code>[global]\nfsid = {cluster uuid}\nmon initial members = {id1}, {id2}, {id2}\nmon host = {ip1}, {ip2}, {ip3}\npublic network = {network range for your public network}\ncluster network = {network range for your cluster network}\nauth cluster required = cephx\nauth service required = cephx\nauth client required = cephx\n</code></pre> <p>Next we create keys for admin, monitors and boostrapping our drives. These keys will then be merged with the monitor key so the initial setup will have the keys used for other operations.</p> <pre><code>sudo ceph-authtool --create-keyring /tmp/monkey --gen-key -n mon. --cap mon 'allow *'\nsudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'\nsudo ceph-authtool --create-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring --gen-key -n client.bootstrap-osd --cap mon 'profile bootstrap-osd'\nsudo ceph-authtool /tmp/monkey --import-keyring /etc/ceph/ceph.client.admin.keyring\nsudo ceph-authtool /tmp/monkey --import-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring\n</code></pre> <p>Make the monitor key available to the ceph user so we don't get an permission error when we start our services.</p> <pre><code>sudo chown ceph:ceph /tmp/monkey\n</code></pre> <p>Next up we create a monitor map so the monitors will know of each other. The monitors keeps track on other resources but for high availability the monitors needs to know who is in charge.</p> <pre><code>monmaptool --create --add {node1-id} {node1-ip} --fsid {cluster uuid} /tmp/monmap\nmonmaptool --add {node2-id} {node2-ip} --fsid {cluster uuid} /tmp/monmap\nmonmaptool --add {node3-id} {node3-ip} --fsid {cluster uuid} /tmp/monmap\n</code></pre> <p>Starting a new monitor is as easy as creating a new directory, creating the filesystem for and starting the service.</p> <pre><code>sudo -u ceph mkdir /var/lib/ceph/mon/ceph-{node1-id}\nsudo -u ceph ceph-mon --mkfs -i {node1-id} --monmap /tmp/monmap --keyring /tmp/monkey\nsudo systemctl start ceph-mon@{node1-id}\n</code></pre> <p>Next up we need a manager so we could configure and monitor our cluster through a visual dashboard. First we create a new key, put that key in a newly created directory and start the service. Enabling a dashboard is as easy as running the command for enabling, creating / assigning a certificate and creating a new admin user.</p> <pre><code>sudo ceph auth get-or-create mgr.{node1-id} mon 'allow profile mgr' osd 'allow *' mds 'allow *'\nsudo -u ceph mkdir /var/lib/ceph/mgr/ceph-{node1-id}\nsudo -u ceph vi /var/lib/ceph/mgr/ceph-{node1-id}/keyring\nsudo systemctl start ceph-mgr@{node1-id}\nsudo ceph mgr module enable dashboard\nsudo ceph dashboard create-self-signed-cert\nsudo ceph dashboard ac-user-create admin -i passwd administrator\n</code></pre>"},{"location":"ceph/#setting-up-more-nodes","title":"Setting up more nodes.","text":"<p>First of we need to copy over the configuration, monitor map and all the keys over to our new host.</p> <pre><code>sudo scp {user}@{server}:/etc/ceph/ceph.conf /etc/ceph/ceph.conf\nsudo scp {user}@{server}:/etc/ceph/ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring\nsudo scp {user}@{server}:/var/lib/ceph/bootstrap-osd/ceph.keyring /var/lib/ceph/bootstrap-osd/ceph.keyring\nsudo scp {user}@{server}:/tmp/monmap /tmp/monmap\nsudo scp {user}@{server}:/tmp/monkey /tmp/monkey\n</code></pre> <p>Next up we setup the monitor node exactly as we did with the first node.</p> <pre><code>sudo -u ceph mkdir /var/lib/ceph/mon/ceph-{node2-id}\nsudo -u ceph ceph-mon --mkfs -i {node2-id} --monmap /tmp/monmap --keyring /tmp/monkey\nsudo systemctl start ceph-mon@{node2-id}\nsudo ceph -s\nsudo ceph mon enable-msgr2\n</code></pre> <p>Then we setup the manager node exactly as we did with the first node.</p> <pre><code>sudo ceph auth get-or-create mgr.{node2-id} mon 'allow profile mgr' osd 'allow *' mds 'allow *'\nsudo -u ceph mkdir /var/lib/ceph/mgr/ceph-{node2-id}\nsudo -u ceph vi /var/lib/ceph/mgr/ceph-{node2-id}/keyring\nsudo systemctl start ceph-mgr@{node2-id}\n</code></pre>"},{"location":"ceph/#adding-storage","title":"Adding storage","text":"<p>When the cluster is up and running and all monitors are in qourum you could add storage services. This is easily done via the volume command. First prepare a disk so it will be known by the cluster and have the keys and configuration copied to the management directory. Next up you activate the service so your storage nodes will be ready to use. This will be done for all the harddrives you want to add to your network.</p> <pre><code>sudo ceph-volume lvm prepare --data /dev/sdb \nsudo ceph-volume lvm activate {osd-number} {osd-uuid}\n</code></pre>"},{"location":"ceph/#post-configuration","title":"Post configuration","text":"<p>Last but not least you want to ensure that all the services starts after a reboot. In debian you do that by enabling the services.</p> <pre><code>sudo systemctl enable ceph-mon@{node-id}\nsudo systemctl enable ceph-mgr@{node-id}\nsudo systemctl enable ceph-osd@{osd-number}\n</code></pre>"},{"location":"chart/","title":"chart","text":""},{"location":"code/","title":"code","text":""},{"location":"code/#install-vscode","title":"install vscode","text":"<pre><code>git clone https://AUR.archlinux.org/visual-studio-code-bin.git\ncd visual-studio-code-bin\nmakepkg -s\nsudo pacman -U *code-bin-*.pkg.tar.zst\ncd ../ &amp;&amp; sudo rm -rfv visual-studio-code-bin/\n</code></pre>"},{"location":"conda/","title":"conda cheat sheet","text":"<pre><code>conda update -n base conda\n\nconda remove --name myenv --all\nconda env remove -n tf2\n\nconda init powershell\n\nconda env create -f environment.yml\nconda env export &gt; environment.yml\n\nconda create --name myenv python=3.10\nconda install --file requirements.txt\nconda install --file requirements.txt -c conda-forge\nconda create --name tft --clone 311\n\npip install -r /path/to/requirements.txt\npip install --upgrade --force-reinstall -r requirements.txt\n\npython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"\n\nconda clean -a\n\nconda install -y -c apple tensorflow-deps\npip install tensorflow-macos tensorflow-metal\n\nbash Miniconda3-py310_22.11.1-1-Linux-x86_64.sh \nconda list\nconda config --add channels conda-forge\nconda config --describe\nconda config --set auto_activate_base false\nconda update --all\npip --disable-pip-version-check list --outdated --format=json | python -c \"import json, sys; print('\\n'.join([x['name'] for x in json.load(sys.stdin)]))\" | xargs -n1 pip install -U\nconda update conda\nconda install --file requirements.txt -c conda-forge\npip install -r requirements.txt\n\n# archlinux\n echo \"[ -f /opt/miniconda3/etc/profile.d/conda.sh ] &amp;&amp; source /opt/miniconda3/etc/profile.d/conda.sh\" &gt;&gt; ~/.zshrc\n\n\n# ubuntu\nmkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm -rf ~/miniconda3/miniconda.sh\n\nsource ~/miniconda3/etc/profile.d/conda.sh\nconda init zsh\n</code></pre>"},{"location":"dataframe/","title":"Dataframe","text":"<p><code>df[\"cancer\"].value_counts().plot(kind='barh')</code> <code>df[[\"patient_id\", \"image_id\"]].astype(str).apply(lambda x: 'data/rsna/'+'/'.join(x)+'.png', axis=1)</code> <code>list(mapping.keys())[list(mapping.values()).index(x)]</code> ``</p> <p>import logging from configs import LOGGER_NAME</p> <p>logger = logging.getLogger(LOGGER_NAME)  # pylint: disable=invalid-name</p> <p>logger.info</p>"},{"location":"dataframe/#rows-of-a-pandas-dataframe-df","title":"Rows of a pandas dataframe df","text":"<pre><code>def __len__(self) -&gt; int:\n        \"\"\"Return the length of the dataset.\"\"\"\n        return len(self.df.index)\n</code></pre> <pre><code>In [7]: timeit len(df.index)\n1000000 loops, best of 3: 248 ns per loop\n\nIn [8]: timeit len(df)\n1000000 loops, best of 3: 573 ns per loop\n</code></pre>"},{"location":"db/","title":"SQLAlchemy","text":"<pre><code>conda create --name sql python=3.11\npip install SQLAlchemy\npip install mariadb\npip install PyMySQL\nbrew install mariadb-connector-c\nbrew install mysql\ndocker-compose up --build -d\n</code></pre>"},{"location":"docker/","title":"Docker","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install git curl htop mc rsync zsh-autosuggestions\nsudo apt install zsh\nchsh -s $(which zsh)\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\nrsync -avuPz ./.oh-my-zsh/custom/themes/custom.zsh-theme furyhawk@arm:/home/furyhawk/.oh-my-zsh/custom/themes/custom.zsh-theme\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestions\ngit clone https://github.com/zdharma-continuum/fast-syntax-highlighting.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/plugins/fast-syntax-highlighting\n## Enable plugins by adding them to .zshrc.\n - Open .zshrc\n\n    `nano ~/.zshrc`\n\n - ZSH_THEME=\"custom\"\n\n - Find the line which says `plugins=(git)`.\n\n - Replace that line with\n    `plugins=(git zsh-autosuggestions zsh-syntax-highlighting fast-syntax-highlighting zsh-autocomplete)`\n\n\ntouch .zprofile\nnano .zprofile\n\n# set PATH so it includes user's private bin if it exists\nif [ -d \"$HOME/bin\" ] ; then\n    PATH=\"$HOME/bin:$PATH\"\nfi\n\n# set PATH so it includes user's private bin if it exists\nif [ -d \"$HOME/.local/bin\" ] ; then\n    PATH=\"$HOME/.local/bin:$PATH\"\nfi\n\nexport TZ=Asia/Singapore\nexport NODE_ID=$(docker info -f '{{.Swarm.NodeID}}')\nexport EMAIL=furyx@hotmail.com\nexport DOMAIN=furyhawk.lol\n\nsudo nano /etc/fstab\ntouch .credentials\nnano .credentials\n\nsudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc\n\nsudo chmod a+r /etc/apt/keyrings/docker.asc\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\n  $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n# sudo groupadd docker\nsudo usermod -aG docker $USER\nsudo systemctl enable docker.service\nsudo systemctl enable containerd.service\nsystemctl list-units --type=service --state=active\ncd /etc/docker\nsudo touch daemon.json\nsudo nano daemon.json\n\n{\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  }\n}\n\n\ndocker swarm join --token SWMTKN-1-xxx 192.168.50.114:2377\n\ndocker node update --availability drain node\ndocker node update --availability Active node\n\ncurl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm\nchmod +x cephadm\nsudo ./cephadm add-repo --release octopus\nsudo ./cephadm install\ncephadm install ceph-common\nmkdir -p /etc/ceph\n\nsudo ./cephadm bootstrap --mon-ip 192.168.65.19\nURL: https://debian.local:8443/\n        User: admin\n    Password: 12345678\n\nYou can access the Ceph CLI with:\n\n    sudo ./cephadm shell --fsid 8ad7deb6-265a-11ef-9e81-c2d0c41fc7e0 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring\n\nPlease consider enabling telemetry to help improve Ceph:\n\n    ceph telemetry on\n\nFor more information see:\n\n    https://docs.ceph.com/docs/master/mgr/telemetry/\n\nalias ceph='./cephadm shell -- ceph'\nsudo ceph -v\nceph version 16.2.11 (3cf40e2dca667f68c6ce3ff5cd94f01e711af894) pacific (stable)\nsudo ceph orch host label add debian mon\nAdded label mon to host debian\nsudo ceph orch apply mon debian\nScheduled mon update...\nsudo ceph orch host ls\n\nssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph-2\nssh-copy-id -f -i /etc/ceph/ceph.pub osd1\nssh-copy-id -f -i /etc/ceph/ceph.pub osd2\nssh-copy-id -f -i /etc/ceph/ceph.pub osd3\nsudo ceph orch host add osd1\nsudo ceph orch host add osd2\nsudo ceph orch host add osd3\n\nsudo ceph orch apply osd --all-available-devices\nsudo ceph status\n\nsudo find / -iname 'cephadm*' 2&gt;/dev/null\n</code></pre> <pre><code>systemctl --user start docker-desktop\nsudo groupadd docker\nsudo usermod -aG docker $USER\ngroups ${USER}\n</code></pre> <pre><code>curl -fsSL test.docker.com -o get-docker.sh &amp;&amp; sh get-docker.sh\nsudo apt-get install libffi-dev libssl-dev\nsudo apt install python3-dev\nsudo apt-get install -y python3 python3-pip\npip install \"cython&lt;3.0.0\" wheel\npip install \"pyyaml==5.4.1\" --no-build-isolation\npip install docker-compose\nsudo systemctl enable docker\n</code></pre> <pre><code>sudo apt-get purge docker-ce\nsudo apt-get purge docker-ce-cli\nsudo rm -rf /var/lib/docker\n</code></pre> <p>rootless</p> <pre><code>sudo apt install -y dbus-user-session\nsudo apt install -y fuse-overlayfs\nsudo apt install -y fuse-overlayfs\nsudo systemctl disable --now docker.service docker.socket\nsudo rm -rf /var/lib/docker\nsudo apt-get purge docker-ce docker-ce-cli containerd.io\nsudo apt-get purge docker-ce docker-ce-cli containerd.io\napt-get install -y uidmap\ncurl -fsSL https://get.docker.com/rootless | sh\n\nnano .zshrc\nexport PATH=/home/furyhawk/bin:$PATH\nexport DOCKER_HOST=unix:///run/user/1000/docker.sock\n\nsystemctl --user enable docker\nsudo loginctl enable-linger $(whoami)\ndocker context use rootless\n\nsudo setcap cap_net_bind_service=ep $(which rootlesskit)\nsystemctl --user restart docker\n#sudo apt-get install -y docker-ce-rootless-extras\n\ndockerd-rootless-setuptool.sh uninstall\ncd ~/bin\nrm -f containerd containerd-shim containerd-shim-runc-v2 ctr docker docker-init docker-proxy dockerd dockerd-rootless-setuptool.sh dockerd-rootless.sh rootlesskit rootlesskit-docker-proxy runc vpnkit\n\nnetstat -ltup\n</code></pre>"},{"location":"docker/#the-compose-specification","title":"The Compose Specification","text":"<p>{:.no_toc}</p> <ul> <li>ToC   {:toc}</li> </ul>"},{"location":"docker/#status-of-this-document","title":"Status of this document","text":"<p>This document specifies the Compose file format used to define multi-containers applications. Distribution of this document is unlimited.</p>"},{"location":"docker/#requirements-and-optional-attributes","title":"Requirements and optional attributes","text":"<p>The Compose specification includes properties designed to target a local OCI container runtime, exposing Linux kernel specific configuration options, but also some Windows container specific properties. It is also designed for cloud platform features related to resource placement on a cluster, replicated application distribution, and scalability.</p> <p>We acknowledge that no Compose implementation is expected to support all attributes, and that support for some properties is platform dependent and can only be confirmed at runtime. The definition of a versioned schema to control the supported properties in a Compose file, established by the docker-compose tool where the Compose file format was designed, doesn't offer any guarantee to the end-user that attributes will be actually implemented.</p> <p>The specification defines the expected configuration syntax and behavior. Unless noted, supporting any of these is optional.</p> <p>A Compose implementation to parse a Compose file using unsupported attributes should warn users. We recommend the following implementors to support those running modes:</p> <ul> <li>Default: warn the user about unsupported attributes, but ignore them</li> <li>Strict: warn the user about unsupported attributes and reject the Compose file</li> <li>Loose: ignore unsupported attributes AND unknown attributes (that were not defined by the spec by the time implementation was created)</li> </ul> <p>From this point onwards, references made to 'Compose' can be interpreted as 'a Compose implementation'. </p>"},{"location":"docker/#the-compose-application-model","title":"The Compose application model","text":"<p>The Compose Specification lets you define a platform-agnostic container based application. Such an application is designed as a set of containers which have to both run together with adequate shared resources and communication channels.</p> <p>Computing components of an application are defined as services. A service is an abstract concept implemented on platforms by running the same container image, and configuration, one or more times.</p> <p>Services communicate with each other through networks. In the Compose Specification, a network is a platform capability abstraction to establish an IP route between containers within services connected together. Low-level, platform-specific networking options are grouped into the Network definition and may be partially implemented on some platforms.</p> <p>Services store and share persistent data into volumes. The Specification describes such a persistent data as a high-level filesystem mount with global options. Actual platform-specific implementation details are grouped into the volumes definition and may be partially implemented on some platforms.</p> <p>Some services require configuration data that is dependent on the runtime or platform. For this, the Specification defines a dedicated configs concept. From a service container point of view, configs are comparable to volumes, in that they are files mounted into the container. But the actual definition involves distinct platform resources and services, which are abstracted by this type.</p> <p>A secret is a specific flavor of configuration data for sensitive data that should not be exposed without security considerations. Secrets are made available to services as files mounted into their containers, but the platform-specific resources to provide sensitive data are specific enough to deserve a distinct concept and definition within the Compose specification.</p> <p>Note</p> <p>With volumes, configs and secrets you can have a simple declaration at the top-level and then add more platform-specific information at the service level.</p> <p>A project is an individual deployment of an application specification on a platform. A project's name, set with the top-level <code>name</code> attribute, is used to group resources together and isolate them from other applications or other installation of the same Compose specified application with distinct parameters. If you are creating resources on a platform, you must prefix resource names by project and set the label <code>com.docker.compose.project</code>.</p> <p>Compose offers a way for users to set a custom project name and override this name, so that the same <code>compose.yaml</code> file can be deployed twice on the same infrastructure, without changes, by just passing a distinct name.</p> <p>Project names must contain only lowercase letters, decimal digits, dashes, and underscores, and must begin with a lowercase letter or decimal digit.</p>"},{"location":"docker/#illustrative-example","title":"Illustrative example","text":"<p>The following example illustrates the Compose Specification concepts outlined above. The example is non-normative.</p> <p>Consider an application split into a frontend web application and a backend service.</p> <p>The frontend is configured at runtime with an HTTP configuration file managed by infrastructure, providing an external domain name, and an HTTPS server certificate injected by the platform's secured secret store.</p> <p>The backend stores data in a persistent volume.</p> <p>Both services communicate with each other on an isolated back-tier network, while the frontend is also connected to a front-tier network and exposes port 443 for external usage.</p> <pre><code>    %%{ init: { 'flowchart': { 'curve': 'linear' } } }%%\n    flowchart LR\n    subgraph A[INFRASTRUCTURE]\n    direction TB\n    subgraph TOP[\" \"]\n        subgraph B1[Frontend Service]\n            fs[\"`**webapp**`\"]\n        end\n        style B1 fill:#ccd6e8, stroke-width:0px\n        subgraph B2[Backend Service]\n            bs[\"`**database**`\"]\n        end\n        style B2 fill:#ccd6e8, stroke-width:0px\n\n    end\n    style TOP fill:transparent, stroke-width:2px, stroke:#62affb, stroke-dasharray: 5 5\n        key[ro= read only\\nr+w = read write]\n        style key fill:transparent, stroke-width:0px,text-align: left, size: 94px\n\n        direction TB\n        id2(Server\\nCertificate)\n        id1(HTTP\\nConfiguration)\n        id1 &amp; id2 -.-|ro| B1\n        style id1 stroke:#000,stroke-width:1px,stroke-dasharray: 10\n        style id2 stroke:#000,stroke-width:1px,stroke-dasharray: 10\n        B2 ==r+w==&gt; id3[(Persistent\\nVolume)]\n    end\n    style A fill:#eeeeee, stroke-width:0px\n    direction LR\n    id4[External\\nUser] ---id5(((443)))---&gt;|Frontend\\nNetwork| B1\n    style id4 stroke:#000,stroke-width:2px\n    B1 --Backend\\nNetwork--&gt; B2\n</code></pre> <p>The example application is composed of the following parts:</p> <ul> <li>2 services, backed by Docker images: <code>webapp</code> and <code>database</code></li> <li>1 secret (HTTPS certificate), injected into the frontend</li> <li>1 configuration (HTTP), injected into the frontend</li> <li>1 persistent volume, attached to the backend</li> <li>2 networks</li> </ul> <pre><code>services:\n  frontend:\n    image: example/webapp\n    ports:\n      - \"443:8043\"\n    networks:\n      - front-tier\n      - back-tier\n    configs:\n      - httpd-config\n    secrets:\n      - server-certificate\n\n  backend:\n    image: example/database\n    volumes:\n      - db-data:/etc/data\n    networks:\n      - back-tier\n\nvolumes:\n  db-data:\n    driver: flocker\n    driver_opts:\n      size: \"10GiB\"\n\nconfigs:\n  httpd-config:\n    external: true\n\nsecrets:\n  server-certificate:\n    external: true\n\nnetworks:\n  ## The presence of these objects is sufficient to define them\n  front-tier: {}\n  back-tier: {}\n</code></pre> <p>This example illustrates the distinction between volumes, configs and secrets. While all of them are all exposed to service containers as mounted files or directories, only a volume can be configured for read+write access. Secrets and configs are read-only. The volume configuration allows you to select a volume driver and pass driver options to tweak volume management according to the actual infrastructure. Configs and secrets rely on platform services, and are declared <code>external</code> as they are not managed as part of the application lifecycle. Compose uses a platform-specific lookup mechanism to retrieve runtime values.</p>"},{"location":"docker/#compose-file","title":"Compose file","text":"<p>The Compose file is a YAML file defining: - Version (Optional) - Services (Required) - Networks - Volumes - Configs  - Secrets</p> <p>The default path for a Compose file is <code>compose.yaml</code> (preferred) or <code>compose.yml</code> that is placed in the working directory. Compose also supports <code>docker-compose.yaml</code> and <code>docker-compose.yml</code> for backwards compatibility of earlier versions. If both files exist, Compose prefers the canonical <code>compose.yaml</code>.</p> <p>You can use fragments and extensions to keep your Compose file efficient and easy to maintain.</p> <p>Multiple Compose files can be merged together to define the application model. The combination of YAML files are implemented by appending or overriding YAML elements based on the Compose file order you set.  Simple attributes and maps get overridden by the highest order Compose file, lists get merged by appending. Relative paths are resolved based on the first Compose file's parent folder, whenever complimentary files being merged are hosted in other folders. As some Compose file elements can both be expressed as single strings or complex objects, merges apply to the expanded form.</p> <p>If you want to reuse other Compose files, or factor out parts of you application model into separate Compose files, you can also use <code>include</code>. This is useful if your Compose application is dependent on another application which is managed by a different team, or needs to be shared with others.</p>"},{"location":"docker/#version-and-name-top-level-elements","title":"Version and name top-level elements","text":""},{"location":"docker/#version-top-level-element","title":"Version top-level element","text":"<p>The top-level <code>version</code> property is defined by the Compose Specification for backward compatibility. It is only informative.</p> <p>Compose doesn't use <code>version</code> to select an exact schema to validate the Compose file, but prefers the most recent schema when it's implemented.</p> <p>Compose validates whether it can fully parse the Compose file. If some fields are unknown, typically because the Compose file was written with fields defined by a newer version of the Specification, you'll receive a warning message. Compose offers options to ignore unknown fields (as defined by \"loose\" mode).</p>"},{"location":"docker/#name-top-level-element","title":"Name top-level element","text":"<p>The top-level <code>name</code> property is defined by the Specification as the project name to be used if you don't set one explicitly. Compose offers a way for you to override this name, and sets a default project name to be used if the top-level <code>name</code> element is not set.</p> <p>Whenever a project name is defined by top-level <code>name</code> or by some custom mechanism, it is exposed for interpolation and environment variable resolution as <code>COMPOSE_PROJECT_NAME</code></p> <pre><code>services:\n  foo:\n    image: busybox\n    environment:\n      - COMPOSE_PROJECT_NAME\n    command: echo \"I'm running ${COMPOSE_PROJECT_NAME}\"\n</code></pre>"},{"location":"docker/#services-top-level-element","title":"Services top-level element","text":"<p>A service is an abstract definition of a computing resource within an application which can be scaled or replaced independently from other components. Services are backed by a set of containers, run by the platform according to replication requirements and placement constraints. As services are backed by containers, they are defined by a Docker image and set of runtime arguments. All containers within a service are identically created with these arguments.</p> <p>A Compose file must declare a <code>services</code> top-level element as a map whose keys are string representations of service names, and whose values are service definitions. A service  definition contains the configuration that is applied to each service container.</p> <p>Each service may also include a <code>build</code> section, which defines how to create the Docker image for the service. Compose supports building docker images using this service definition. If not used, the <code>build</code> section is ignored and the Compose file is still considered valid. Build support is an optional aspect of the Compose Specification, and is described in detail in the Compose Build Specification documentation.</p> <p>Each service defines runtime constraints and requirements to run its containers. The <code>deploy</code> section groups these constraints and allows the platform to adjust the deployment strategy to best match containers' needs with available resources. Deploy support is an optional aspect of the Compose Specification, and is described in detail in the Compose Deploy Specification documentation. If not implemented the <code>deploy</code> section is ignored and the Compose file is still considered valid.</p>"},{"location":"docker/#attach","title":"attach","text":"<p>When <code>attach</code> is defined and set to <code>false</code> Compose does not collect service logs, until you explicitly request it to.</p> <p>The default service configuration is <code>attach: true</code>.</p>"},{"location":"docker/#build","title":"build","text":"<p><code>build</code> specifies the build configuration for creating a container image from source, as defined in the Compose Build Specification.</p>"},{"location":"docker/#blkio_config","title":"blkio_config","text":"<p><code>blkio_config</code> defines a set of configuration options to set block IO limits for a service.</p> <pre><code>services:\n  foo:\n    image: busybox\n    blkio_config:\n       weight: 300\n       weight_device:\n         - path: /dev/sda\n           weight: 400\n       device_read_bps:\n         - path: /dev/sdb\n           rate: '12mb'\n       device_read_iops:\n         - path: /dev/sdb\n           rate: 120\n       device_write_bps:\n         - path: /dev/sdb\n           rate: '1024k'\n       device_write_iops:\n         - path: /dev/sdb\n           rate: 30\n</code></pre>"},{"location":"docker/#device_read_bps-device_write_bps","title":"device_read_bps, device_write_bps","text":"<p>Set a limit in bytes per second for read / write operations on a given device. Each item in the list must have two keys:</p> <ul> <li><code>path</code>: Defines the symbolic path to the affected device.</li> <li><code>rate</code>: Either as an integer value representing the number of bytes or as a string expressing a byte value.</li> </ul>"},{"location":"docker/#device_read_iops-device_write_iops","title":"device_read_iops, device_write_iops","text":"<p>Set a limit in operations per second for read / write operations on a given device. Each item in the list must have two keys:</p> <ul> <li><code>path</code>: Defines the symbolic path to the affected device.</li> <li><code>rate</code>: As an integer value representing the permitted number of operations per second.</li> </ul>"},{"location":"docker/#weight","title":"weight","text":"<p>Modify the proportion of bandwidth allocated to a service relative to other services. Takes an integer value between 10 and 1000, with 500 being the default.</p>"},{"location":"docker/#weight_device","title":"weight_device","text":"<p>Fine-tune bandwidth allocation by device. Each item in the list must have two keys:</p> <ul> <li><code>path</code>: Defines the symbolic path to the affected device.</li> <li><code>weight</code>: An integer value between 10 and 1000.</li> </ul>"},{"location":"docker/#cpu_count","title":"cpu_count","text":"<p><code>cpu_count</code> defines the number of usable CPUs for service container.</p>"},{"location":"docker/#cpu_percent","title":"cpu_percent","text":"<p><code>cpu_percent</code> defines the usable percentage of the available CPUs.</p>"},{"location":"docker/#cpu_shares","title":"cpu_shares","text":"<p><code>cpu_shares</code> defines, as integer value, a service container's relative CPU weight versus other containers.</p>"},{"location":"docker/#cpu_period","title":"cpu_period","text":"<p><code>cpu_period</code> configures CPU CFS (Completely Fair Scheduler) period when a platform is based on Linux kernel.</p>"},{"location":"docker/#cpu_quota","title":"cpu_quota","text":"<p><code>cpu_quota</code> configures CPU CFS (Completely Fair Scheduler) quota when a platform is based on Linux kernel.</p>"},{"location":"docker/#cpu_rt_runtime","title":"cpu_rt_runtime","text":"<p><code>cpu_rt_runtime</code> configures CPU allocation parameters for platforms with support for realtime scheduler. It can be either an integer value using microseconds as unit or a duration.</p> <pre><code> cpu_rt_runtime: '400ms'\n cpu_rt_runtime: 95000`\n</code></pre>"},{"location":"docker/#cpu_rt_period","title":"cpu_rt_period","text":"<p><code>cpu_rt_period</code> configures CPU allocation parameters for platforms with support for realtime scheduler. It can be either an integer value using microseconds as unit or a duration.</p> <pre><code> cpu_rt_period: '1400us'\n cpu_rt_period: 11000`\n</code></pre>"},{"location":"docker/#cpus","title":"cpus","text":"<p>DEPRECATED: use deploy.limits.cpus</p> <p><code>cpus</code> define the number of (potentially virtual) CPUs to allocate to service containers. This is a fractional number. <code>0.000</code> means no limit.</p>"},{"location":"docker/#cpuset","title":"cpuset","text":"<p><code>cpuset</code> defines the explicit CPUs in which to allow execution. Can be a range <code>0-3</code> or a list <code>0,1</code></p>"},{"location":"docker/#cap_add","title":"cap_add","text":"<p><code>cap_add</code> specifies additional container capabilities as strings.</p> <pre><code>cap_add:\n  - ALL\n</code></pre>"},{"location":"docker/#cap_drop","title":"cap_drop","text":"<p><code>cap_drop</code> specifies container capabilities to drop as strings.</p> <pre><code>cap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n</code></pre>"},{"location":"docker/#cgroup","title":"cgroup","text":"<p><code>cgroup</code> specifies the cgroup namespace to join. When unset, it is the container runtime's decision to select which cgroup namespace to use, if supported.</p> <ul> <li><code>host</code>: Runs the container in the Container runtime cgroup namespace.</li> <li><code>private</code>: Runs the container in its own private cgroup namespace.</li> </ul>"},{"location":"docker/#cgroup_parent","title":"cgroup_parent","text":"<p><code>cgroup_parent</code> specifies an optional parent cgroup for the container.</p> <pre><code>cgroup_parent: m-executor-abcd\n</code></pre>"},{"location":"docker/#command","title":"command","text":"<p><code>command</code> overrides the default command declared by the container image, for example by Dockerfile's <code>CMD</code>.</p> <pre><code>command: bundle exec thin -p 3000\n</code></pre> <p>The value can also be a list, in a manner similar to Dockerfile:</p> <pre><code>command: [ \"bundle\", \"exec\", \"thin\", \"-p\", \"3000\" ]\n</code></pre> <p>If the value is <code>null</code>, the default command from the image is used.</p> <p>If the value is <code>[]</code> (empty list) or <code>''</code> (empty string), the default command declared by the image is ignored, i.e. overridden to be empty.</p>"},{"location":"docker/#configs","title":"configs","text":"<p>Configs allow services to adapt their behaviour without the need to rebuild a Docker image.  Services can only access configs when explicitly granted by the <code>configs</code> attribute. Two different syntax variants are supported.</p> <p>Compose reports an error if <code>config</code> doesn't exist on the platform or isn't defined in the <code>configs</code> top-level element in the Compose file.</p> <p>There are two syntaxes defined for configs. To remain compliant to this specification, an implementation must support both syntaxes. Implementations must allow use of both short and long syntaxes within the same document.</p> <p>You can grant a service access to multiple configs, and you can mix long and short syntax.</p>"},{"location":"docker/#short-syntax","title":"Short syntax","text":"<p>The short syntax variant only specifies the config name. This grants the container access to the config and mounts it as files into a service\u2019s container\u2019s filesystem. The location of the mount point within the container defaults to <code>/&lt;config_name&gt;</code> in Linux containers, and <code>C:\\&lt;config-name&gt;</code> in Windows containers. </p> <p>The following example uses the short syntax to grant the <code>redis</code> service access to the <code>my_config</code> and <code>my_other_config</code> configs. The value of <code>my_config</code> is set to the contents of the file <code>./my_config.txt</code>, and <code>my_other_config</code> is defined as an external resource, which means that it has already been defined in the platform. If the external config does not exist, the deployment fails.</p> <pre><code>services:\n  redis:\n    image: redis:latest\n    configs:\n      - my_config\n      - my_other_config\nconfigs:\n  my_config:\n    file: ./my_config.txt\n  my_other_config:\n    external: true\n</code></pre>"},{"location":"docker/#long-syntax","title":"Long syntax","text":"<p>The long syntax provides more granularity in how the config is created within the service's task containers.</p> <ul> <li><code>source</code>: The name of the config as it exists in the platform.</li> <li><code>target</code>: The path and name of the file to be mounted in the service's   task containers. Defaults to <code>/&lt;source&gt;</code> if not specified.</li> <li><code>uid</code> and <code>gid</code>: The numeric UID or GID that owns the mounted config file   within the service's task containers. Default value when not specified is USER running container.</li> <li><code>mode</code>: The permissions for the file that is mounted within the service's   task containers, in octal notation. Default value is world-readable (<code>0444</code>).   Writable bit must be ignored. The executable bit can be set.</li> </ul> <p>The following example sets the name of <code>my_config</code> to <code>redis_config</code> within the container, sets the mode to <code>0440</code> (group-readable) and sets the user and group to <code>103</code>. The <code>redis</code> service does not have access to the <code>my_other_config</code> config.</p> <pre><code>services:\n  redis:\n    image: redis:latest\n    configs:\n      - source: my_config\n        target: /redis_config\n        uid: \"103\"\n        gid: \"103\"\n        mode: 0440\nconfigs:\n  my_config:\n    external: true\n  my_other_config:\n    external: true\n</code></pre>"},{"location":"docker/#container_name","title":"container_name","text":"<p><code>container_name</code> is a string that specifies a custom container name, rather than a name generated by default.</p> <pre><code>container_name: my-web-container\n</code></pre> <p>Compose does not scale a service beyond one container if the Compose file specifies a <code>container_name</code>. Attempting to do so results in an error.</p> <p><code>container_name</code> follows the regex format of <code>[a-zA-Z0-9][a-zA-Z0-9_.-]+</code></p>"},{"location":"docker/#credential_spec","title":"credential_spec","text":"<p><code>credential_spec</code> configures the credential spec for a managed service account.</p> <p>If you have services that use Windows containers, you can use <code>file:</code> and <code>registry:</code> protocols for <code>credential_spec</code>. Compose also supports additional protocols for custom use-cases.</p> <p>The <code>credential_spec</code> must be in the format <code>file://&lt;filename&gt;</code> or <code>registry://&lt;value-name&gt;</code>.</p> <pre><code>credential_spec:\n  file: my-credential-spec.json\n</code></pre> <p>When using <code>registry:</code>, the credential spec is read from the Windows registry on the daemon's host. A registry value with the given name must be located in:</p> <pre><code>HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs\n</code></pre> <p>The following example loads the credential spec from a value named <code>my-credential-spec</code> in the registry:</p> <pre><code>credential_spec:\n  registry: my-credential-spec\n</code></pre>"},{"location":"docker/#example-gmsa-configuration","title":"Example gMSA configuration","text":"<p>When configuring a gMSA credential spec for a service, you only need to specify a credential spec with <code>config</code>, as shown in the following example:</p> <pre><code>services:\n  myservice:\n    image: myimage:latest\n    credential_spec:\n      config: my_credential_spec\n\nconfigs:\n  my_credentials_spec:\n    file: ./my-credential-spec.json|\n</code></pre>"},{"location":"docker/#depends_on","title":"depends_on","text":"<p><code>depends_on</code> expresses startup and shutdown dependencies between services.</p>"},{"location":"docker/#short-syntax_1","title":"Short syntax","text":"<p>The short syntax variant only specifies service names of the dependencies. Service dependencies cause the following behaviors:</p> <ul> <li> <p>Compose creates services in dependency order. In the following   example, <code>db</code> and <code>redis</code> are created before <code>web</code>.</p> </li> <li> <p>Compose removes services in dependency order. In the following   example, <code>web</code> is removed before <code>db</code> and <code>redis</code>.</p> </li> </ul> <p>Simple example:</p> <pre><code>services:\n  web:\n    build: .\n    depends_on:\n      - db\n      - redis\n  redis:\n    image: redis\n  db:\n    image: postgres\n</code></pre> <p>Compose guarantees dependency services have been started before starting a dependent service. Compose waits for dependency services to be \"ready\" before starting a dependent service.</p>"},{"location":"docker/#long-syntax_1","title":"Long syntax","text":"<p>The long form syntax enables the configuration of additional fields that can't be expressed in the short form.</p> <ul> <li> <p><code>restart</code>: When set to <code>true</code> Compose restarts this service after it updates the dependency service.   This applies to an explicit restart controlled by a Compose operation, and excludes automated restart by the container runtime   after the container dies.</p> </li> <li> <p><code>condition</code>: Sets the condition under which dependency is considered satisfied</p> </li> <li><code>service_started</code>: An equivalent of the short syntax described above</li> <li><code>service_healthy</code>: Specifies that a dependency is expected to be \"healthy\"     (as indicated by healthcheck) before starting a dependent     service.</li> <li><code>service_completed_successfully</code>: Specifies that a dependency is expected to run     to successful completion before starting a dependent service.</li> <li><code>required</code>: When set to <code>false</code> Compose only warns you when the dependency service isn't started or available. If it's not defined     the default value of <code>required</code> is <code>true</code>.</li> </ul> <p>Service dependencies cause the following behaviors:</p> <ul> <li> <p>Compose creates services in dependency order. In the following   example, <code>db</code> and <code>redis</code> are created before <code>web</code>.</p> </li> <li> <p>Compose waits for healthchecks to pass on dependencies   marked with <code>service_healthy</code>. In the following example, <code>db</code> is expected to   be \"healthy\" before <code>web</code> is created.</p> </li> <li> <p>Compose removes services in dependency order. In the following   example, <code>web</code> is removed before <code>db</code> and <code>redis</code>.</p> </li> </ul> <pre><code>services:\n  web:\n    build: .\n    depends_on:\n      db:\n        condition: service_healthy\n        restart: true\n      redis:\n        condition: service_started\n  redis:\n    image: redis\n  db:\n    image: postgres\n</code></pre> <p>Compose guarantees dependency services are started before starting a dependent service. Compose guarantees dependency services marked with <code>service_healthy</code> are \"healthy\" before starting a dependent service.</p>"},{"location":"docker/#deploy","title":"deploy","text":"<p><code>deploy</code> specifies the configuration for the deployment and lifecycle of services, as defined in the Compose Deploy Specification.</p>"},{"location":"docker/#develop","title":"develop","text":"<p><code>develop</code> specifies the development configuration for maintaining a container in sync with source, as defined in the Development Section.</p>"},{"location":"docker/#device_cgroup_rules","title":"device_cgroup_rules","text":"<p><code>device_cgroup_rules</code> defines a list of device cgroup rules for this container. The format is the same format the Linux kernel specifies in the Control Groups Device Whitelist Controller.</p> <pre><code>device_cgroup_rules:\n  - 'c 1:3 mr'\n  - 'a 7:* rmw'\n</code></pre>"},{"location":"docker/#devices","title":"devices","text":"<p><code>devices</code> defines a list of device mappings for created containers in the form of <code>HOST_PATH:CONTAINER_PATH[:CGROUP_PERMISSIONS]</code>.</p> <pre><code>devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n  - \"/dev/sda:/dev/xvda:rwm\"\n</code></pre>"},{"location":"docker/#dns","title":"dns","text":"<p><code>dns</code> defines custom DNS servers to set on the container network interface configuration. It can be a single value or a list.</p> <pre><code>dns: 8.8.8.8\n</code></pre> <pre><code>dns:\n  - 8.8.8.8\n  - 9.9.9.9\n</code></pre>"},{"location":"docker/#dns_opt","title":"dns_opt","text":"<p><code>dns_opt</code> list custom DNS options to be passed to the container\u2019s DNS resolver (<code>/etc/resolv.conf</code> file on Linux).</p> <pre><code>dns_opt:\n  - use-vc\n  - no-tld-query\n</code></pre>"},{"location":"docker/#dns_search","title":"dns_search","text":"<p><code>dns_search</code> defines custom DNS search domains to set on container network interface configuration. It can be a single value or a list.</p> <pre><code>dns_search: example.com\n</code></pre> <pre><code>dns_search:\n  - dc1.example.com\n  - dc2.example.com\n</code></pre>"},{"location":"docker/#domainname","title":"domainname","text":"<p><code>domainname</code> declares a custom domain name to use for the service container. It must be a valid RFC 1123 hostname.</p>"},{"location":"docker/#entrypoint","title":"entrypoint","text":"<p><code>entrypoint</code> declares the default entrypoint for the service container. This overrides the <code>ENTRYPOINT</code> instruction from the service's Dockerfile.</p> <p>If <code>entrypoint</code> is non-null, Compose ignores any default command from the image, for example the <code>CMD</code> instruction in the Dockerfile.</p> <p>See also <code>command</code> to set or override the default command to be executed by the entrypoint process.</p> <p>In its short form, the value can be defined as a string:</p> <pre><code>entrypoint: /code/entrypoint.sh\n</code></pre> <p>Alternatively, the value can also be a list, in a manner similar to the Dockerfile:</p> <pre><code>entrypoint:\n  - php\n  - -d\n  - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so\n  - -d\n  - memory_limit=-1\n  - vendor/bin/phpunit\n</code></pre> <p>If the value is <code>null</code>, the default entrypoint from the image is used.</p> <p>If the value is <code>[]</code> (empty list) or <code>''</code> (empty string), the default entrypoint declared by the image is ignored, i.e. overridden to be empty.</p>"},{"location":"docker/#env_file","title":"env_file","text":"<p><code>env_file</code> adds environment variables to the container based on the file content.</p> <pre><code>env_file: .env\n</code></pre> <p><code>env_file</code> can also be a list. The files in the list are processed from the top down. For the same variable specified in two env files, the value from the last file in the list stands.</p> <pre><code>env_file:\n  - ./a.env\n  - ./b.env\n</code></pre> <p>List elements can also be declared as a mapping, which then lets you set an additional attribute <code>required</code>. This defaults to <code>true</code>. When <code>required</code> is set to <code>false</code> and the <code>.env</code> file is missing, Compose silently ignores the entry.</p> <pre><code>env_file:\n  - path: ./default.env\n    required: true ## default\n  - path: ./override.env\n    required: false\n</code></pre> <p>Relative path are resolved from the Compose file's parent folder. As absolute paths prevent the Compose file from being portable, Compose warns you when such a path is used to set <code>env_file</code>.</p> <p>Environment variables declared in the environment section override these values. This holds true even if those values are empty or undefined.</p>"},{"location":"docker/#env_file-format","title":"Env_file format","text":"<p>Each line in an <code>.env</code> file must be in <code>VAR[=[VAL]]</code> format. The following syntax rules apply:</p> <ul> <li>Lines beginning with <code>#</code> are processed as comments and ignored.</li> <li>Blank lines are ignored.</li> <li>Unquoted and double-quoted (<code>\"</code>) values have Interpolation applied.</li> <li>Each line represents a key-value pair. Values can optionally be quoted.</li> <li><code>VAR=VAL</code> -&gt; <code>VAL</code></li> <li><code>VAR=\"VAL\"</code> -&gt; <code>VAL</code></li> <li><code>VAR='VAL'</code> -&gt; <code>VAL</code></li> <li>Inline comments for unquoted values must be preceded with a space.</li> <li><code>VAR=VAL ## comment</code> -&gt; <code>VAL</code></li> <li><code>VAR=VAL## not a comment</code> -&gt; <code>VAL## not a comment</code></li> <li>Inline comments for quoted values must follow the closing quote.</li> <li><code>VAR=\"VAL ## not a comment\"</code> -&gt; <code>VAL ## not a comment</code></li> <li><code>VAR=\"VAL\" ## comment</code> -&gt; <code>VAL</code></li> <li>Single-quoted (<code>'</code>) values are used literally.</li> <li><code>VAR='$OTHER'</code> -&gt; <code>$OTHER</code></li> <li><code>VAR='${OTHER}'</code> -&gt; <code>${OTHER}</code></li> <li>Quotes can be escaped with <code>\\</code>.</li> <li><code>VAR='Let\\'s go!'</code> -&gt; <code>Let's go!</code></li> <li><code>VAR=\"{\\\"hello\\\": \\\"json\\\"}\"</code> -&gt; <code>{\"hello\": \"json\"}</code></li> <li>Common shell escape sequences including <code>\\n</code>, <code>\\r</code>, <code>\\t</code>, and <code>\\\\</code> are supported in double-quoted values.</li> <li><code>VAR=\"some\\tvalue\"</code> -&gt; <code>some  value</code></li> <li><code>VAR='some\\tvalue'</code> -&gt; <code>some\\tvalue</code></li> <li><code>VAR=some\\tvalue</code> -&gt; <code>some\\tvalue</code></li> </ul> <p><code>VAL</code> may be omitted, in such cases the variable value is an empty string. <code>=VAL</code> may be omitted, in such cases the variable is unset.</p> <pre><code>## Set Rails/Rack environment\nRACK_ENV=development\nVAR=\"quoted\"\n</code></pre>"},{"location":"docker/#environment","title":"environment","text":"<p><code>environment</code> defines environment variables set in the container. <code>environment</code> can use either an array or a map. Any boolean values; true, false, yes, no, should be enclosed in quotes to ensure they are not converted to True or False by the YAML parser.</p> <p>Environment variables can be declared by a single key (no value to equals sign). In this case Compose relies on you to resolve the value. If the value is not resolved, the variable is unset and is removed from the service container environment.</p> <p>Map syntax:</p> <pre><code>environment:\n  RACK_ENV: development\n  SHOW: \"true\"\n  USER_INPUT:\n</code></pre> <p>Array syntax:</p> <pre><code>environment:\n  - RACK_ENV=development\n  - SHOW=true\n  - USER_INPUT\n</code></pre> <p>When both <code>env_file</code> and <code>environment</code> are set for a service, values set by <code>environment</code> have precedence.</p>"},{"location":"docker/#expose","title":"expose","text":"<p><code>expose</code> defines the (incoming) port or a range of ports that Compose exposes from the container. These ports must be accessible to linked services and should not be published to the host machine. Only the internal container ports can be specified.</p> <p>Syntax is <code>&lt;portnum&gt;/[&lt;proto&gt;]</code> or <code>&lt;startport-endport&gt;/[&lt;proto&gt;]</code> for a port range. When not explicitly set, <code>tcp</code> protocol is used.</p> <pre><code>expose:\n  - \"3000\"\n  - \"8000\"\n  - \"8080-8085/tcp\n</code></pre> <p>Note</p> <p>If the Dockerfile for the image already exposes ports, it is visible to other containers on the network even if <code>expose</code> is not set in your Compose file. </p>"},{"location":"docker/#extends","title":"extends","text":"<p><code>extends</code> lets you share common configurations among different files, or even different projects entirely. With <code>extends</code> you can define a common set of service options in one place and refer to it from anywhere. You can refer to another Compose file and select a service you want to also use in your own application, with the ability to override some attributes for your own needs.</p> <p>You can use <code>extends</code> on any service together with other configuration keys. The <code>extends</code> value must be a mapping defined with a required <code>service</code> and an optional <code>file</code> key.</p> <pre><code>extends:\n  file: common.yml\n  service: webapp\n</code></pre> <ul> <li><code>service</code>: Defines the name of the service being referenced as a base, for example <code>web</code> or <code>database</code>.</li> <li><code>file</code>: The location of a Compose configuration file defining that service.</li> </ul>"},{"location":"docker/#restrictions","title":"Restrictions","text":"<p>The following restrictions apply to the service being referenced:</p> <ul> <li>Services that have dependencies on other services cannot be used as a base. Therefore, any key   that introduces a dependency on another service is incompatible with <code>extends</code>. The   non-exhaustive list of such keys is: <code>links</code>, <code>volumes_from</code>, <code>container</code> mode (in <code>ipc</code>, <code>pid</code>,   <code>network_mode</code> and <code>net</code>), <code>service</code> mode (in <code>ipc</code>, <code>pid</code> and <code>network_mode</code>), <code>depends_on</code>.</li> <li>Services cannot have circular references with <code>extends</code>.</li> </ul> <p>Compose returns an error in all of these cases.</p>"},{"location":"docker/#finding-referenced-service","title":"Finding referenced service","text":"<p><code>file</code> value can be:</p> <ul> <li>Not present.   This indicates that another service within the same Compose file is being referenced.</li> <li>File path, which can be either:</li> <li>Relative path. This path is considered as relative to the location of the main Compose     file.</li> <li>Absolute path.</li> </ul> <p>A service denoted by <code>service</code> must be present in the identified referenced Compose file. Compose returns an error if:</p> <ul> <li>The service denoted by <code>service</code> is not found.</li> <li>The Compose file denoted by <code>file</code> is not found.</li> </ul>"},{"location":"docker/#merging-service-definitions","title":"Merging service definitions","text":"<p>Two service definitions, the main one in the current Compose file and the referenced one specified by <code>extends</code>, are merged in the following way:</p> <ul> <li>Mappings: Keys in mappings of the main service definition override keys in mappings   of the referenced service definition. Keys that aren't overridden are included as is.</li> <li>Sequences: Items are combined together into a new sequence. The order of elements is   preserved with the referenced items coming first and main items after.</li> <li>Scalars: Keys in the main service definition take precedence over keys in the   referenced one.</li> </ul>"},{"location":"docker/#mappings","title":"Mappings","text":"<p>The following keys should be treated as mappings: <code>annotations</code>, <code>build.args</code>, <code>build.labels</code>, <code>build.extra_hosts</code>, <code>deploy.labels</code>, <code>deploy.update_config</code>, <code>deploy.rollback_config</code>, <code>deploy.restart_policy</code>, <code>deploy.resources.limits</code>, <code>environment</code>, <code>healthcheck</code>, <code>labels</code>, <code>logging.options</code>, <code>sysctls</code>, <code>storage_opt</code>, <code>extra_hosts</code>, <code>ulimits</code>.</p> <p>One exception that applies to <code>healthcheck</code> is that the main mapping cannot specify <code>disable: true</code> unless the  referenced mapping also specifies <code>disable: true</code>. Compose returns an error in this case.</p> <p>For example, the input below:</p> <pre><code>services:\n  common:\n    image: busybox\n    environment:\n      TZ: utc\n      PORT: 80\n  cli:\n    extends:\n      service: common\n    environment:\n      PORT: 8080\n</code></pre> <p>Produces the following configuration for the <code>cli</code> service. The same output is produced if array syntax is used.</p> <pre><code>environment:\n  PORT: 8080\n  TZ: utc\nimage: busybox\n</code></pre> <p>Items under <code>blkio_config.device_read_bps</code>, <code>blkio_config.device_read_iops</code>, <code>blkio_config.device_write_bps</code>, <code>blkio_config.device_write_iops</code>, <code>devices</code> and <code>volumes</code> are also treated as mappings where key is the target path inside the container.</p> <p>For example, the input below:</p> <pre><code>services:\n  common:\n    image: busybox\n    volumes:\n      - common-volume:/var/lib/backup/data:rw\n  cli:\n    extends:\n      service: common\n    volumes:\n      - cli-volume:/var/lib/backup/data:ro\n</code></pre> <p>Produces the following configuration for the <code>cli</code> service. Note that the mounted path now points to the new volume name and <code>ro</code> flag was applied.</p> <pre><code>image: busybox\nvolumes:\n- cli-volume:/var/lib/backup/data:ro\n</code></pre> <p>If the referenced service definition contains <code>extends</code> mapping, the items under it are simply copied into the new merged definition. The merging process is then kicked off again until no <code>extends</code> keys are remaining.</p> <p>For example, the input below:</p> <pre><code>services:\n  base:\n    image: busybox\n    user: root\n  common:\n    image: busybox\n    extends:\n      service: base\n  cli:\n    extends:\n      service: common\n</code></pre> <p>Produces the following configuration for the <code>cli</code> service. Here, <code>cli</code> services gets <code>user</code> key from <code>common</code> service, which in turn gets this key from <code>base</code> service.</p> <pre><code>image: busybox\nuser: root\n</code></pre>"},{"location":"docker/#sequences","title":"Sequences","text":"<p>The following keys should be treated as sequences: <code>cap_add</code>, <code>cap_drop</code>, <code>configs</code>, <code>deploy.placement.constraints</code>, <code>deploy.placement.preferences</code>, <code>deploy.reservations.generic_resources</code>, <code>device_cgroup_rules</code>, <code>expose</code>, <code>external_links</code>, <code>ports</code>, <code>secrets</code>, <code>security_opt</code>. Any duplicates resulting from the merge are removed so that the sequence only contains unique elements.</p> <p>For example, the input below:</p> <pre><code>services:\n  common:\n    image: busybox\n    security_opt:\n      - label:role:ROLE\n  cli:\n    extends:\n      service: common\n    security_opt:\n      - label:user:USER\n</code></pre> <p>Produces the following configuration for the <code>cli</code> service.</p> <pre><code>image: busybox\nsecurity_opt:\n- label:role:ROLE\n- label:user:USER\n</code></pre> <p>In case list syntax is used, the following keys should also be treated as sequences: <code>dns</code>, <code>dns_search</code>, <code>env_file</code>, <code>tmpfs</code>. Unlike sequence fields mentioned above, duplicates resulting from the merge are not removed.</p>"},{"location":"docker/#scalars","title":"Scalars","text":"<p>Any other allowed keys in the service definition should be treated as scalars.</p>"},{"location":"docker/#annotations","title":"annotations","text":"<p><code>annotations</code> defines annotations for the container. <code>annotations</code> can use either an array or a map.</p> <pre><code>annotations:\n  com.example.foo: bar\n</code></pre> <pre><code>annotations:\n  - com.example.foo=bar\n</code></pre>"},{"location":"docker/#external_links","title":"external_links","text":"<p><code>external_links</code> link service containers to services managed outside of your Compose application. <code>external_links</code> define the name of an existing service to retrieve using the platform lookup mechanism. An alias of the form <code>SERVICE:ALIAS</code> can be specified.</p> <pre><code>external_links:\n  - redis\n  - database:mysql\n  - database:postgresql\n</code></pre>"},{"location":"docker/#extra_hosts","title":"extra_hosts","text":"<p><code>extra_hosts</code> adds hostname mappings to the container network interface configuration (<code>/etc/hosts</code> for Linux).</p>"},{"location":"docker/#short-syntax_2","title":"Short syntax","text":"<p>Short syntax uses plain strings in a list. Values must set hostname and IP address for additional hosts in the form of <code>HOSTNAME=IP</code>.</p> <pre><code>extra_hosts:\n  - \"somehost=162.242.195.82\"\n  - \"otherhost=50.31.209.229\"\n  - \"myhostv6=::1\"\n</code></pre> <p>IPv6 addresses can be enclosed in square brackets, for example:</p> <pre><code>extra_hosts:\n  - \"myhostv6=[::1]\"\n</code></pre> <p>The separator <code>=</code> is preferred, but <code>:</code> can also be used. For example:</p> <pre><code>extra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"myhostv6:::1\"\n</code></pre>"},{"location":"docker/#long-syntax_2","title":"Long syntax","text":"<p>Alternatively, <code>extra_hosts</code> can be set as a mapping between hostname(s) and IP(s)</p> <pre><code>extra_hosts:\n  somehost: \"162.242.195.82\"\n  otherhost: \"50.31.209.229\"\n  myhostv6: \"::1\"\n</code></pre> <p>Compose creates a matching entry with the IP address and hostname in the container's network configuration, which means for Linux <code>/etc/hosts</code> get extra lines:</p> <pre><code>162.242.195.82  somehost\n50.31.209.229   otherhost\n::1             myhostv6\n</code></pre>"},{"location":"docker/#group_add","title":"group_add","text":"<p><code>group_add</code> specifies additional groups, by name or number, which the user inside the container must be a member of.</p> <p>An example of where this is useful is when multiple containers (running as different users) need to all read or write the same file on a shared volume. That file can be owned by a group shared by all the containers, and specified in <code>group_add</code>.</p> <pre><code>services:\n  myservice:\n    image: alpine\n    group_add:\n      - mail\n</code></pre> <p>Running <code>id</code> inside the created container must show that the user belongs to the <code>mail</code> group, which would not have been the case if <code>group_add</code> were not declared.</p>"},{"location":"docker/#healthcheck","title":"healthcheck","text":"<p><code>healthcheck</code> declares a check that's run to determine whether or not the service containers are \"healthy\". It works in the same way, and has the same default values, as the HEALTHCHECK Dockerfile instruction set by the service's Docker image. Your Compose file can override the values set in the Dockerfile. </p> <pre><code>healthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n  interval: 1m30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n  start_interval: 5s\n</code></pre> <p><code>interval</code>, <code>timeout</code>, <code>start_period</code>, and <code>start_interval</code> are specified as durations.</p> <p><code>test</code> defines the command Compose runs to check container health. It can be either a string or a list. If it's a list, the first item must be either <code>NONE</code>, <code>CMD</code> or <code>CMD-SHELL</code>. If it's a string, it's equivalent to specifying <code>CMD-SHELL</code> followed by that string.</p> <pre><code>## Hit the local web app\ntest: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n</code></pre> <p>Using <code>CMD-SHELL</code> runs the command configured as a string using the container's default shell (<code>/bin/sh</code> for Linux). Both forms below are equivalent:</p> <pre><code>test: [\"CMD-SHELL\", \"curl -f http://localhost || exit 1\"]\n</code></pre> <pre><code>test: curl -f https://localhost || exit 1\n</code></pre> <p><code>NONE</code> disables the healthcheck, and is mostly useful to disable the Healthcheck Dockerfile instruction set by the service's Docker image. Alternatively, the healthcheck set by the image can be disabled by setting <code>disable: true</code>:</p> <pre><code>healthcheck:\n  disable: true\n</code></pre>"},{"location":"docker/#hostname","title":"hostname","text":"<p><code>hostname</code> declares a custom host name to use for the service container. It must be a valid RFC 1123 hostname.</p>"},{"location":"docker/#image","title":"image","text":"<p><code>image</code> specifies the image to start the container from. <code>image</code> must follow the Open Container Specification addressable image format, as <code>[&lt;registry&gt;/][&lt;project&gt;/]&lt;image&gt;[:&lt;tag&gt;|@&lt;digest&gt;]</code>.</p> <pre><code>    image: redis\n    image: redis:5\n    image: redis@sha256:0ed5d5928d4737458944eb604cc8509e245c3e19d02ad83935398bc4b991aac7\n    image: library/redis\n    image: docker.io/library/redis\n    image: my_private.registry:5000/redis\n</code></pre> <p>If the image does not exist on the platform, Compose attempts to pull it based on the <code>pull_policy</code>. If you are also using the Compose Build Specification, there are alternative options for controlling the precedence of pull over building the image from source, however pulling the image is the default behavior.</p> <p><code>image</code> may be omitted from a Compose file as long as a <code>build</code> section is declared. If you are not using the Compose Build Specification, Compose won't work if <code>image</code> is missing from the Compose file.</p>"},{"location":"docker/#init","title":"init","text":"<p><code>init</code> runs an init process (PID 1) inside the container that forwards signals and reaps processes. Set this option to <code>true</code> to enable this feature for the service.</p> <pre><code>services:\n  web:\n    image: alpine:latest\n    init: true\n</code></pre> <p>The init binary that is used is platform specific.</p>"},{"location":"docker/#ipc","title":"ipc","text":"<p><code>ipc</code> configures the IPC isolation mode set by the service container. Available values are platform specific, but Compose defines specific values which must be implemented as described if supported:</p> <ul> <li><code>shareable</code>: Gives the container its own private IPC namespace, with a   possibility to share it with other containers.</li> <li><code>service:{name}</code>: Makes the container join another container's   (<code>shareable</code>) IPC namespace.</li> </ul> <pre><code>    ipc: \"shareable\"\n    ipc: \"service:[service name]\"\n</code></pre>"},{"location":"docker/#uts","title":"uts","text":"<p><code>uts</code> configures the UTS namespace mode set for the service container. When unspecified it is the runtime's decision to assign a UTS namespace, if supported. Available values are:</p> <ul> <li><code>'host'</code>: Results in the container using the same UTS namespace as the host.</li> </ul> <pre><code>    uts: \"host\"\n</code></pre>"},{"location":"docker/#isolation","title":"isolation","text":"<p><code>isolation</code> specifies a container\u2019s isolation technology. Supported values are platform specific.</p>"},{"location":"docker/#labels","title":"labels","text":"<p><code>labels</code> add metadata to containers. You can use either an array or a map.</p> <p>It's recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.</p> <pre><code>labels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n</code></pre> <pre><code>labels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n</code></pre> <p>Compose creates containers with canonical labels:</p> <ul> <li><code>com.docker.compose.project</code> set on all resources created by Compose to the user project name</li> <li><code>com.docker.compose.service</code> set on service containers with service name as defined in the Compose file</li> </ul> <p>The <code>com.docker.compose</code> label prefix is reserved. Specifying labels with this prefix in the Compose file results in a runtime error.</p>"},{"location":"docker/#links","title":"links","text":"<p>Note</p> <p>Availability of the <code>links</code> attribute is implementation specific.</p> <p><code>links</code> defines a network link to containers in another service. Either specify both the service name and a link alias (<code>SERVICE:ALIAS</code>), or just the service name.</p> <pre><code>web:\n  links:\n    - db\n    - db:database\n    - redis\n</code></pre> <p>Containers for the linked service are reachable at a hostname identical to the alias, or the service name if no alias is specified.</p> <p>Links are not required to enable services to communicate. When no specific network configuration is set, any service is able to reach any other service at that service\u2019s name on the <code>default</code> network. If services do declare networks they are attached to, <code>links</code> does not override the network configuration and services not attached to a shared network are not be able to communicate. Compose doesn't warn you about a configuration mismatch.</p> <p>Links also express implicit dependency between services in the same way as depends_on, so they determine the order of service startup.</p>"},{"location":"docker/#logging","title":"logging","text":"<p><code>logging</code> defines the logging configuration for the service.</p> <pre><code>logging:\n  driver: syslog\n  options:\n    syslog-address: \"tcp://192.168.0.42:123\"\n</code></pre> <p>The <code>driver</code> name specifies a logging driver for the service's containers. The default and available values are platform specific. Driver specific options can be set with <code>options</code> as key-value pairs.</p>"},{"location":"docker/#network_mode","title":"network_mode","text":"<p><code>network_mode</code> sets a service container's network mode. Available values are platform specific, but Compose defines specific values which must be implemented as described if supported:</p> <ul> <li><code>none</code>: Turns off all container networking.</li> <li><code>host</code>: Gives the container raw access to the host's network interface.</li> <li><code>service:{name}</code>: Gives the containers access to the specified service only.</li> </ul> <pre><code>    network_mode: \"host\"\n    network_mode: \"none\"\n    network_mode: \"service:[service name]\"\n</code></pre> <p>When set, the <code>networks</code> attribute is not allowed and Compose rejects any Compose file containing both attributes.</p>"},{"location":"docker/#networks","title":"networks","text":"<p><code>networks</code> defines the networks that service containers are attached to, referencing entries under the top-level <code>networks</code> key.</p> <pre><code>services:\n  some-service:\n    networks:\n      - some-network\n      - other-network\n</code></pre>"},{"location":"docker/#aliases","title":"aliases","text":"<p><code>aliases</code> declares alternative hostnames for the service on the network. Other containers on the same network can use either the service name or an alias to connect to one of the service's containers.</p> <p>Since <code>aliases</code> are network-scoped, the same service can have different aliases on different networks.</p> <p>Note A network-wide alias can be shared by multiple containers, and even by multiple services. If it is, then exactly which container the name resolves to is not guaranteed.</p> <pre><code>services:\n  some-service:\n    networks:\n      some-network:\n        aliases:\n          - alias1\n          - alias3\n      other-network:\n        aliases:\n          - alias2\n</code></pre> <p>In the following example, service <code>frontend</code> is able to reach the <code>backend</code> service at the hostname <code>backend</code> or <code>database</code> on the <code>back-tier</code> network. The service <code>monitoring</code> is able to reach same <code>backend</code> service at <code>backend</code> or <code>mysql</code> on the <code>admin</code> network.</p> <pre><code>services:\n  frontend:\n    image: example/webapp\n    networks:\n      - front-tier\n      - back-tier\n\n  monitoring:\n    image: example/monitoring\n    networks:\n      - admin\n\n  backend:\n    image: example/backend\n    networks:\n      back-tier:\n        aliases:\n          - database\n      admin:\n        aliases:\n          - mysql\n\nnetworks:\n  front-tier:\n  back-tier:\n  admin:\n</code></pre>"},{"location":"docker/#ipv4_address-ipv6_address","title":"ipv4_address, ipv6_address","text":"<p>Specify a static IP address for a service container when joining the network.</p> <p>The corresponding network configuration in the top-level networks section must have an <code>ipam</code> attribute with subnet configurations covering each static address.</p> <pre><code>services:\n  frontend:\n    image: example/webapp\n    networks:\n      front-tier:\n        ipv4_address: 172.16.238.10\n        ipv6_address: 2001:3984:3989::10\n\nnetworks:\n  front-tier:\n    ipam:\n      driver: default\n      config:\n        - subnet: \"172.16.238.0/24\"\n        - subnet: \"2001:3984:3989::/64\"\n</code></pre>"},{"location":"docker/#link_local_ips","title":"link_local_ips","text":"<p><code>link_local_ips</code> specifies a list of link-local IPs. Link-local IPs are special IPs which belong to a well known subnet and are purely managed by the operator, usually dependent on the architecture where they are deployed. Implementation is platform specific.</p> <p>Example:</p> <pre><code>services:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net:\n        link_local_ips:\n          - 57.123.22.11\n          - 57.123.22.13\nnetworks:\n  app_net:\n    driver: bridge\n</code></pre>"},{"location":"docker/#mac_address","title":"mac_address","text":"<p><code>mac_address</code> sets the MAC address used by the service container when connecting to this particular network.</p>"},{"location":"docker/#priority","title":"priority","text":"<p><code>priority</code> indicates in which order Compose connects the service\u2019s containers to its networks. If unspecified, the default value is 0.</p> <p>In the following example, the app service connects to <code>app_net_1</code> first as it has the highest priority. It then connects to <code>app_net_3</code>, then <code>app_net_2</code>, which uses the default priority value of 0.</p> <pre><code>services:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net_1:\n        priority: 1000\n      app_net_2:\n\n      app_net_3:\n        priority: 100\nnetworks:\n  app_net_1:\n  app_net_2:\n  app_net_3:\n</code></pre>"},{"location":"docker/#mac_address_1","title":"mac_address","text":"<p><code>mac_address</code> sets a MAC address for the service container.</p> <p>Note Container runtimes might reject this value (ie. Docker Engine &gt;= v25.0). In that case, you should use networks.mac_address instead.</p>"},{"location":"docker/#mem_limit","title":"mem_limit","text":"<p>DEPRECATED: use deploy.limits.memory</p>"},{"location":"docker/#mem_reservation","title":"mem_reservation","text":"<p>DEPRECATED: use deploy.reservations.memory</p>"},{"location":"docker/#mem_swappiness","title":"mem_swappiness","text":"<p><code>mem_swappiness</code> defines as a percentage, a value between 0 and 100, for the host kernel to swap out anonymous memory pages used by a container.</p> <ul> <li><code>0</code>: Turns off anonymous page swapping.</li> <li><code>100</code>: Sets all anonymous pages as swappable.</li> </ul> <p>The default value is platform specific.</p>"},{"location":"docker/#memswap_limit","title":"memswap_limit","text":"<p><code>memswap_limit</code> defines the amount of memory the container is allowed to swap to disk. This is a modifier attribute that only has meaning if <code>memory</code> is also set. Using swap lets the container write excess memory requirements to disk when the container has exhausted all the memory that is available to it. There is a performance penalty for applications that swap memory to disk often.</p> <ul> <li>If <code>memswap_limit</code> is set to a positive integer, then both <code>memory</code> and <code>memswap_limit</code> must be set. <code>memswap_limit</code> represents the total amount of memory and swap that can be used, and <code>memory</code> controls the amount used by non-swap memory. So if <code>memory</code>=\"300m\" and <code>memswap_limit</code>=\"1g\", the container can use 300m of memory and 700m (1g - 300m) swap.</li> <li>If <code>memswap_limit</code> is set to 0, the setting is ignored, and the value is treated as unset.</li> <li>If <code>memswap_limit</code> is set to the same value as <code>memory</code>, and <code>memory</code> is set to a positive integer, the container does not have access to swap.</li> <li>If <code>memswap_limit</code> is unset, and <code>memory</code> is set, the container can use as much swap as the <code>memory</code> setting, if the host container has swap memory configured. For instance, if <code>memory</code>=\"300m\" and <code>memswap_limit</code> is not set, the container can use 600m in total of memory and swap.</li> <li>If <code>memswap_limit</code> is explicitly set to -1, the container is allowed to use unlimited swap, up to the amount available on the host system.</li> </ul>"},{"location":"docker/#oom_kill_disable","title":"oom_kill_disable","text":"<p>If <code>oom_kill_disable</code> is set, Compose configures the platform so it won't kill the container in case of memory starvation.</p>"},{"location":"docker/#oom_score_adj","title":"oom_score_adj","text":"<p><code>oom_score_adj</code> tunes the preference for containers to be killed by platform in case of memory starvation. Value must be within [-1000,1000] range.</p>"},{"location":"docker/#pid","title":"pid","text":"<p><code>pid</code> sets the PID mode for container created by Compose. Supported values are platform specific.</p>"},{"location":"docker/#pids_limit","title":"pids_limit","text":"<p>DEPRECATED: use deploy.resources.limits.pids</p> <p><code>pids_limit</code> tunes a container\u2019s PIDs limit. Set to -1 for unlimited PIDs.</p> <pre><code>pids_limit: 10\n</code></pre>"},{"location":"docker/#platform","title":"platform","text":"<p><code>platform</code> defines the target platform the containers for the service run on. It uses the <code>os[/arch[/variant]]</code> syntax.</p> <p>The values of <code>os</code>, <code>arch</code>, and <code>variant</code> must conform to the convention used by the OCI Image Spec.</p> <p>Compose uses this attribute to determine which version of the image is pulled and/or on which platform the service\u2019s build is performed.</p> <pre><code>platform: darwin\nplatform: windows/amd64\nplatform: linux/arm64/v8\n</code></pre>"},{"location":"docker/#ports","title":"ports","text":"<p>Exposes container ports.</p> <p>Note</p> <p>Port mapping must not be used with <code>network_mode: host</code> otherwise a runtime error occurs.</p>"},{"location":"docker/#short-syntax_3","title":"Short syntax","text":"<p>The short syntax is a colon-separated string to set the host IP, host port, and container port in the form:</p> <p><code>[HOST:]CONTAINER[/PROTOCOL]</code> where:</p> <ul> <li><code>HOST</code> is <code>[IP:](port | range)</code></li> <li><code>CONTAINER</code> is <code>port | range</code></li> <li><code>PROTOCOL</code> to restrict port to specified protocol. <code>tcp</code> and <code>udp</code> values are defined by the Specification,   Compose offers support for platform-specific protocol names.</li> </ul> <p>If host IP is not set, it binds to all network interfaces. Ports can be either a single value or a range. Host and container must use equivalent ranges.</p> <p>Either specify both ports (<code>HOST:CONTAINER</code>), or just the container port. In the latter case, the container runtime automatically allocates any unassigned port of the host.</p> <p><code>HOST:CONTAINER</code> should always be specified as a (quoted) string, to avoid conflicts with yaml base-60 float.</p> <p>Examples:</p> <pre><code>ports:\n  - \"3000\"\n  - \"3000-3005\"\n  - \"8000:8000\"\n  - \"9090-9091:8080-8081\"\n  - \"49100:22\"\n  - \"8000-9000:80\"\n  - \"127.0.0.1:8001:8001\"\n  - \"127.0.0.1:5000-5010:5000-5010\"\n  - \"6060:6060/udp\"\n</code></pre> <p>Note</p> <p>If Host IP mapping is not supported by a container engine, Compose rejects the Compose file and ignores the specified host IP.</p>"},{"location":"docker/#long-syntax_3","title":"Long syntax","text":"<p>The long form syntax allows the configuration of additional fields that can't be expressed in the short form.</p> <ul> <li><code>target</code>: The container port</li> <li><code>published</code>: The publicly exposed port. It is defined as a string and can be set as a range using syntax <code>start-end</code>. It means the actual port is assigned a remaining available port, within the set range.</li> <li><code>host_ip</code>: The Host IP mapping, unspecified means all network interfaces (<code>0.0.0.0</code>).</li> <li><code>protocol</code>: The port protocol (<code>tcp</code> or <code>udp</code>). Defaults to <code>tcp</code>.</li> <li><code>mode</code>: <code>host</code>: For publishing a host port on each node, or <code>ingress</code> for a port to be load balanced. Defaults to <code>ingress</code>.</li> <li><code>name</code>: A human-readable name for the port, used to document it's usage within the service</li> </ul> <pre><code>ports:\n  - name: http\n    target: 80\n    host_ip: 127.0.0.1\n    published: \"8080\"\n    protocol: tcp\n    mode: host    \n\n  - name: https\n    target: 443\n    host_ip: 127.0.0.1\n    published: \"8083-9000\"\n    protocol: tcp\n    mode: host\n</code></pre>"},{"location":"docker/#privileged","title":"privileged","text":"<p><code>privileged</code> configures the service container to run with elevated privileges. Support and actual impacts are platform specific.</p>"},{"location":"docker/#profiles","title":"profiles","text":"<p><code>profiles</code> defines a list of named profiles for the service to be enabled under. If unassigned, the service is always started but if assigned, it is only started if the profile is activated.</p> <p>If present, <code>profiles</code> follow the regex format of <code>[a-zA-Z0-9][a-zA-Z0-9_.-]+</code>.</p> <pre><code>services:\n  frontend:\n    image: frontend\n    profiles: [\"frontend\"]\n\n  phpmyadmin:\n    image: phpmyadmin\n    depends_on:\n      - db\n    profiles:\n      - debug\n</code></pre>"},{"location":"docker/#pull_policy","title":"pull_policy","text":"<p><code>pull_policy</code> defines the decisions Compose makes when it starts to pull images. Possible values are:</p> <ul> <li><code>always</code>: Compose always pulls the image from the registry.</li> <li><code>never</code>: Compose doesn't pull the image from a registry and relies on the platform cached image.    If there is no cached image, a failure is reported.</li> <li><code>missing</code>: Compose pulls the image only if it's not available in the platform cache.    This is the default option if you are not also using the Compose Build Specification.   <code>if_not_present</code> is considered an alias for this value for backward compatibility.</li> <li><code>build</code>: Compose builds the image. Compose rebuilds the image if it's already present.</li> </ul>"},{"location":"docker/#read_only","title":"read_only","text":"<p><code>read_only</code> configures the service container to be created with a read-only filesystem.</p>"},{"location":"docker/#restart","title":"restart","text":"<p><code>restart</code> defines the policy that the platform applies on container termination.</p> <ul> <li><code>no</code>: The default restart policy. It does not restart the container under any circumstances.</li> <li><code>always</code>: The policy always restarts the container until its removal.</li> <li><code>on-failure</code>: The policy restarts the container if the exit code indicates an error.</li> <li><code>unless-stopped</code>: The policy restarts the container irrespective of the exit code but stops   restarting when the service is stopped or removed.</li> </ul> <pre><code>    restart: \"no\"\n    restart: always\n    restart: on-failure\n    restart: unless-stopped\n</code></pre>"},{"location":"docker/#runtime","title":"runtime","text":"<p><code>runtime</code> specifies which runtime to use for the service\u2019s containers.</p> <p>The value of <code>runtime</code> is specific to the implementation. For example, <code>runtime</code> can be the name of an implementation of OCI Runtime Spec, such as \"runc\".</p> <pre><code>web:\n  image: busybox:latest\n  command: true\n  runtime: runc\n</code></pre>"},{"location":"docker/#scale","title":"scale","text":"<p><code>scale</code> specifies the default number of containers to deploy for this service. When both are set, <code>scale</code> must be consistent with the <code>replicas</code> attribute in the Deploy Specification.</p>"},{"location":"docker/#secrets","title":"secrets","text":"<p><code>secrets</code> grants access to sensitive data defined by secrets on a per-service basis. Two different syntax variants are supported; the short syntax and the long syntax.</p> <p>Compose reports an error if the secret doesn't exist on the platform or isn't defined in the <code>secrets</code> section of the Compose file.</p> <p>Services can be granted access to multiple secrets. Long and short syntax for secrets may be used in the same Compose file. Defining a secret in the top-level <code>secrets</code> must not imply granting any service access to it. Such grant must be explicit within service specification as secrets service element.</p>"},{"location":"docker/#short-syntax_4","title":"Short syntax","text":"<p>The short syntax variant only specifies the secret name. This grants the container access to the secret and mounts it as read-only to <code>/run/secrets/&lt;secret_name&gt;</code> within the container. The source name and destination mountpoint are both set to the secret name.</p> <p>The following example uses the short syntax to grant the <code>frontend</code> service access to the <code>server-certificate</code> secret. The value of <code>server-certificate</code> is set to the contents of the file <code>./server.cert</code>.</p> <pre><code>services:\n  frontend:\n    image: example/webapp\n    secrets:\n      - server-certificate\nsecrets:\n  server-certificate:\n    file: ./server.cert\n</code></pre>"},{"location":"docker/#long-syntax_4","title":"Long syntax","text":"<p>The long syntax provides more granularity in how the secret is created within the service's containers.</p> <ul> <li><code>source</code>: The name of the secret as it exists on the platform.</li> <li><code>target</code>: The name of the file to be mounted in <code>/run/secrets/</code> in the   service's task container, or absolute path of the file if an alternate location is required. Defaults to <code>source</code> if not specified.</li> <li><code>uid</code> and <code>gid</code>: The numeric UID or GID that owns the file within   <code>/run/secrets/</code> in the service's task containers. Default value is USER running container.</li> <li><code>mode</code>: The permissions for the file to be mounted in <code>/run/secrets/</code>   in the service's task containers, in octal notation.   The default value is world-readable permissions (mode <code>0444</code>).   The writable bit must be ignored if set. The executable bit may be set.</li> </ul> <p>Note that the <code>uid</code>, <code>gid</code>, and <code>mode</code> attributes are implementation specific. </p> <p>The following example sets the name of the <code>server-certificate</code> secret file to <code>server.crt</code> within the container, sets the mode to <code>0440</code> (group-readable), and sets the user and group to <code>103</code>. The value of <code>server-certificate</code> secret is provided by the platform through a lookup and the secret's lifecycle is not directly managed by Compose.</p> <pre><code>services:\n  frontend:\n    image: example/webapp\n    secrets:\n      - source: server-certificate\n        target: server.cert\n        uid: \"103\"\n        gid: \"103\"\n        mode: 0440\nsecrets:\n  server-certificate:\n    external: true\n</code></pre>"},{"location":"docker/#security_opt","title":"security_opt","text":"<p><code>security_opt</code> overrides the default labeling scheme for each container.</p> <pre><code>security_opt:\n  - label:user:USER\n  - label:role:ROLE\n</code></pre> <p>For further default labeling schemes you can override, see Security configuration.</p>"},{"location":"docker/#shm_size","title":"shm_size","text":"<p><code>shm_size</code> configures the size of the shared memory (<code>/dev/shm</code> partition on Linux) allowed by the service container. It's specified as a byte value.</p>"},{"location":"docker/#stdin_open","title":"stdin_open","text":"<p><code>stdin_open</code> configures a service containers to run with an allocated stdin.</p>"},{"location":"docker/#stop_grace_period","title":"stop_grace_period","text":"<p><code>stop_grace_period</code> specifies how long Compose must wait when attempting to stop a container if it doesn't handle SIGTERM (or whichever stop signal has been specified with <code>stop_signal</code>), before sending SIGKILL. It's specified as a duration.</p> <pre><code>    stop_grace_period: 1s\n    stop_grace_period: 1m30s\n</code></pre> <p>Default value is 10 seconds for the container to exit before sending SIGKILL.</p>"},{"location":"docker/#stop_signal","title":"stop_signal","text":"<p><code>stop_signal</code> defines the signal that Compose uses to stop the service containers. If unset containers are stopped by Compose by sending <code>SIGTERM</code>.</p> <pre><code>stop_signal: SIGUSR1\n</code></pre>"},{"location":"docker/#storage_opt","title":"storage_opt","text":"<p><code>storage_opt</code> defines storage driver options for a service.</p> <pre><code>storage_opt:\n  size: '1G'\n</code></pre>"},{"location":"docker/#sysctls","title":"sysctls","text":"<p><code>sysctls</code> defines kernel parameters to set in the container. <code>sysctls</code> can use either an array or a map.</p> <pre><code>sysctls:\n  net.core.somaxconn: 1024\n  net.ipv4.tcp_syncookies: 0\n</code></pre> <pre><code>sysctls:\n  - net.core.somaxconn=1024\n  - net.ipv4.tcp_syncookies=0\n</code></pre> <p>You can only use sysctls that are namespaced in the kernel. Docker does not support changing sysctls inside a container that also modify the host system. For an overview of supported sysctls, refer to configure namespaced kernel parameters (sysctls) at runtime.</p>"},{"location":"docker/#tmpfs","title":"tmpfs","text":"<p><code>tmpfs</code> mounts a temporary file system inside the container. It can be a single value or a list.</p> <pre><code>tmpfs: /run\n</code></pre> <pre><code>tmpfs:\n  - /run\n  - /tmp\n</code></pre>"},{"location":"docker/#tty","title":"tty","text":"<p><code>tty</code> configures service container to run with a TTY.</p>"},{"location":"docker/#ulimits","title":"ulimits","text":"<p><code>ulimits</code> overrides the default ulimits for a container. It's specified either as an integer for a single limit or as mapping for soft/hard limits.</p> <pre><code>ulimits:\n  nproc: 65535\n  nofile:\n    soft: 20000\n    hard: 40000\n</code></pre>"},{"location":"docker/#user","title":"user","text":"<p><code>user</code> overrides the user used to run the container process. The default is set by the image (i.e. Dockerfile <code>USER</code>). If it's not set, then <code>root</code>.</p>"},{"location":"docker/#userns_mode","title":"userns_mode","text":"<p><code>userns_mode</code> sets the user namespace for the service. Supported values are platform specific and may depend on platform configuration.</p> <pre><code>userns_mode: \"host\"\n</code></pre>"},{"location":"docker/#volumes","title":"volumes","text":"<p><code>volumes</code> define mount host paths or named volumes that are accessible by service containers. You can use <code>volumes</code> to define multiple types of mounts; <code>volume</code>, <code>bind</code>, <code>tmpfs</code>, or <code>npipe</code>. </p> <p>If the mount is a host path and is only used by a single service, it can be declared as part of the service definition. To reuse a volume across multiple services, a named volume must be declared in the top-level <code>volumes</code> key.</p> <p>The following example shows a named volume (<code>db-data</code>) being used by the <code>backend</code> service, and a bind mount defined for a single service.</p> <pre><code>services:\n  backend:\n    image: example/backend\n    volumes:\n      - type: volume\n        source: db-data\n        target: /data\n        volume:\n          nocopy: true\n      - type: bind\n        source: /var/run/postgres/postgres.sock\n        target: /var/run/postgres/postgres.sock\n\nvolumes:\n  db-data:\n</code></pre>"},{"location":"docker/#short-syntax_5","title":"Short syntax","text":"<p>The short syntax uses a single string with colon-separated values to specify a volume mount (<code>VOLUME:CONTAINER_PATH</code>), or an access mode (<code>VOLUME:CONTAINER_PATH:ACCESS_MODE</code>).</p> <ul> <li><code>VOLUME</code>: Can be either a host path on the platform hosting containers (bind mount) or a volume name.</li> <li><code>CONTAINER_PATH</code>: The path in the container where the volume is mounted.</li> <li><code>ACCESS_MODE</code>: A comma-separated <code>,</code> list of options:</li> <li><code>rw</code>: Read and write access. This is the default if none is specified.</li> <li><code>ro</code>: Read-only access.</li> <li><code>z</code>: SELinux option indicating that the bind mount host content is shared among multiple containers.</li> <li><code>Z</code>: SELinux option indicating that the bind mount host content is private and unshared for other containers.</li> </ul> <p>Note</p> <p>The SELinux re-labeling bind mount option is ignored on platforms without SELinux.</p> <p>Note Relative host paths are only supported by Compose that deploy to a local container runtime. This is because the relative path is resolved from the Compose file\u2019s parent directory which is only applicable in the local case. When Compose deploys to a non-local platform it rejects Compose files which use relative host paths with an error. To avoid ambiguities with named volumes, relative paths should always begin with <code>.</code> or <code>..</code>.</p>"},{"location":"docker/#long-syntax_5","title":"Long syntax","text":"<p>The long form syntax allows the configuration of additional fields that can't be expressed in the short form.</p> <ul> <li><code>type</code>: The mount type. Either <code>volume</code>, <code>bind</code>, <code>tmpfs</code>, <code>npipe</code>, or <code>cluster</code></li> <li><code>source</code>: The source of the mount, a path on the host for a bind mount, or the   name of a volume defined in the   top-level <code>volumes</code> key. Not applicable for a tmpfs mount.</li> <li><code>target</code>: The path in the container where the volume is mounted.</li> <li><code>read_only</code>: Flag to set the volume as read-only.</li> <li><code>bind</code>: Used to configure additional bind options:</li> <li><code>propagation</code>: The propagation mode used for the bind.</li> <li><code>create_host_path</code>: Creates a directory at the source path on host if there is nothing present.     Compose does nothing if there is something present at the path. This is automatically implied by short syntax     for backward compatibility with <code>docker-compose</code> legacy.</li> <li><code>selinux</code>: The SELinux re-labeling option <code>z</code> (shared) or <code>Z</code> (private)</li> <li><code>volume</code>: Configures additional volume options:</li> <li><code>nocopy</code>: Flag to disable copying of data from a container when a volume is created.</li> <li><code>tmpfs</code>: Configures additional tmpfs options:</li> <li><code>size</code>: The size for the tmpfs mount in bytes (either numeric or as bytes unit).</li> <li><code>mode</code>: The file mode for the tmpfs mount as Unix permission bits as an octal number.</li> <li><code>consistency</code>: The consistency requirements of the mount. Available values are platform specific.</li> </ul>"},{"location":"docker/#volumes_from","title":"volumes_from","text":"<p><code>volumes_from</code> mounts all of the volumes from another service or container. You can optionally specify read-only access <code>ro</code> or read-write <code>rw</code>. If no access level is specified, then read-write access is used.</p> <p>You can also mount volumes from a container that is not managed by Compose by using the <code>container:</code> prefix.</p> <pre><code>volumes_from:\n  - service_name\n  - service_name:ro\n  - container:container_name\n  - container:container_name:rw\n</code></pre>"},{"location":"docker/#working_dir","title":"working_dir","text":"<p><code>working_dir</code> overrides the container's working directory which is specified by the image, for example Dockerfile's <code>WORKDIR</code>.</p>"},{"location":"docker/#networks-top-level-element","title":"Networks top-level element","text":"<p>Networks are the layer that allow services to communicate with each other.</p> <p>The top-level <code>networks</code> element lets you configure named networks that can be reused across multiple services. To use a network across multiple services, you must explicitly grant each service access by using the networks attribute within the <code>services</code> top-level element. The <code>networks</code> top-level element has additional syntax that provides more granular control.</p>"},{"location":"docker/#examples","title":"Examples","text":""},{"location":"docker/#basic-example","title":"Basic example","text":"<p>In the following example, at runtime, networks <code>front-tier</code> and <code>back-tier</code> are created and the <code>frontend</code> service is connected to <code>front-tier</code> and <code>back-tier</code> networks.</p> <pre><code>services:\n  frontend:\n    image: example/webapp\n    networks:\n      - front-tier\n      - back-tier\n\nnetworks:\n  front-tier:\n  back-tier:\n</code></pre>"},{"location":"docker/#advanced-example","title":"Advanced example","text":"<pre><code>services:\n  proxy:\n    build: ./proxy\n    networks:\n      - frontend\n  app:\n    build: ./app\n    networks:\n      - frontend\n      - backend\n  db:\n    image: postgres\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n    ## Use a custom driver\n    driver: custom-driver-1\n  backend:\n    ## Use a custom driver which takes special options\n    driver: custom-driver-2\n    driver_opts:\n      foo: \"1\"\n      bar: \"2\"\n</code></pre> <p>The advanced example shows a Compose file which defines two custom networks. The <code>proxy</code> service is isolated from the <code>db</code> service, because they do not share a network in common. Only <code>app</code> can talk to both.</p>"},{"location":"docker/#attributes","title":"Attributes","text":""},{"location":"docker/#driver","title":"driver","text":"<p><code>driver</code> specifies which driver should be used for this network. Compose returns an error if the driver is not available on the platform.</p> <pre><code>networks:\n  db-data:\n    driver: overlay\n</code></pre> <p>Default and available values are platform specific. Compose supports the following drivers: <code>none</code> and <code>host</code></p> <ul> <li><code>host</code>: Use the host's networking stack.</li> <li><code>none</code>: Turn off networking.</li> </ul>"},{"location":"docker/#host-or-none","title":"host or none","text":"<p>The syntax for using built-in networks such as <code>host</code> and <code>none</code> is different, as such networks implicitly exist outside the scope of Compose. To use them, you must define an external network with the name <code>host</code> or <code>none</code> and an alias that Compose can use (<code>hostnet</code> and <code>nonet</code> in the following example), then grant the service access to that network using its alias.</p> <pre><code>services:\n  web:\n    networks:\n      hostnet: {}\n\nnetworks:\n  hostnet:\n    external: true\n    name: host\n</code></pre> <pre><code>services:\n  web:\n    ...\n    networks:\n      nonet: {}\n\nnetworks:\n  nonet:\n    external: true\n    name: none\n</code></pre>"},{"location":"docker/#driver_opts","title":"driver_opts","text":"<p><code>driver_opts</code> specifies a list of options as key-value pairs to pass to the driver. These options are driver-dependent. Consult the driver's documentation for more information. </p> <pre><code>networks:\n  db-data:\n    driver_opts:\n      foo: \"bar\"\n      baz: 1\n</code></pre>"},{"location":"docker/#attachable","title":"attachable","text":"<p>If <code>attachable</code> is set to <code>true</code>, then standalone containers should be able to attach to this network, in addition to services. If a standalone container attaches to the network, it can communicate with services and other standalone containers that are also attached to the network.</p> <pre><code>networks:\n  mynet1:\n    driver: overlay\n    attachable: true\n</code></pre>"},{"location":"docker/#enable_ipv6","title":"enable_ipv6","text":"<p><code>enable_ipv6</code> enables IPv6 networking. For an example, see step four of Create an IPv6 network.</p>"},{"location":"docker/#external","title":"external","text":"<p>If set to <code>true</code>:  - <code>external</code> specifies that this network\u2019s lifecycle is maintained outside of that of the application. Compose doesn't attempt to create these networks, and returns an error if one doesn't exist.  - All other attributes apart from name are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.</p> <p>In the example below, <code>proxy</code> is the gateway to the outside world. Instead of attempting to create a network, Compose queries the platform for an existing network simply called <code>outside</code> and connects the <code>proxy</code> service's containers to it.</p> <pre><code>\nservices:\n  proxy:\n    image: example/proxy\n    networks:\n      - outside\n      - default\n  app:\n    image: example/app\n    networks:\n      - default\n\nnetworks:\n  outside:\n    external: true\n</code></pre>"},{"location":"docker/#ipam","title":"ipam","text":"<p><code>ipam</code> specifies a custom IPAM configuration. This is an object with several properties, each of which is optional:</p> <ul> <li><code>driver</code>: Custom IPAM driver, instead of the default.</li> <li><code>config</code>: A list with zero or more configuration elements, each containing a:</li> <li><code>subnet</code>: Subnet in CIDR format that represents a network segment</li> <li><code>ip_range</code>: Range of IPs from which to allocate container IPs</li> <li><code>gateway</code>: IPv4 or IPv6 gateway for the master subnet</li> <li><code>aux_addresses</code>: Auxiliary IPv4 or IPv6 addresses used by Network driver, as a mapping from hostname to IP</li> <li><code>options</code>: Driver-specific options as a key-value mapping.</li> </ul> <pre><code>networks:\n  mynet1:\n    ipam:\n      driver: default\n      config:\n        - subnet: 172.28.0.0/16\n          ip_range: 172.28.5.0/24\n          gateway: 172.28.5.254\n          aux_addresses:\n            host1: 172.28.1.5\n            host2: 172.28.1.6\n            host3: 172.28.1.7\n      options:\n        foo: bar\n        baz: \"0\"\n</code></pre>"},{"location":"docker/#internal","title":"internal","text":"<p>By default, Compose provides external connectivity to networks. <code>internal</code>, when set to <code>true</code>, allows you to create an externally isolated network.</p>"},{"location":"docker/#labels_1","title":"labels","text":"<p>Add metadata to containers using <code>labels</code>. You can use either an array or a dictionary.</p> <p>It is recommended that you use reverse-DNS notation to prevent labels from conflicting with those used by other software.</p> <pre><code>networks:\n  mynet1:\n    labels:\n      com.example.description: \"Financial transaction network\"\n      com.example.department: \"Finance\"\n      com.example.label-with-empty-value: \"\"\n</code></pre> <pre><code>networks:\n  mynet1:\n    labels:\n      - \"com.example.description=Financial transaction network\"\n      - \"com.example.department=Finance\"\n      - \"com.example.label-with-empty-value\"\n</code></pre> <p>Compose sets <code>com.docker.compose.project</code> and <code>com.docker.compose.network</code> labels.</p>"},{"location":"docker/#name","title":"name","text":"<p><code>name</code> sets a custom name for the network. The name field can be used to reference networks which contain special characters. The name is used as is and is not scoped with the project name.</p> <pre><code>networks:\n  network1:\n    name: my-app-net\n</code></pre> <p>It can also be used in conjunction with the <code>external</code> property to define the platform network that Compose should retrieve, typically by using a parameter so the Compose file doesn't need to hard-code runtime specific values:</p> <pre><code>networks:\n  network1:\n    external: true\n    name: \"${NETWORK_ID}\"\n</code></pre>"},{"location":"docker/#volumes-top-level-element","title":"Volumes top-level element","text":"<p>Volumes are persistent data stores implemented by the container engine. Compose offers a neutral way for services to mount volumes, and configuration parameters to allocate them to infrastructure.</p> <p>The top-level <code>volumes</code> declaration lets you configure named volumes that can be reused across multiple services. To use a volume across multiple services, you must explicitly grant each service access by using the volumes attribute within the <code>services</code> top-level element. The <code>volumes</code> attribute has additional syntax that provides more granular control.</p>"},{"location":"docker/#example","title":"Example","text":"<p>The following example shows a two-service setup where a database's data directory is shared with another service as a volume, named <code>db-data</code>, so that it can be periodically backed up.</p> <pre><code>services:\n  backend:\n    image: example/database\n    volumes:\n      - db-data:/etc/data\n\n  backup:\n    image: backup-service\n    volumes:\n      - db-data:/var/lib/backup/data\n\nvolumes:\n  db-data:\n</code></pre> <p>The <code>db-data</code> volume is mounted at the <code>/var/lib/backup/data</code> and <code>/etc/data</code> container paths for backup and backend respectively.</p> <p>Running <code>docker compose up</code> creates the volume if it doesn't already exist. Otherwise, the existing volume is used and is recreated if it's manually deleted outside of Compose.</p>"},{"location":"docker/#attributes_1","title":"Attributes","text":"<p>An entry under the top-level <code>volumes</code> section can be empty, in which case it uses the container engine's default configuration for creating a volume. Optionally, you can configure it with the following keys:</p>"},{"location":"docker/#driver_1","title":"driver","text":"<p>Specifies which volume driver should be used. Default and available values are platform specific. If the driver is not available, Compose returns an error and doesn't deploy the application.</p> <pre><code>volumes:\n  db-data:\n    driver: foobar\n</code></pre>"},{"location":"docker/#driver_opts_1","title":"driver_opts","text":"<p><code>driver_opts</code> specifies a list of options as key-value pairs to pass to the driver for this volume. The options are driver-dependent.</p> <pre><code>volumes:\n  example:\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=10.40.0.199,nolock,soft,rw\"\n      device: \":/docker/example\"\n</code></pre>"},{"location":"docker/#external_1","title":"external","text":"<p>If set to <code>true</code>:  - <code>external</code> specifies that this volume already exists on the platform and its lifecycle is managed outside of that of the application. Compose doesn't then create the volume, and returns an error if the volume doesn't  exist.  - All other attributes apart from <code>name</code> are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.</p> <p>In the example below, instead of attempting to create a volume called <code>{project_name}_db-data</code>, Compose looks for an existing volume simply called <code>db-data</code> and mounts it into the <code>backend</code> service's containers.</p> <pre><code>services:\n  backend:\n    image: example/database\n    volumes:\n      - db-data:/etc/data\n\nvolumes:\n  db-data:\n    external: true\n</code></pre>"},{"location":"docker/#labels_2","title":"labels","text":"<p><code>labels</code> are used to add metadata to volumes. You can use either an array or a dictionary.</p> <p>It's recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.</p> <pre><code>volumes:\n  db-data:\n    labels:\n      com.example.description: \"Database volume\"\n      com.example.department: \"IT/Ops\"\n      com.example.label-with-empty-value: \"\"\n</code></pre> <pre><code>volumes:\n  db-data:\n    labels:\n      - \"com.example.description=Database volume\"\n      - \"com.example.department=IT/Ops\"\n      - \"com.example.label-with-empty-value\"\n</code></pre> <p>Compose sets <code>com.docker.compose.project</code> and <code>com.docker.compose.volume</code> labels.</p>"},{"location":"docker/#name_1","title":"name","text":"<p><code>name</code> sets a custom name for a volume. The name field can be used to reference volumes that contain special characters. The name is used as is and is not scoped with the stack name.</p> <pre><code>volumes:\n  db-data:\n    name: \"my-app-data\"\n</code></pre> <p>This makes it possible to make this lookup name a parameter of the Compose file, so that the model ID for the volume is hard-coded but the actual volume ID on the platform is set at runtime during deployment. </p> <p>For example, if <code>DATABASE_VOLUME=my_volume_001</code> in your <code>.env</code> file:</p> <pre><code>volumes:\n  db-data:\n      name: ${DATABASE_VOLUME}\n</code></pre> <p>Running <code>docker compose up</code> uses the volume called <code>my_volume_001</code>. </p> <p>It can also be used in conjunction with the <code>external</code> property. This means the name of the volume used to lookup the actual volume on the platform is set separately from the name used to refer to it within the Compose file:</p> <pre><code>volumes:\n  db-data:\n    external:\n      name: actual-name-of-volume\n</code></pre>"},{"location":"docker/#configs-top-level-element","title":"Configs top-level element","text":"<p>Configs allow services to adapt their behaviour without the need to rebuild a Docker image.</p> <p>Services can only access configs when explicitly granted by a <code>configs</code> attribute within the <code>services</code> top-level element.</p> <p>As with volumes, configs are mounted as files into a service's container's filesystem. The location of the mount point within the container defaults to <code>/&lt;config-name&gt;</code> in Linux containers and <code>C:\\&lt;config-name&gt;</code> in Windows containers. </p> <p>By default, the config: - Is owned by the user running the container command but can be overridden by service configuration. - Has world-readable permissions (mode 0444), unless the service is configured to override this.</p> <p>The top-level <code>configs</code> declaration defines or references configuration data that is granted to services in your Compose application. The source of the config is either <code>file</code> or <code>external</code>.</p> <ul> <li><code>file</code>: The config is created with the contents of the file at the specified path.</li> <li><code>environment</code>: The config content is created with the value of an environment variable.</li> <li><code>content</code>: The content is created with the inlined value.</li> <li><code>external</code>: If set to true, <code>external</code> specifies that this config has already been created. Compose does not   attempt to create it, and if it does not exist, an error occurs.</li> <li><code>name</code>: The name of the config object in the container engine to look up. This field can be used to   reference configs that contain special characters. The name is used as is   and will not be scoped with the project name.</li> </ul>"},{"location":"docker/#example-1","title":"Example 1","text":"<p><code>&lt;project_name&gt;_http_config</code> is created when the application is deployed, by registering the content of the <code>httpd.conf</code> as the configuration data.</p> <pre><code>configs:\n  http_config:\n    file: ./httpd.conf\n</code></pre> <p>Alternatively, <code>http_config</code> can be declared as external. Compose looks up <code>http_config</code> to expose the configuration data to relevant services.</p> <pre><code>configs:\n  http_config:\n    external: true\n</code></pre>"},{"location":"docker/#example-2","title":"Example 2","text":"<p><code>&lt;project_name&gt;_app_config</code> is created when the application is deployed, by registering the inlined content as the configuration data. This comes with the benefits Compose will infer variables when creating the config, which allows to adjust content according to service configuration:</p> <pre><code>configs:\n  app_config:\n    content: |\n      debug=${DEBUG}\n      spring.application.admin.enabled=${DEBUG}\n      spring.application.name=${COMPOSE_PROJECT_NAME}\n</code></pre>"},{"location":"docker/#example-3","title":"Example 3","text":"<p>External configs lookup can also use a distinct key by specifying a <code>name</code>. </p> <p>The following example modifies the previous one to look up a config using the parameter <code>HTTP_CONFIG_KEY</code>. The the actual lookup key will is set at deployment time by the interpolation of variables, but exposed to containers as hard-coded ID <code>http_config</code>.</p> <pre><code>configs:\n  http_config:\n    external: true\n    name: \"${HTTP_CONFIG_KEY}\"\n</code></pre> <p>If <code>external</code> is set to <code>true</code>, all other attributes apart from <code>name</code> are irrelevant. If Compose detecs any other attribute, it rejects the Compose file as invalid.</p>"},{"location":"docker/#secrets-top-level-element","title":"Secrets top-level element","text":"<p>Secrets are a flavor of Configs focusing on sensitive data, with specific constraint for this usage. </p> <p>Services can only access secrets when explicitly granted by a <code>secrets</code> attribute within the <code>services</code> top-level element.</p> <p>The top-level <code>secrets</code> declaration defines or references sensitive data that is granted to the services in your Compose application. The source of the secret is either <code>file</code> or <code>environment</code>.</p> <ul> <li><code>file</code>: The secret is created with the contents of the file at the specified path.</li> <li><code>environment</code>: The secret is created with the value of an environment variable.</li> <li><code>external</code>: If set to true, <code>external</code> specifies that this secret has already been created. Compose does   not attempt to create it, and if it does not exist, an error occurs.</li> <li><code>name</code>: The name of the secret object in Docker. This field can be used to   reference secrets that contain special characters. The name is used as is   and isn't scoped with the project name.</li> </ul>"},{"location":"docker/#example-1_1","title":"Example 1","text":"<p><code>server-certificate</code> secret is created as <code>&lt;project_name&gt;_server-certificate</code> when the application is deployed, by registering content of the <code>server.cert</code> as a platform secret.</p> <pre><code>secrets:\n  server-certificate:\n    file: ./server.cert\n</code></pre>"},{"location":"docker/#example-2_1","title":"Example 2","text":"<p><code>token</code> secret  is created as <code>&lt;project_name&gt;_token</code> when the application is deployed, by registering the content of the <code>OAUTH_TOKEN</code> environment variable as a platform secret.</p> <pre><code>secrets:\n  token:\n    environment: \"OAUTH_TOKEN\"\n</code></pre> <p>Alternatively, <code>server-certificate</code> can be declared as external. Compose looks up the <code>server-certificate</code> secret to expose to relevant services.</p> <pre><code>secrets:\n  server-certificate:\n    external: true\n</code></pre>"},{"location":"docker/#example-3_1","title":"Example 3","text":"<p>External secrets lookup can also use a distinct key by specifying a <code>name</code>. </p> <p>The following example modifies the previous example to look up a secret using the name <code>CERTIFICATE_KEY</code>. The actual lookup key is set at deployment time by the interpolation of variables, but exposed to containers as hard-coded ID <code>server-certificate</code>.</p> <pre><code>secrets:\n  server-certificate:\n    external: true\n    name: \"${CERTIFICATE_KEY}\"\n</code></pre> <p>If <code>external</code> is set to <code>true</code>, all other attributes apart from <code>name</code> are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.</p> <p>Your Compose file needs to explicitly grant access to the secrets to relevant services in your application.</p>"},{"location":"docker/#fragments","title":"Fragments","text":"<p>With Compose, you can use built-in YAML features to make your Compose file neater and more efficient. Anchors and aliases let you create re-usable blocks. This is useful if you start to find common configurations that span multiple services. Having re-usable blocks minimizes potential mistakes.</p> <p>Anchors are created using the <code>&amp;</code> sign. The sign is followed by an alias name. You can use this alias with the <code>*</code> sign later to reference the value following the anchor. Make sure there is no space between the <code>&amp;</code> and the <code>*</code> characters and the following alias name. </p> <p>You can use more than one anchor and alias in a single Compose file.</p>"},{"location":"docker/#example-1_2","title":"Example 1","text":"<pre><code>volumes:\n  db-data: &amp;default-volume\n    driver: default\n  metrics: *default-volume\n</code></pre> <p>In the example above, a <code>default-volume</code> anchor is created based on the <code>db-data</code> volume. It is later reused by the alias <code>*default-volume</code> to define the <code>metrics</code> volume. </p> <p>Anchor resolution takes place before variables interpolation, so variables can't be used to set anchors or aliases.</p>"},{"location":"docker/#example-2_2","title":"Example 2","text":"<pre><code>services:\n  first:\n    image: my-image:latest\n    environment: &amp;env\n      - CONFIG_KEY\n      - EXAMPLE_KEY\n      - DEMO_VAR\n  second:\n    image: another-image:latest\n    environment: *env\n</code></pre> <p>If you have an anchor that you want to use in more than one service, use it in conjunction with an extension to make your Compose file easier to maintain.</p>"},{"location":"docker/#example-3_2","title":"Example 3","text":"<p>You may want to partially override values. Compose follows the rule outlined by YAML merge type. </p> <p>In the following example, <code>metrics</code> volume specification uses alias to avoid repetition but overrides <code>name</code> attribute:</p> <pre><code>\nservices:\n  backend:\n    image: example/database\n    volumes:\n      - db-data\n      - metrics\nvolumes:\n  db-data: &amp;default-volume\n    driver: default\n    name: \"data\"\n  metrics:\n    &lt;&lt;: *default-volume\n    name: \"metrics\"\n</code></pre>"},{"location":"docker/#example-4","title":"Example 4","text":"<p>You can also extend the anchor to add additional values.</p> <pre><code>services:\n  first:\n    image: my-image:latest\n    environment: &amp;env\n      FOO: BAR\n      ZOT: QUIX\n  second:\n    image: another-image:latest\n    environment:\n      &lt;&lt;: *env\n      YET_ANOTHER: VARIABLE\n</code></pre> <p>Note</p> <p>YAML merge only applies to mappings, and can't be used with sequences. </p> <p>In example above, the environment variables must be declared using the <code>FOO: BAR</code> mapping syntax, while the sequence syntax <code>- FOO=BAR</code> is only valid when no fragments are involved. </p>"},{"location":"docker/#extension","title":"Extension","text":"<p>As with Fragments, Extensions can be used to make your Compose file more efficient and easier to maintain. Extensions can also be used with anchors and aliases.</p> <p>Use the prefix <code>x-</code> as a top-level element to modularize configurations that you want to reuse.  Compose ignores any fields that start with <code>x-</code>, this is the sole exception where Compose silently ignores unrecognized fields.</p> <p>They also can be used within any structure in a Compose file where user-defined keys are not expected.  Compose use those to enable experimental features, the same way browsers add support for custom CSS features</p>"},{"location":"docker/#example-1_3","title":"Example 1","text":"<pre><code>x-custom:\n  foo:\n    - bar\n    - zot\n\nservices:\n  webapp:\n    image: example/webapp\n    x-foo: bar\n</code></pre> <pre><code>service:\n  backend:\n    deploy:\n      placement:\n        x-aws-role: \"arn:aws:iam::XXXXXXXXXXXX:role/foo\"\n        x-aws-region: \"eu-west-3\"\n        x-azure-region: \"france-central\"\n</code></pre>"},{"location":"docker/#example-2_3","title":"Example 2","text":"<pre><code>x-env: &amp;env\n  environment:\n    - CONFIG_KEY\n    - EXAMPLE_KEY\n\nservices:\n  first:\n    &lt;&lt;: *env\n    image: my-image:latest\n  second:\n    &lt;&lt;: *env\n    image: another-image:latest\n</code></pre> <p>In this example, the environment variables do not belong to either of the services. They\u2019ve been lifted out completely into the <code>x-env</code> extension field. This defines a new node which contains the environment field. The <code>&amp;env</code> YAML anchor is used so both services can reference the extension field\u2019s value as <code>*env</code>.</p>"},{"location":"docker/#example-3_3","title":"Example 3","text":"<pre><code>x-function: &amp;function\n labels:\n   function: \"true\"\n depends_on:\n   - gateway\n networks:\n   - functions\n deploy:\n   placement:\n     constraints:\n       - 'node.platform.os == linux'\nservices:\n ## Node.js gives OS info about the node (Host)\n nodeinfo:\n   &lt;&lt;: *function\n   image: functions/nodeinfo:latest\n   environment:\n     no_proxy: \"gateway\"\n     https_proxy: $https_proxy\n ## Uses `cat` to echo back response, fastest function to execute.\n echoit:\n   &lt;&lt;: *function\n   image: functions/alpine:health\n   environment:\n     fprocess: \"cat\"\n     no_proxy: \"gateway\"\n     https_proxy: $https_proxy\n</code></pre> <p>The <code>nodeinfo</code> and <code>echoit</code> services both include the <code>x-function</code> extension via the <code>&amp;function</code> anchor, then set their specific image and environment. </p>"},{"location":"docker/#example-4_1","title":"Example 4","text":"<p>Using YAML merge it is also possible to use multiple extensions and share and override additional attributes for specific needs:</p> <pre><code>x-environment: &amp;default-environment\n  FOO: BAR\n  ZOT: QUIX\nx-keys: &amp;keys\n  KEY: VALUE\nservices:\n  frontend:\n    image: example/webapp\n    environment: \n      &lt;&lt; : [*default-environment, *keys]\n      YET_ANOTHER: VARIABLE\n</code></pre> <p>Note</p> <p>YAML merge only applies to mappings, and can't be used with sequences. </p> <p>In the example above, the environment variables are declared using the <code>FOO: BAR</code> mapping syntax, while the sequence syntax <code>- FOO=BAR</code> is only valid when no fragments are involved.</p>"},{"location":"docker/#informative-historical-notes","title":"Informative Historical Notes","text":"<p>This section is informative. At the time of writing, the following prefixes are known to exist:</p> Prefix Vendor/Organization docker Docker kubernetes Kubernetes"},{"location":"docker/#specifying-byte-values","title":"Specifying byte values","text":"<p>Values express a byte value as a string in <code>{amount}{byte unit}</code> format: The supported units are <code>b</code> (bytes), <code>k</code> or <code>kb</code> (kilo bytes), <code>m</code> or <code>mb</code> (mega bytes) and <code>g</code> or <code>gb</code> (giga bytes).</p> <pre><code>    2b\n    1024kb\n    2048k\n    300m\n    1gb\n</code></pre>"},{"location":"docker/#specifying-durations","title":"Specifying durations","text":"<p>Values express a duration as a string in the form of <code>{value}{unit}</code>. The supported units are <code>us</code> (microseconds), <code>ms</code> (milliseconds), <code>s</code> (seconds), <code>m</code> (minutes) and <code>h</code> (hours). Values can combine multiple values without separator.</p> <pre><code>  10ms\n  40s\n  1m30s\n  1h5m30s20ms\n</code></pre>"},{"location":"docker/#interpolation","title":"Interpolation","text":"<p>Values in a Compose file can be set by variables and interpolated at runtime. Compose files use a Bash-like syntax <code>${VARIABLE}</code>.</p> <p>Both <code>$VARIABLE</code> and <code>${VARIABLE}</code> syntax is supported. Default values can be defined inline using typical shell syntax:</p> <ul> <li><code>${VARIABLE:-default}</code> evaluates to <code>default</code> if <code>VARIABLE</code> is unset or   empty in the environment.</li> <li><code>${VARIABLE-default}</code> evaluates to <code>default</code> only if <code>VARIABLE</code> is unset   in the environment.</li> </ul> <p>Similarly, the following syntax allows you to specify mandatory variables:</p> <ul> <li><code>${VARIABLE:?err}</code> exits with an error message containing <code>err</code> if   <code>VARIABLE</code> is unset or empty in the environment.</li> <li><code>${VARIABLE?err}</code> exits with an error message containing <code>err</code> only if   <code>VARIABLE</code> is unset in the environment.</li> </ul> <p>Interpolation can also be nested:</p> <ul> <li><code>${VARIABLE:-${FOO}}</code></li> <li><code>${VARIABLE?$FOO}</code></li> <li><code>${VARIABLE:-${FOO:-default}}</code></li> </ul> <p>Other extended shell-style features, such as <code>${VARIABLE/foo/bar}</code>, are not supported by Compose.</p> <p>You can use a <code>$$</code> (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a <code>$$</code> allows you to refer to environment variables that you don't want processed by Compose.</p> <pre><code>web:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n</code></pre> <p>If Compose can't resolve a substituted variable and no default value is defined, it displays a warning and substitutes the variable with an empty string.</p> <p>As any values in a Compose file can be interpolated with variable substitution, including compact string notation for complex elements, interpolation is applied before a merge on a per-file basis.</p> <p>Interpolation applies only to YAML values, not to keys. For the few places where keys are actually arbitrary user-defined strings, such as labels or environment, an alternate equal sign syntax must be used for interpolation to apply. For example:</p> <pre><code>services:\n  foo:\n    labels:\n      \"$VAR_NOT_INTERPOLATED_BY_COMPOSE\": \"BAR\"\n</code></pre> <pre><code>services:\n  foo:\n    labels:\n      - \"$VAR_INTERPOLATED_BY_COMPOSE=BAR\"\n</code></pre>"},{"location":"docker/#merge-and-override","title":"Merge and override","text":"<p>Compose lets you define a Compose application model through multiple Compose files.  When doing so, Compose follows the rules declared in this section to merge Compose files.</p>"},{"location":"docker/#mapping","title":"Mapping","text":"<p>A YAML <code>mapping</code> gets merged by adding missing entries and merging the conflicting ones.</p> <p>Merging the following example YAML trees:</p> <pre><code>services:\n  foo:\n    key1: value1\n    key2: value2\n</code></pre> <pre><code>services:\n  foo:\n    key2: VALUE\n    key3: value3\n</code></pre> <p>Results in a Compose application model equivalent to the YAML tree:</p> <pre><code>services:\n  foo:\n    key1: value1\n    key2: VALUE\n    key3: value3\n</code></pre>"},{"location":"docker/#sequence","title":"Sequence","text":"<p>A YAML <code>sequence</code> is merged by appending values from the overriding Compose file to the previous one.</p> <p>Merging the following example YAML trees:</p> <pre><code>services:\n  foo:\n    DNS:\n      - 1.1.1.1\n</code></pre> <pre><code>services:\n  foo:\n    DNS: \n      - 8.8.8.8\n</code></pre> <p>Results in a Compose application model equivalent to the YAML tree:</p> <pre><code>services:\n  foo:\n    DNS:\n      - 1.1.1.1\n      - 8.8.8.8\n</code></pre>"},{"location":"docker/#exceptions","title":"Exceptions","text":""},{"location":"docker/#shell-commands","title":"Shell commands","text":"<p>When merging Compose files that use the services attributes command, entrypoint and healthcheck: <code>test</code>, the value is overridden by the latest Compose file, and not appended.</p> <p>Merging the following example YAML trees:</p> <pre><code>services:\n  foo:\n    command: [\"echo\", \"foo\"]\n</code></pre> <pre><code>services:\n  foo:\n    command: [\"echo\", \"bar\"]\n</code></pre> <p>Results in a Compose application model equivalent to the YAML tree:</p> <pre><code>services:\n  foo:\n    command: [\"echo\", \"bar\"]\n</code></pre>"},{"location":"docker/#unique-resources","title":"Unique resources","text":"<p>Applies to the ports, volumes, secrets and configs services attributes. While these types are modeled in a Compose file as a sequence, they have special uniqueness requirements:</p> Attribute Unique key volumes target secrets source configs source ports {ip, target, published, protocol} <p>When merging Compose files, Compose appends new entries that do not violate a uniqueness constraint and merge entries that share a unique key.</p> <p>Merging the following example YAML trees:</p> <pre><code>services:\n  foo:\n    volumes:\n      - foo:/work\n</code></pre> <pre><code>services:\n  foo:\n    volumes:\n      - bar:/work\n</code></pre> <p>Results in a Compose application model equivalent to the YAML tree:</p> <pre><code>services:\n  foo:\n    volumes:\n      - bar:/work\n</code></pre>"},{"location":"docker/#reset-value","title":"Reset value","text":"<p>In addition to the previously described mechanism, an override Compose file can also be used to remove elements from your application model. For this purpose, the custom YAML tag <code>!reset</code> can be set to override a value set by the overriden Compose file. A valid value for attribute must be provided, but will be ignored and target attribute will be set with type's default value or <code>null</code>. </p> <p>For readability, it is recommended to explicitly set the attribute value to the null (<code>null</code>) or empty array <code>[]</code> (with <code>!reset null</code> or <code>!reset []</code>) so that it is clear that resulting attribute will be cleared.</p> <p>A base <code>compose.yaml</code> file:</p> <pre><code>services:\napp:\n    image: myapp\n    ports:\n      - \"8080:80\"\n    environment:\n      FOO: BAR             \n</code></pre> <p>And an <code>overide.compose.yaml</code> file:</p> <pre><code>services:\n  app:\n    image: myapp\n    ports: !reset []\n    environment:\n      FOO: !reset null\n</code></pre> <p>Results in:</p> <pre><code>services:\n  app:\n    image: myapp\n</code></pre>"},{"location":"docker/#replace-value","title":"Replace value","text":"<p>While <code>!reset</code> can be used to remove a declaration from a Compose file using an override file, <code>!override</code> allows you to fully replace an attribute, bypassing the standard merge rules. A typical example is to fully replace a  resource definition, to rely on a distinct model but using the same name.</p> <p>A base <code>compose.yaml</code> file:</p> <pre><code>services:\napp:\n    image: myapp\n    ports:\n      - \"8080:80\"\n</code></pre> <p>To remove the original port, but expose a new one, the following override file is used:</p> <pre><code>services:\n  app:\n    ports: !override\n      - \"8443:443\" \n</code></pre> <p>This results in: </p> <pre><code>services:\n  app:\n    image: myapp\n    ports:\n      - \"8443:443\" \n</code></pre> <p>If <code>!override</code> had not been used, both <code>8080:80</code> and <code>8443:443</code> would be exposed as per the merging rules outlined above. </p>"},{"location":"docker/#include","title":"Include","text":"<p>A Compose application can declare dependency on another Compose application. This is useful if: - You want to reuse other Compose files. - You need to factor out parts of your application model into separate Compose files so they can be managed separately or shared with others. - Teams need to keep a Compose file reasonably complicated for the limited amount of resources it has to declare for it's own sub-domain, within a larger deployment.</p> <p>The <code>include</code> top-level section is used to define the dependency on another Compose application, or sub-domain. Each path listed in the <code>include</code> section is loaded as an individual Compose application model, with it's own project directory, in order to resolve relative paths. </p> <p>Once the included Compose application is loaded, all resources definitions are copied into the  current Compose application model. Compose displays a warning if resource names conflict and doesn't  try to merge them. To enforce this, <code>include</code> is evaluated after the Compose file(s) selected  to define the Compose application model have been parsed and merged, so that conflicts  between Compose files are detected.</p> <p><code>include</code> applies recursively so an included Compose file which declares its own <code>include</code> section, triggers those other files to be included as well. </p> <p>Any volumes, networks, or other resources pulled in from the included Compose file can be used by the current Compose application for cross-service references. For example:</p> <pre><code>include:\n  - my-compose-include.yaml  #with serviceB declared\nservices:\n  serviceA:\n    build: .\n    depends_on:\n      - serviceB #use serviceB directly as if it was declared in this Compose file\n</code></pre> <p>Compose also supports the use of interpolated variables with <code>include</code>. It's recommended that you specify mandatory variables. For example:</p> <pre><code>include:\n  -${INCLUDE_PATH:?FOO}/compose.yaml\n</code></pre>"},{"location":"docker/#short-syntax_6","title":"Short syntax","text":"<p>The short syntax only defines paths to other Compose files. The file is loaded with the parent folder as the project directory, and an optional <code>.env</code> file that is loaded to define any variables' default values by interpolation. The local project's environment can override those values. </p> <pre><code>include:\n  - ../commons/compose.yaml\n  - ../another_domain/compose.yaml\n\nservices:\n  webapp:\n    depends_on:\n      - included-service ## defined by another_domain\n</code></pre> <p>In the above example, both <code>../commons/compose.yaml</code> and  <code>../another_domain/compose.yaml</code> are loaded as individual Compose projects. Relative paths  in Compose files being referred by <code>include</code> are resolved relative to their own Compose  file path, not based on the local project's directory. Variables are interpolated using values set in the optional <code>.env</code> file in same folder, and is overridden by the local project's environment.</p>"},{"location":"docker/#long-syntax_6","title":"Long syntax","text":"<p>The long syntax offers more control over the sub-project parsing:</p> <pre><code>include:\n   - path: ../commons/compose.yaml\n     project_directory: ..\n     env_file: ../another/.env\n</code></pre>"},{"location":"docker/#path","title":"path","text":"<p><code>path</code> is required and defines the location of the Compose file(s) to be parsed and included into the local Compose model. <code>path</code> can be set either to a string when a single Compose file is involved, or to a list of strings when multiple Compose files need to be merged together to define the Compose model to be included in the local application.</p> <pre><code>include:\n   - path: \n       - ../commons/compose.yaml\n       - ./commons-override.yaml\n</code></pre>"},{"location":"docker/#project_directory","title":"project_directory","text":"<p><code>project_directory</code> defines a base path to resolve relative paths set in the Compose file. It defaults to  the directory of the included Compose file.</p>"},{"location":"docker/#env_file_1","title":"env_file","text":"<p><code>env_file</code> defines an environment file(s) to use to define default values when interpolating variables in the Compose file being parsed. It defaults to <code>.env</code> file in the <code>project_directory</code> for the Compose  file being parsed. </p> <p><code>env_file</code> can be set either to a string or a list of strings when multiple environment files need to be merged to define a project environment.</p> <pre><code>include:\n   - path: ../another/compose.yaml\n     env_file:\n       - ../another/.env\n       - ../another/dev.env\n</code></pre> <p>The local project's environment has precedence over the values set by the Compose file, so that the local project can override values for customization.</p>"},{"location":"docker/#profiles_1","title":"Profiles","text":"<p>With profiles you can define a set of active profiles so your Compose application model is adjusted for various usages and environments. The exact mechanism is implementation specific and may include command line flags, environment variables, etc.</p> <p>The services top-level element supports a <code>profiles</code> attribute to define a list of named profiles.  Services without a <code>profiles</code> attribute are always enabled. </p> <p>A service is ignored by Compose when none of the listed <code>profiles</code> match the active ones, unless the service is explicitly targeted by a command. In that case its profile is added to the set of active profiles.</p> <p>Note</p> <p>All other top-level elements are not affected by <code>profiles</code> and are always active.</p> <p>References to other services (by <code>links</code>, <code>extends</code> or shared resource syntax <code>service:xxx</code>) do not automatically enable a component that would otherwise have been ignored by active profiles. Instead Compose returns an error.</p>"},{"location":"docker/#illustrative-example_1","title":"Illustrative example","text":"<pre><code>services:\n  foo:\n    image: foo\n  bar:\n    image: bar\n    profiles:\n      - test\n  baz:\n    image: baz\n    depends_on:\n      - bar\n    profiles:\n      - test\n  zot:\n    image: zot\n    depends_on:\n      - bar\n    profiles:\n      - debug\n</code></pre> <p>In the above example:</p> <ul> <li>If the Compose application model is parsed with no profile enabled, it only contains the <code>foo</code> service.</li> <li>If the profile <code>test</code> is enabled, the model contains the services <code>bar</code> and <code>baz</code>, and service <code>foo</code>, which is always enabled.</li> <li>If the profile <code>debug</code> is enabled, the model contains both <code>foo</code> and <code>zot</code> services, but not <code>bar</code> and <code>baz</code>,   and as such the model is invalid regarding the <code>depends_on</code> constraint of <code>zot</code>.</li> <li>If the profiles <code>debug</code> and <code>test</code> are enabled, the model contains all services; <code>foo</code>, <code>bar</code>, <code>baz</code> and <code>zot</code>.</li> <li>If Compose is executed with <code>bar</code> as the explicit service to run, <code>bar</code> and the <code>test</code> profile   are active even if <code>test</code> profile is not enabled.</li> <li>If Compose is executed with <code>baz</code> as the explicit service to run, the service <code>baz</code> and the   profile <code>test</code> are active and <code>bar</code> is pulled in by the <code>depends_on</code> constraint.</li> <li>If Compose is executed with <code>zot</code> as the explicit service to run, again the model is   invalid regarding the <code>depends_on</code> constraint of <code>zot</code>, since <code>zot</code> and <code>bar</code> have no common <code>profiles</code>   listed.</li> <li>If Compose is executed with <code>zot</code> as the explicit service to run and profile <code>test</code> is enabled,   profile <code>debug</code> is automatically enabled and service <code>bar</code> is pulled in as a dependency starting both   services <code>zot</code> and <code>bar</code>.</li> </ul> <p>See how you can use <code>profiles</code> in Docker Compose.</p>"},{"location":"embedding/","title":"Embedding","text":"<p>Embedding is a way to represent categorical variables in a way that can be used by machine learning algorithms. It is a way to represent a categorical variable as a continuous vector of numbers. This is done by creating a matrix of weights that is learned during the training process. The matrix is initialized randomly and updated during training. The embedding matrix is a dense representation of the categorical variable.</p>"},{"location":"embedding/#leaderboard","title":"Leaderboard","text":"<p>https://huggingface.co/spaces/mteb/leaderboard</p>"},{"location":"framework/","title":"Framework","text":""},{"location":"framework/#pytorch-vs-tensorflow","title":"Pytorch vs Tensorflow","text":"<p>The image range is different for each framework. In PyTorch, the image range is 0-1 while TensorFlow uses a range from 0 to 255. To use TensorFlow, we have to adapt the image range.</p>"},{"location":"framework/#to-tf","title":"To TF","text":"<pre><code>def dataset_to_tf(\n    dataset,\n    cols_to_retain,\n    collate_fn,\n    collate_fn_args,\n    columns_to_np_types,\n    output_signature,\n    shuffle,\n    batch_size,\n    drop_remainder,\n):\n    \"\"\"Create a tf.data.Dataset from the underlying Dataset. This is a single-process method - the multiprocess\n    equivalent is multiprocess_dataset_to_tf.\n\n            Args:\n                dataset (`Dataset`): Dataset to wrap with tf.data.Dataset.\n                cols_to_retain (`List[str]`): Dataset column(s) to load in the\n                    tf.data.Dataset. It is acceptable to include column names that are created by the `collate_fn` and\n                    that do not exist in the original dataset.\n                collate_fn(`Callable`): A function or callable object (such as a `DataCollator`) that will collate\n                    lists of samples into a batch.\n                collate_fn_args (`Dict`): A  `dict` of keyword arguments to be passed to the\n                    `collate_fn`. Can be empty.\n                columns_to_np_types (`Dict[str, np.dtype]`): A `dict` mapping column names to numpy dtypes.\n                output_signature (`Dict[str, tf.TensorSpec]`): A `dict` mapping column names to\n                    `tf.TensorSpec` objects.\n                shuffle(`bool`): Shuffle the dataset order when loading. Recommended True for training, False for\n                    validation/evaluation.\n                batch_size (`int`): Size of batches to load from the dataset.\n                drop_remainder(`bool`, default `None`): Drop the last incomplete batch when loading. If not provided,\n                    defaults to the same setting as shuffle.\n\n            Returns:\n                `tf.data.Dataset`\n    \"\"\"\n    if config.TF_AVAILABLE:\n        import tensorflow as tf\n    else:\n        raise ImportError(\"Called a Tensorflow-specific function but Tensorflow is not installed.\")\n\n    getter_fn = partial(\n        np_get_batch,\n        dataset=dataset,\n        cols_to_retain=cols_to_retain,\n        collate_fn=collate_fn,\n        collate_fn_args=collate_fn_args,\n        columns_to_np_types=columns_to_np_types,\n        return_dict=False,  # TF expects numpy_function to return a list and will not accept a dict\n    )\n\n    @tf.function(input_signature=[tf.TensorSpec(None, tf.int64)])\n    def fetch_function(indices):\n        output = tf.numpy_function(\n            getter_fn,\n            inp=[indices],\n            # This works because dictionaries always output in the same order\n            Tout=[tf.dtypes.as_dtype(dtype) for dtype in columns_to_np_types.values()],\n        )\n        return {key: output[i] for i, key in enumerate(columns_to_np_types.keys())}\n\n    tf_dataset = tf.data.Dataset.from_tensor_slices(np.arange(len(dataset), dtype=np.int64))\n\n    if shuffle:\n        tf_dataset = tf_dataset.shuffle(len(dataset))\n\n    tf_dataset = tf_dataset.batch(batch_size, drop_remainder=drop_remainder).map(fetch_function)\n\n    def ensure_shapes(input_dict):\n        return {key: tf.ensure_shape(val, output_signature[key].shape) for key, val in input_dict.items()}\n\n    return tf_dataset.map(ensure_shapes)\n</code></pre>"},{"location":"framework/#pytorch-dataset-to-tf-dataset","title":"pytorch dataset to tf dataset","text":"<pre><code>import tensorflow as tf\nimport torch\n\n# Assume that we have a PyTorch Dataset object called 'dataset'\n\ndef pytorch_dataset_to_tensorflow_dataset(dataset):\n  def generator():\n    for data in dataset:\n      # Convert data from PyTorch tensors to TensorFlow tensors\n      data = [tf.convert_to_tensor(x) for x in data]\n      yield data\n\n  # Create a TensorFlow Dataset from the generator\n  dataset = tf.data.Dataset.from_generator(generator, output_types=data[0].dtype, output_shapes=data[0].shape)\n\n  return dataset\n\n# Create a TensorFlow Dataset from the PyTorch Dataset\ndataset = pytorch_dataset_to_tensorflow_dataset(dataset)\n\n# Create a TensorFlow DataLoader from the TensorFlow Dataset\ndataloader = tf.data.DataLoader(dataset, batch_size=32, num_parallel_calls=tf.data.AUTOTUNE)\n</code></pre> <pre><code>image = tf.io.read_file(filename=filepath)\nimage = tf.image.decode_jpeg(image, channels=3) #or decode_png\n</code></pre> <p>The opposite of <code>unsqueeze</code> and <code>squeeze</code> is <code>expand_dims</code>:</p> <pre><code>img = tf.expand_dims(img,axis=0)\n</code></pre> <p>yield the desired/necessary transformations.</p> <p>As for the photos, I am quite sure that you missed a /255.0 in case of PyTorch or added a 255.0 division in case of TensorFlow.</p> <p>In fact, when digging deep into the Keras backend, you can see that when you call your preprocessing function, it will call this function here:</p> <pre><code>def _preprocess_numpy_input(x, data_format, mode):\n  \"\"\"Preprocesses a Numpy array encoding a batch of images.\n\n  Arguments:\n    x: Input array, 3D or 4D.\n    data_format: Data format of the image array.\n    mode: One of \"caffe\", \"tf\" or \"torch\".\n      - caffe: will convert the images from RGB to BGR,\n          then will zero-center each color channel with\n          respect to the ImageNet dataset,\n          without scaling.\n      - tf: will scale pixels between -1 and 1,\n          sample-wise.\n      - torch: will scale pixels between 0 and 1 and then\n          will normalize each channel with respect to the\n          ImageNet dataset.\n\n  Returns:\n      Preprocessed Numpy array.\n  \"\"\"\n  if not issubclass(x.dtype.type, np.floating):\n    x = x.astype(backend.floatx(), copy=False)\n\n  if mode == 'tf':\n    x /= 127.5\n    x -= 1.\n    return x\n  elif mode == 'torch':\n    x /= 255.\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n  else:\n    if data_format == 'channels_first':\n      # 'RGB'-&gt;'BGR'\n      if x.ndim == 3:\n        x = x[::-1, ...]\n      else:\n        x = x[:, ::-1, ...]\n    else:\n      # 'RGB'-&gt;'BGR'\n      x = x[..., ::-1]\n    mean = [103.939, 116.779, 123.68]\n    std = None\n\n  # Zero-center by mean pixel\n  if data_format == 'channels_first':\n    if x.ndim == 3:\n      x[0, :, :] -= mean[0]\n      x[1, :, :] -= mean[1]\n      x[2, :, :] -= mean[2]\n      if std is not None:\n        x[0, :, :] /= std[0]\n        x[1, :, :] /= std[1]\n        x[2, :, :] /= std[2]\n    else:\n      x[:, 0, :, :] -= mean[0]\n      x[:, 1, :, :] -= mean[1]\n      x[:, 2, :, :] -= mean[2]\n      if std is not None:\n        x[:, 0, :, :] /= std[0]\n        x[:, 1, :, :] /= std[1]\n        x[:, 2, :, :] /= std[2]\n  else:\n    x[..., 0] -= mean[0]\n    x[..., 1] -= mean[1]\n    x[..., 2] -= mean[2]\n    if std is not None:\n      x[..., 0] /= std[0]\n      x[..., 1] /= std[1]\n      x[..., 2] /= std[2]\n  return x\n</code></pre>"},{"location":"framework/#mean-and-std","title":"mean and std","text":"<pre><code>mean = 0.0\nstd = 0.0\nfor images, _ in dl:\n    batch_samples = images.size(0)  # batch size (the last batch can have smaller size!)\n    images = images.view(batch_samples, images.size(1), -1)\n    mean += images.mean(2).sum(0)\n    std += images.std(2).sum(0)\n\nmean /= len(dl.dataset)\nstd /= len(dl.dataset)\n</code></pre>"},{"location":"framework/#datageneratorkerasutilssequence","title":"DataGenerator(keras.utils.Sequence):","text":"<pre><code>import numpy as np\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n                 n_classes=10, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            X[i,] = np.load('data/' + ID + '.npy')\n\n            # Store class\n            y[i] = self.labels[ID]\n\n        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n</code></pre> <pre><code>class ImageDataGenerator(tf.keras.preprocessing.image.ImageDataGenerator):\n    def __init__(self):\n        super().__init__(\n            rescale=1.0 / 255.0,\n            rotation_range=10,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            zoom_range=[0.95, 1.05],\n            shear_range=0.1,\n            fill_mode=\"wrap\",\n            horizontal_flip=True,\n            vertical_flip=True,\n        )\n\n\nclass Generator(object):\n    def __init__(self, batch_size, name_x, name_y):\n\n        data_f = None  # h5py.File(open_directory, \"r\")\n\n        self.x = data_f[name_x]\n        self.y = data_f[name_y]\n\n        if len(self.x.shape) == 4:\n            self.shape_x = (None, self.x.shape[1], self.x.shape[2], self.x.shape[3])\n\n        if len(self.x.shape) == 3:\n            self.shape_x = (None, self.x.shape[1], self.x.shape[2])\n\n        if len(self.y.shape) == 4:\n            self.shape_y = (None, self.y.shape[1], self.y.shape[2], self.y.shape[3])\n\n        if len(self.y.shape) == 3:\n            self.shape_y = (None, self.y.shape[1], self.y.shape[2])\n\n        self.num_samples = self.x.shape[0]\n        self.batch_size = batch_size\n        self.epoch_size = self.num_samples // self.batch_size + 1 * (\n            self.num_samples % self.batch_size != 0\n        )\n\n        self.pointer = 0\n        self.sample_nums = np.arange(0, self.num_samples)\n        np.random.shuffle(self.sample_nums)\n\n    def data_generator(self):\n\n        for batch_num in range(self.epoch_size):\n\n            x = []\n            y = []\n\n            for elem_num in range(self.batch_size):\n\n                sample_num = self.sample_nums[self.pointer]\n\n                x += [self.x[sample_num]]\n                y += [self.y[sample_num]]\n\n                self.pointer += 1\n\n                if self.pointer == self.num_samples:\n                    self.pointer = 0\n                    np.random.shuffle(self.sample_nums)\n                    break\n\n            x = np.array(x, dtype=np.float32)\n            y = np.array(y, dtype=np.float32)\n\n            yield x, y\n\n    def get_dataset(self):\n        dataset = tf.data.Dataset.from_generator(\n            self.data_generator,\n            output_signature=(\n                tf.TensorSpec(shape=(), dtype=tf.int32),\n                tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32),\n            ),\n        )\n        dataset = dataset.prefetch(1)\n\n        return dataset\n</code></pre> <pre><code>def _load_image(self, image_path):\n        image = cv2.imread(image_path)  # BGR\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # image = tf.io.read_file(image_path)\n        # image = tf.io.decode_image(\n        #     image,\n        #     channels=self.num_channels,\n        #     dtype=tf.dtypes.uint8,\n        #     expand_animations=False,\n        # )\n        # image = tf.image.resize(\n        #     image,\n        #     self.dim,\n        #     method=tf.image.ResizeMethod.BILINEAR,\n        #     preserve_aspect_ratio=True,\n        #     antialias=False,\n        #     name=None,\n        # )\n        # if not issubclass(image.dtype.type, np.floating):\n        image = image.astype(np.float32)\n        # image = image.astype(tf.keras.backend.floatx(), copy=False)\n        image = self.apply_image_transforms(image)\n        # 'RGB'-&gt;'BGR'\n        # image = image[..., ::-1]\n        # image = tf.image.convert_image_dtype(image, dtype=tf.uint8, saturate=False)\n        # image = tf.cast(image, tf.float32)  # / 127.5\n        # image -= 1.0\n        mean = [103.939, 116.779, 123.68]\n        # mean_tensor = tf.keras.backend.constant(-np.array(mean))\n        # if tf.keras.backend.dtype(image) != tf.keras.backend.dtype(mean_tensor):\n        #     image = tf.keras.backend.bias_add(\n        #         image,\n        #         tf.keras.backend.cast(mean_tensor, tf.keras.backend.dtype(image)),\n        #         data_format=\"channels_last\",\n        #     )\n        # else:\n        #     image = tf.keras.backend.bias_add(image, mean_tensor, \"channels_last\")\n        # image[0, :, :] -= mean[0]\n        # image[1, :, :] -= mean[1]\n        # image[2, :, :] -= mean[2]\n        image[..., 0] -= mean[0]\n        image[..., 1] -= mean[1]\n        image[..., 2] -= mean[2]\n        # image = tf.keras.applications.vgg16.preprocess_input(image)\n        \"\"\" Preprocessed numpy.array or a tf.Tensor with type float32. The images are converted from RGB to BGR,\n            then each color channel is zero-centered with respect to the ImageNet dataset, without scaling. \"\"\"\n        return image\n</code></pre>"},{"location":"framework/#unfreeze-specific-layers","title":"Unfreeze specific layers","text":"<p>Here is one way to unfreeze specific layers. We pick the same model and some layers (e.g. <code>block14_sepconv2</code>). The purpose is to unfreeze these layers and make the rest of the layers freeze.</p> <pre><code>from tensorflow import keras\n\nbase_model = keras.applications.Xception(\n    weights='imagenet',\n    input_shape=(150,150,3),\n    include_top=False\n)\n\n# free all layer except the desired layers\n# which is in [ ... ]\nfor layer in base_model.layers:\n    if layer.name not in ['block14_sepconv2', 'block13_sepconv1']:\n        layer.trainable = False\n\n    if layer.trainable:\n        print(layer.name)\n\nblock14_sepconv2\nblock13_sepconv1\n</code></pre>"},{"location":"framework/#compute-the-trainable-and-non-trainable-variables","title":"Compute the trainable and non-trainable variables.","text":"<pre><code>import tensorflow.keras.backend as K\nimport numpy as np \n\ntrainable_count = np.sum([K.count_params(w) \\\n                          for w in base_model.trainable_weights])\nnon_trainable_count = np.sum([K.count_params(w) \\\n                              for w in base_model.non_trainable_weights])\nprint('Total params: {:,}'.format(trainable_count + non_trainable_count))\nprint('Trainable params: {:,}'.format(trainable_count))\nprint('Non-trainable params: {:,}'.format(non_trainable_count))\n</code></pre> <pre><code>Total params: 20,861,480\nTrainable params: 3,696,088\nNon-trainable params: 17,165,392\n</code></pre>"},{"location":"framework/#tensorflow-macos-releases","title":"tensorflow-macos Releases","text":"tensorflow-macos tensorflow-metal macOS version Features v2.5 0.1.2 12.0+ Pluggable device v2.6 0.2.0 12.0+ Variable sequences for RNN layers v2.7 0.3.0 12.0+ Custom op support v2.8 0.4.0 12.0+ RNN performance improvements v2.9 0.5.0 12.1+ Distributed training"},{"location":"git/","title":"GIT","text":""},{"location":"git/#readmemd","title":"README.md","text":"<ul> <li>\ud83d\udc4b Hi, I\u2019m @furyhawk</li> <li>\ud83d\udc40 I\u2019m interested in AI</li> <li>\ud83c\udf31 I\u2019m currently learning AI</li> <li>\ud83d\udc9e\ufe0f I\u2019m looking to collaborate on AI</li> <li>\ud83d\udceb How to reach me ...</li> </ul> <p>https://github.com/furyhawk</p> <pre><code>git config --global user.name \"furyhawk\"\ngit config --global user.email furyx@hotmail.com\ngit config pull.rebase true\n</code></pre>"},{"location":"git/#commit-msg","title":"commit msg","text":"<pre><code>&lt;type&gt;: &lt;short summary&gt;\n  \u2502            \u2502\n  \u2502            \u2514\u2500\u2af8 Summary in present tense. Not capitalized. No period at the end.\n  \u2502\n  \u2514\u2500\u2af8 Commit Type: build|cicd|docs|feat|fix|node|refactor|test\n</code></pre>"},{"location":"git/#fetchpull-all-branches","title":"Fetch/pull all branches","text":"<pre><code>git branch -r | grep -v '\\-&gt;' | sed \"s,\\x1B\\[[0-9;]*[a-zA-Z],,g\" | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\"; done\ngit fetch --all\ngit pull --all\n</code></pre>"},{"location":"git/#how-can-i-enable-github-notifications","title":"How can I enable github notifications?","text":"<p>install and authenticate with the github cli:</p> <pre><code>pacman -S github-cli\nbrew install gh\nsudo apt update\nsudo apt install gh\n\ngh auth login\n</code></pre> <p>ubuntu:</p> <pre><code>type -p curl &gt;/dev/null || (sudo apt update &amp;&amp; sudo apt install curl -y)\ncurl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null \\\n&amp;&amp; sudo apt update \\\n&amp;&amp; sudo apt install gh -y\n</code></pre> <p>reset to last working commit:</p> <pre><code>git reset --hard &lt;last_working_commit_id&gt;\ngit push --force\n</code></pre> <p>working with submodules:</p> <pre><code>git submodule update --init --recursive\n\nThere are four steps involved when you delete a submodule.\n\n# 1. deinit the submodule\ngit submodule deinit &lt;submodule_directory&gt;\n# 2. Remove the submodule directory from Git\ngit rm &lt;submodule_directory&gt;\n# 3. Remove the submodule directory from .git/modules/\nrm -rf .git/modules/&lt;submodule_directory&gt;\n# 4. commit and push the changes\n# add submodule and define the master branch as the one you want to track\ngit submodule add -b master [URL to Git repo] \ngit submodule init \n</code></pre>"},{"location":"gpt/","title":"gpt","text":"<p>https://github.com/furyhawk/nanoGPT</p>"},{"location":"gpt/#train","title":"train","text":"<p>python train.py --dataset=shakespeare --n_layer=4 --n_head=4 --n_embd=64 --device=mps --compile=False --eval_iters=1 --block_size=64 --batch_size=16</p>"},{"location":"gpt/#logs","title":"logs","text":"<p>iter 432061: loss 3.3774, time 102.72ms</p> <p>number of parameters: 3.42M No meta.pkl found, assuming GPT-2 encodings...</p> <p>The state of heaven with him yet have set The enam received in his power, It will be such,morrow; if he be By common enemies, so may not do, you As if you mark the truth.</p> <p>FLORIZEL: Why is my part; Not here my life, we'll do't, where it is The lark that the Earl of Warwick is slain: On bold, my rest, my liege, in whose good time I'll drown him worthy me to my Earl towards, Is Come to draw to scARD a fearful day. 3 KING HENRY VI</p> <p>KING LEWIS XI: What! canst thou live in poor soul, To do him banish'd at the same our point And the freshinks I come, 'tis aught to have but I fear you joys: all that I cannot On thee would of my heart, my poor soul, To be so bold a knave in this time; And thou by, she's children's blood, only, it is To see my life.</p> <p>MARIANA: A thousand part, indeed, sir, a time As you will wonder not: come, my liege, I well; And he is too a gentleman. See that with the voice that at once, you must Flried the senators of the any it good to us being son: but, I cannot be done; but we can tell him; for him I'll draw your words together. What you will know how you?</p> <p>COMINIUS: They are, uncle.</p> <p>CORIOLANUS: Therefore, my gracious friend, I am the farther un ches: What, poor! I beseech you, let it be a cousin.</p> <p>VOLUMNIA: Tush, the gods!</p> <p>MENENIUS: I am too! Nay begin to bid my lady play well: I am no pity that willy heir is right; But, by his leave I have or why it is.</p> <p>CORIOLANUS: Not? let me see, you are strange? They have made no more than all. Hath my wife's lord, upon pain of death.</p> <p>Third Citizen: Why,</p> <p>I shall have had some heard of you hear.</p> <p>QUEEN MARGARET: And so we all, I thank thee: 'tis more; Thou art the letter, and thou hast not so: wouldst be done, hark you, I know, my soul here have t something So to say, but I pray, and no more.</p> <p>ISABELLA: O, if it were full of such deep Norfolk, love, I would have more than his gracious fault Than Angelo first to you at great comfort.</p> <p>ANGELO: Yea, and make you he crook 'pt TrleKE: I'll make.</p> <p>Provost: What, my general?</p> <p>DUKE VINCENTIO: 'Tis like of his most, And leave me to the will for my poor side.</p> <p>ANGELO: Hath the king'ster heaven with the majesty of tears, With a kind: I have, my lord, must die.</p> <p>MARCIUS: Tell me hate them not, honesty are there To entreat of my wife, and my son to my order, And set the mother all my father's consent To make the must fly: so go: From whom that I would not, I do not fear, As well I will have me, you are vile toward.</p> <p>QUEEN MARGARET: But, by your vouchius, I fear not what I am: For since we came, your father's, at the least?</p> <p>Second Servant: Tis more than this of you can but have done My love or mercy to the queen of heaven: But I have forgot it, more, goodenio.</p> <p>CAPULET: Ay, as the matter I told you speak, my lord.</p> <p>BALTHASAR: But to the case of the Tower.</p> <p>ROMEO: Never; live, my lord, my soul is as well: I hope, by this which is a villain, When that thy brothers Romeo is, one sun With thy mother's wife, that I may return To know me what a dream hath as well As she run thought to be your mother, I I may not need to my sweet,</p> <p>CAPULET: Ay, what art thou?</p> <p>ROMEO: A queen, nurse?</p> <p>JULIET: Good lords, If thou dost know ye but.</p> <p>JULIET: Say, that Richmond's soul, take me in all.</p> <p>ROMEO: O, Romeo, I will not weep a while.</p> <p>JULIET: For the defry of grief makes them fair: But since unsapblful villain's wit of heaven It was a friend for ever-day, When I was lawful oath and not so, I am born to do it would it might be, I am revenged on-hearted my leaves dead king's oath, For the wantless blood whose heads must enter: 'Tis the Lord Northumberland that King Edward was himself, The Duke of Warwick, and his place in France, And thou shalt come to my will-day shall not stay.</p> <p>HENRY BOLINGBROKE: Why, howof, I beseech you talk of, Here must I play my heart with a cruelay; That doth not fall dead, I know the matter.</p> <p>DUKE VINCENTIO: You had even like'd, fie me, 'tis, I am resolved: Nay, unadBe now, I have heard her speak more than you I speak at peace.</p> <p>ANGELO: Well, I do beseech you, fair sir. Your eyes will not come upon me: he is most man, it is not so: so most much little most wrong, and may go to that by: which you have therein your hate, we may see themselves.</p> <p>LADY CAPULET: We are in prison, one word; ask him; For some you win me, upon his best: You know no better for the mind, there's no matter  stands on him.</p> <p>DUCHESS OF YORK: How wouldst thou?</p> <p>Messenger: My gracious lord, I like youThis.</p> <p>DUKE OF YORK: Is it not dead, cousin.</p> <p>DUCHESS OF YORK: Then 'tis shame forAnd all that thou wast?</p>"},{"location":"gpt/#king-r","title":"KING R","text":"<p>DUKE VINCENTIO: Romeo.</p> <p>Provost: It do trust me.</p> <p>ANGELO: Our lord, I cannot speak the good word: Since I havewas not it, I do'll therefore know Will a divineade me speak.</p> <p>ISABELLA: O, let me hear what you did deliver, By 'twere pity to him. This friends, be his head it, with one that's no matter, look to me as this lure of the prince a curse; more stands on't; No, sir; not a very weak of mine, If not that. Now, andso death's like death! I see, and hear Montague, my Montague. Who knows thou nothing; be not gentle, I may not, yet they shall be so, then; And had he come'd withAnd the oracle: I'll have your heart: that I shall follow that send him; that, we will warrant you, andPEY?</p> <p>ELBOW: Nay, he shall get a man to me.</p> <p>ELBOW: Look, very well, he shallEL' the better royal, which I do do't But I shall find, a time will be from his spirit. I prithee, take one: give me not your comfortier: I will not be come to-morrow; let's entreaty?</p> <p>ROMEO: I beseech your grace, sir,--</p> <p>BISHOP OF CARke, my dTwere 't.</p> <p>BUCKINGHAM: I will, my lord: nay, You will have you go with me to please again.</p> <p>BUCKINGHAM: You will not hear duty, but for I will, sir, You have not the lady will with thee love But what you may! You are sure of he is to be a doth valiant; I will wot the prince: and have first to-morrow then.</p> <p>ANGELO: Thy business is the more and that my brother's sister.</p> <p>ISABELLA: It cannot be so.</p> <p>DUKE VINCENTIO: I say you, well; for if his present is the</p> <p>WARWICK: And thou wert enam'd; I'll not be mine own?</p> <p>KING LEWIS XI: What man is none than that at his house, That bear their down heart to Edward's-t thou him?</p> <p>WARWICK: Bid me, noble lord, our friends are fled, And sit to be true; and with all our sonsiss, From forth the most defend in theile departedath Be not born to make a husband as if I send it to thought that I did weep, And quench blood or not well.</p> <p>KING RICHARD II: O I was Clarence! What'sFL words were it: That I, as we are, that they have no friend, Even in the blood of heaven of fight, Thou p country's blood and'd. Come, and go with thee go; And, as mine I remember as any man's son As merry as I told the people and am mighty As'd an hour begin and bears our hands, But shame no other Paris and her be drawn.</p> <p>ROMEO: Is my long come. carry, let'st thou father In this remembrance of love: thou eat not 'em most noble swear tongue for what thou mayst, not wert between. The Earl of heaven of Warwick's love, this man, That's hearts, the true king, myMON and Sir. And unlook'd in the princess slain, Is beg of hen, and did yield in their arms At no moreOR create give from their hands, For the dead George of Clarence to his king, Who spake me his enemies shall hold it.</p> <p>BUCKINGHAM: My lord, my gracious lord, You had a power of wisdom cam thou out of mine?</p> <p>KING RICHARD II: He hath enem this, people, but I'll win me.</p> <p>CATESBY: Then here, my lord.</p> <p>KING RICHARD III: Nor I, the crown that queen is slain, To take the devil of our other linean ground, Not his our kingly curse people's-Which they that Is put to have open honesty Either to come in their arms.</p> <p>QUEEN MARGARET:</p> <p>ANTIGONUS: Hear you not?</p> <p>First Citizen: Come, sir; go, be it must none but you: I am ta'en and leave of you; and, then, go with me.</p> <p>First Servingman: Why, we will, sir.</p> <p>Second Servingman: I would not, no more: the provost.</p> <p>Third Servingman: What's the matter?</p> <p>Third Servingman: What's the matter?</p> <p>Second Servingman: No, my master, I can tell; I know how it you, thereof he m it.</p> <p>Clown: He's here; we should be a witness to the purpose.</p> <p>Third Citizen: He hath done what you are done.</p> <p>Third Servingman: A Romeo, sir, for them he would have found baw Rome of the world.</p> <p>CORIOLANUS: But I love the child, Not that thou hast other of thy life.</p> <p>Third Servingman: If thou she were thrice a man, And had these griefing force royal royal queen; And I am son, and I love thee myself.</p> <p>KING RICHARD III: But I will be poor; which he is he made?</p> <p>BUCKINGHAM: My gracious lord, let's see your grace be company.</p> <p>KING RICHARD III: Why, what a fellow should be?</p> <p>BUCKINGHAM: My lord, 'tis a subject, proud Which else, which, had some him, it will with heaven Till wind manage our doth made over his land. Why, proud I have ta'en the service of the people, That would not have more better that, Which will be satisfied; and, how his ignorant shouldER' He seems not? and I have had rather thy, To do my country, to make the'd right, With all the envy of this loyal, Our holy and be England and Duke of York, Not in his second soul I and have been The which never bid us, and call King Richard's lord.</p> <p>HENRY BOLINGBROKE: Welcome, uncle; we shall not be unto him; But so, my good son, I</p> <p>I do further.</p> <p>KING RICHARD III: Why, then, I confess thee, lord, If thou hadst never yet thou yet hadst never, But yet thou wilt wert up in thy horse.</p> <p>CLIFFORD: Clarence and Gloucester, I will not bethink, But that's not yet did nothing: but the gods The times of revenge!</p> <p>RICHARD: Nay, bring me what ancient, and this hand.'</p> <p>KING HENRY VI: But, to thee speak commonth very day!</p> <p>CLIFFORD: That thou wert so disgraced me to me.</p> <p>KING HENRY VI: Woth he the oath that I should tread upon our way?</p> <p>CLIFFORD: What may your grace in poor Henry's life and him?</p> <p>WARWICK: No, like a bawd, you not so; and, and for the poor one did, he is even to give his l.</p> <p>WARWICK: Uncle, so: I do intend to him in all, I hope.</p> <p>KING HENRY VI: How far I mean? if this be so bold with! The which, his queen, the queen, his love; And so, gentle king, may they do you in at night And fly him in the slander of his king, To be revenged on him that, so should you have; For, by this way be you found you to, She's a woman.</p> <p>ANGELO: He will not see you, sir.</p> <p>ESCALUS: I am aTo your request in hand, you shall in arms You must give, and yet go by, a course it is thence.</p> <p>ESCALUS: LARTI not mock mine own good.</p> <p>ANGELO: Do you hear. The duke hath forgot you for what you are?</p> <p>ESCALUS: BUS: for whose offence?</p> <p>CORIOLANUS: What to you?</p> <p>CORIOLANUS: O, worthy madam, And have I too most, you shall not.</p> <p>AUFIDIUS: Worthy sir, farewell.</p>"},{"location":"gpt/#vol","title":"VOL","text":"<p>Had not himself, nor known she!</p> <p>Provost: An me, both that; he did, sir, to steal-on Her mother's Romeo! O old faithful friar!</p> <p>JULIET: Why do I more than that I should never speak of.</p> <p>ROMEO: Nay, rather give me leave me that I will; For I shall find some better happy days Than lay, a man.</p> <p>FRIAR LAURENCE: But slain, her hath the next day a little.</p> <p>ROMEO: Nay, good woman; my turn in thy sake art full nights here. Who is dead and young prince. Ah, how, dost thou find me to thy breast, Thine hast he, and more, a noble fawd. Sir, thou canst not speak, I wouldst thou wert For sleep the mark of thy deadly years? Ah, keep'st, asLord men, thou hast got By so thy voice: there's no power, it is none honest.</p> <p>MERCUTIO: Tybalt, Romeo, whom I have the best I think how I have done.</p> <p>ROMEO: Thy life art thou, that thou art too fair!</p> <p>BENVOLIO: Mehe, and go not in 't.</p> <p>MERCUTIO: Nay, I'll bring some noise for a for that.</p> <p>CLAUDIO: Your face? aarer is a traitor's head to pluck him to the king the house. But which you can do I have to the hand; for it will be, as I am and a block withFor a man that Claudio hath married, If be a uncle.</p> <p>DUKE VINCENTIO: He did know more. You are most little more, he hath done it well, our the city and do them to make me theD:' Aufidius come to me and brother; and she isome with those that hath been, 'twere pity us all. Then, soft, wot each that am aly; For now I did well know. My mother!</p> <p>LEONTES: What's well man?</p> <p>CAMILLO:</p> <p>KING RICHARD III: Be not so?</p> <p>HENRY BOLINGBROKE: So that of God he would have the king his!</p> <p>BUCKINGHAM: I'll make more  than my gracious case: I will bear the deed.</p> <p>KING RICHARD III: tis you by king, I would am I bethink, To make an amissant in love That thou wouldst protest to keep post toOR'n; And thou he is not nowSo.</p> <p>LEONTES: Unman, it is; Nay, good my good lord, be satisfied still.</p> <p>LEONTES: A most business: Let me have been since I was to be mercy; Whiles the lark-f orth-she, He cannot, Marcius worthyKE: 'tis well stock no poison. The manner of the envy he spake to Marcius, That with the power is worth dead, the doth be brief, In worthy Romeo hastous tune up.</p> <p>KING RICHARD II: Whom was it so, my child is set on death.</p> <p>HENRY BOLINGBROKE: ClOR, my lord; With late that cons news, for, to that I would Trueass the great number pardon'd, from your head  already're his mind i' the there, I will.</p> <p>DUKE VINCENTIO: You do but see your highness of your arms Would know the king's mouth with peace.</p> <p>MARIANA: I mean, a son, it is not a word  through a tear for Claudio, and be banished; But when you bid this manner bless us, In whom we have had been wont to do, 'twas upon the business, you I shall call'd his friends to him, and then.</p> <p>DUKE OF Lord: He's tearsark; for long my gentleness' I let me hear; good cousin, adieu! Belike his hands I in his remedy; And I have died to face, my love to me, And I will make him leave of can say, I had rather keep their words with him to keep him Whither, to thy fortune but put off;</p> <p>And see that this terror may be so, So if that cannot: so that's the friend, That will be deservedly of your honour's life, Let thy rage here cut in his grave; One side do not.</p> <p>MENENIUS: Hath the people's great state by power, That they shall have set up a part; But, as minetis the nothing of a man, That is the deputy,tis well for fault, And breathed his honour with the fear of death, That all for that as you are, and we may live.</p> <p>BALTHASAR: A pretty fardman!</p> <p>RICHMOND: Bid him be here? and I'll make me pardon up.</p> <p>RIVERS: What, hast he not?</p> <p>BUCKINGHAM: My lord, my gracious lord.</p> <p>KING RICHARD III: As I remember; against thee, thou wert not so much done, That thou canst swear and thee, for thou hast no cause.</p> <p>RATCLIFF: I will not be not, my lord.</p> <p>KING RICHARD III: Ay, O my children, my eyes!</p> <p>BUCKINGHAM: No, mighty lord, I hope, shall understand it.</p> <p>KING RICHARD III: I know no? but himself he is done; The side must be seen and make me wrong.</p> <p>QUEEN ELIZABETH: That thou mean I sent to see thy life To have no more fit than it is in this world To look upon thy brother's make me hear, The Duke of Norfolk; if thou darest with Thy Lord Northumberland, rouse'd and thy crown, For thou shalt no life but by thy kingdom.</p> <p>KING EDWARD IV: But thou, in my turn, my grave jest thou, You, the newats, and have the ears, Where fruit men have done-bended, then my daughter Of happyness! O my woman! If thou didst, thou tis'st fair a piteous, which he was, And know not 't prove a thousand right while you That you are to have something: so, my kingdom, 'Tis just that I</p> <p>iter 506998: loss 3.5516, time 71.91ms iter 506999: loss 3.6803, time 72.24ms iter 507000: loss 3.3026, time 72.24ms iter 507001: loss 3.4185, time 71.62ms iter 507002: loss 3.6271, time 73.12ms iter 507003: loss 3.5836, time 71.73ms iter 507004: loss 3.1981, time 75.92ms iter 507005: loss 3.6141, time 71.98ms iter 507006: loss 3.2294, time 73.99ms</p> <p>number of parameters: 3.42M No meta.pkl found, assuming GPT-2 encodings...</p> <p>The state of heaven with him, and that his body is humray'd this.</p> <p>WARWICK: And I.</p> <p>DUCHESS OF YORK: My dear lord,</p> <p>DUCHESS OF YORK:</p> <p>HENRY BOLINGBROKE: As far go we as any we toOL?</p> <p>HORTENSIO: I think she is well: then will you have so: I would we were not been then in war's good.</p> <p>DUKE VINCENTIO: We shall not be still be gone and been to see.</p> <p>GREMIO: And your good lord, I would all and like you; and in your hope.</p> <p>ISABELLA: I can know the truth, I am your father's house.</p> <p>DUKE VINCENTIO: It is no gone, sir?</p> <p>LUCIO: I think I would, sir, I know say, I am a friendlike by him: it is the very much of your blood; if Would I be well show'd of you in the bosom And our new-a.</p> <p>Provost:</p> <p>MAMILLIUS: My lord, I'll warrant thee a holy heart: which's with mine, I am too good to him.</p> <p>LEONTES: I am none; Sir, for your son I have here in this business To the justice of your father's worth.</p> <p>PAULINA: It is my gr in that I were, To the most of your own: your therefore have Be consul: Come, come, go, go, be much here too much: I am no more.</p> <p>LEONTES: They are such a and the and yet.</p> <p>HERMIONE: The better, sir; I am an't that you have notity.</p> <p>LEONTES:</p> <p>LEONTES: Well, well, what!</p> <p>LARTIUS: I am so.</p> <p>PAULINA: I pray any I, sir?</p> <p>PAULINA: Alas, poor woman! What ha</p> <p>HENRYHAM: Too true Clarence was a holy bed.</p>"},{"location":"gpt/#camillo","title":"CAMILLO","text":"<p>I shall have had a brother of your son, To yield your brother's brother.</p> <p>LordOUCESTER:</p> <p>CLARENCE:</p> <p>KING EDWARD IV:</p> <p>KING EDWARD IV: Why, then, think you what: go-morrow, son, That you must not do that I am just, For when you can, my lord, my brother, Henry With your brother, if he bring end to your last. And, high-ed, if you see her you do, He would not have been thus an whose speak With that most un Butice: I would, he were born, a name: The house of him I'll speak to see your wife's.</p> <p>DUKE VINCENTIO: 'Tis not her in, sir, his friends, which Of wrongstAName to the earth, with a little way.</p> <p>ISABELLA: I am so mither'd by the point of it That I have had.</p> <p>DUKE VINCENTIO: O, let me think; and let me see a word.</p> <p>Provost: I wouldISABELLA: Wilt thou not, then, not in a very kind for a very for me that I did use me from him to speak. And I beseech your majesty and your bosom And my great opinion, have a wife and father, Unto my brother father and my well.</p> <p>FRIAR LAURENCE: And there is my hNor talk'd be no sworn to death But that I should think 'twack the part of you In the duke's daughter.</p> <p>Nurse: A love a man that his blood is more a life Than this may standow make her false friends. Nay, more farewell; I not for't; Our unf shors'll ask you: come by the man-likeent of this lady is the least, But to the everatter of me dearest day, Or me but one earth, like a thing that Not so much sorrow's, as many more is true Than this in his own! as our bthe light As I do! What's in all my shame  already may in openings! You, my sweet</p> <p>HASTINGS: Be early what would you say to our lord?</p> <p>YORK: It is not so.</p> <p>GLOUCESTER: It is.</p> <p>LADY ANNE:  sweet my old grace, that thou follow'st!</p> <p>GLOUCESTER: And, for God's sake, till you are three years.</p> <p>LADY ANNE: What, prince?</p> <p>GLOUCESTER: No noble thing I should be a happy king?</p> <p>GLOUCESTER: Away with him!</p> <p>DUCHESS OF YORK: My lord, I must not need: Yere to my children's love's loss of thee, But thou, even to the king, thou thy doubt'st tongue.</p> <p>KING RICHARD III: What is't o'So?</p> <p>DUCHESS OF YORK: I, by my life, I have done, but so in once For in the virtue of our blood: without that kind Was never so far gGLOUCESTR well, And I will follow him.</p> <p>DUKE VINCENTIO: M King Richard, give me leave to my thou thou go Be at home of these good fairWARD. But of what, thou dost to do Edward!</p> <p>B vouch'd: My lords, more than you shall please our royal name.</p> <p>LORD ROMASET: So, to save the king; yet he's just, And come, to answer me in him my country, And you shall have you where we did say the prince?</p> <p>DUCHESS OF YORK: My Lord, may you do this dangerous lady, My father's heart, which your hand did thee yet be The first one of this noble Edward's king; And yet that is no more: come to thee, For I am we of my your love.</p> <p>KATHARINA: I have a very.</p> <p>KING RICHARD III:  sadful lord, and his part-f ready I come To make the king a king from him there is That he's made good. Come, let you go; But there be 'twere noIC at you all; But you shall have</p> <p>France, for honour; if you were now have My body hath done to banish yourself, To prove a good will-dew heart, Wherein my noble prince was comfort To make a man's name and a great bed: 'Tis well aKINGBe, he's in a child I'll be by my husband; let me she: I'll have it if I use my sake. Why, how, let is in that sword this traitor!</p> <p>HENRY BOLINGBROKE: Richard, help! but more than his that I'll make my tongue to love thee such life As thou art to Romeo.</p> <p>KING EDWARD IV: This? but doth he not Edward's death's death!</p> <p>HEN MARGARET: It is more than no more yet than by it.</p> <p>BUCKINGHAM: What, is it so?</p> <p>GLOUCESTER: I shall be there was in my heart With gracious lord and my good lordle brought He is well: but I hear you will Give me to my duty, to the world.</p> <p>First Murderer: Because thou canst love, that ever, thy love, thy child, Thy man shall take a grave on thy wretcheding. Fare not thy sword, content Camillo, give Of your she on a my master and son; And here, I beseech your highness,--</p> <p>FRIAR LAURENCE:</p> <p>eyeTYou may my kindred again!</p> <p>ROMEO: A good things still, this is this day's run Doth never speak,--ces nay, For I have seen thee very like a fard blood, This were thy poor, which bestELLIO: Let the more be put, sir, play in, I'll tell you is Edward in such deep men!</p> <p>KING EDWARD IV: By heaven, I hear no more: my brother's heart.</p> <p>HEN ELIZABETH: I am come to have a more worth in this.</p> <p>KING RICHARD III: Allak thou, God! it is not my son.</p> <p>QUEEN ELIZABETH: There is no more I swear than they shall  grief is so.</p> <p>WARWICK: And thou and that Romeo's and thy son's face, That thou shalt thousandame in thy rest, Whose father's heart, of grace and heart's blood is come, And with the tongue that did not be there.</p> <p>BENVOLIO: T Gm would cause, I wouldsthip wish it true.</p> <p>ROMEO: Is thy life- vouch's own word.</p> <p>MERCUTIO: My lord, I'll take thy choice to go Hath yet with an heart-day's death?</p> <p>BENVOLIO: I dare not for the best upon thyPle I talk of thy Ver lives. Come, let's not A noble man: For she hath yet a man to fall?</p> <p>ROMEO: Thou art not so well:OM pity her: But he's an but one.</p> <p>FRIAR LAURENCE: WithSecond, sir, a thousand duke's of idle hand; But I am sworn to it I should not stay, To be a life as thy honour's love: But let me rest?</p> <p>JULIET: This will be, to put forth; there is no man.</p> <p>DUKE OF YORK: Well, me for mine; let me by till thy husband I have no brother, till I am not a king's son: For I have done, I here hear you speak: By heaven, I am a beg by my life, So far as most in a man that's the mour of! O, that I would be less! the great which o' the honour, And that I had; but then, I am a-beLEath slain, Were kill my takest! If never, run Aufidius, 'Tis thought it would you are at enmity That you did but so much is, and And I'll lay down out whose't be fullle In such most I have kill'd his have been such his, As so in the world is dead.</p> <p>Messenger: The man that he is our lady.</p> <p>KING RICHARD III: He kill, my lord; who, we could not say 'ld have so much. Come, come away.</p> <p>Of God's name and our fair?</p> <p>'Tis oath?</p> <p>TYRSON: He's lord, my daughter; but I doubt not more, Farewell; and 'twas it be before I did Or not a one that she is not to be thy tNor in a thought of the world was not  enough to be the king.</p> <p>Provost:</p> <p>DUKE VINCENTIO: How?</p> <p>DUKE VINCENTIO: O, let me go my lord, I would youheeio her, prince, of you, And make me be seen to the people.</p> <p>DUKE VINCENTIO: I do believe it, to grant and love me My state English yourself, being full of your love! O prince! one of you a man that I must not all be the king, which is mine and him.</p> <p>LUCIO: But, madam, an'tess'd by the do break your honour.</p> <p>DUKE OF YORK: I, for an Murd--</p> <p>KING RICHARD III: What! what goes this? at' lie I'force?</p> <p>DUCHESS OF YORK: I would I had a poor day for- thou art made it.</p> <p>DUCHESS OF YORK: I should I will love thee any Isabel, If I have seen the king.</p> <p>Provost:</p> <p>DUKE VINCENTIO: Good Romeo, Romeo: 'twas done, As that in any man have done to you wretch with him: So, well I desire it, to my heart Is this the day of Edward's wife: Thou most Richard, I fear me, Thou wilt make thee as thou wilt be a thousand As I am, as most gentle for ourselves: To this my husband's fair day, my soul, I therefore let her stay with heavy kiss: And, as I could, but I would, my good lords, Ere you be king in oath, and my death.</p> <p>LUCIO: Why, how thou hast done this man with thy love! Farewell! thou dead too, what 'twas no time Thy other blood should come; and with that</p> <p>WhosePOL know to fain: 'Tis so false, to beg mercy, their pluck'dine side For their goodILL'er's hands.</p> <p>POLIXENES: What, be there enough' the king with the king: Clarence other m O Warwick! if it be done, And that my good cousin, I wot that I know.</p> <p>LEONTES: How can you think! We must be this be you; this power are My true son, my brother.</p> <p>AUTOLYCUS: Here's he that did keep her to be: he's a par and a the duke; he is very well said, he doth: He had not so, I do fear.</p> <p>AUTOLYCUS: I may say, sir, my queen, dear love.</p> <p>Clown: My lord, you will, by my life, a word; the he duke's daughter's wife!</p> <p>MAMILLIUS: I have not been i' the lie.</p> <p>DORCAS: I know thy canre so.</p> <p>POLIXENES: O my lord!</p> <p>MAMILLIUS: No, my good Paulina,--</p> <p>DORCaius out,--</p> <p>DORCLEY: So much to it, sir, that it may be received To the sons; your pleasure where, the king's heir, Have he been nothing to be depose, But the poor law so far the rest is dead.</p> <p>KING RICHARD III: Ay, if I have Clarence's bosom forth.</p> <p>QUEEN ELIZABETH: WhyWARD, Well, pray, go with us? he is very comfort.</p> <p>RIVERS: No, as the devil'st I am no more more; But I shall have heaven with my life to go.</p> <p>QUEEN ELIZABETH: How long the justice of the earth is not mine?</p> <p>GRUMIO:</p> <p>prison does: Come, sir, it is no more.</p> <p>And the rHAM: My flum, will tell your Lordhip; here is mine ToWARD; and yet I then lay at arms.</p>"},{"location":"gpt/#york","title":"YORK:","text":"<p>God save your lordship to his own Lord Hastings! I but on such right and said 'tis well.</p> <p>KING HENRY VI: O, then, I'll away thy life to bear.</p> <p>QUEEN ELIZABETH: Come, come, come, let no longer, call to our daughter: For now the news is come.</p> <p>KING RICHARD III: O, but the father that is the king, The love for maid truth: 'tis in the needful Richard' death?</p> <p>QUEEN ELIZABETH: Nay me, gone, go with me, in good I'ight in thyAnd shall the sound wrong.</p> <p>KING RICHARD III: So much theseford still he is: His name is troth thee well my death: What, that is not so much, any of thee and let me think she hath no further As, nor any soldier, nor pardon, But that was she hath done, she should be.</p> <p>STANLEY: It is no more of your bed hath best not true.</p> <p>KING RICHARD III: Hath there been, and die out, so much to me The word of a love: what art thou?</p> <p>Second Lord: Thy father lives, that therefore can not be I take theUTA way out of our offer, And, as I say, for we shall not stay.</p> <p>LADY CAPULET: O my hand, a fault will be more never heard Or else moreare.</p> <p>CAPULET: Under this boy, she is of the Duke of York's son He live from mine honour and his blood'st To take us good; and, with much subject Like to the cause to be thus.</p> <p>LEONTES: You have content'd your most mostday To speak your ownness and my soul.</p> <p>LEONTES: Why, the Lord Angelo, So York, as it be father, for his life, To call them hope 'twere yourself and dangerous.</p> <p>CAMILLO: Why, what a thing?</p> <p>LEONTES: Was everBut in such a time of her, Or in a good will of this unisest?</p> <p>KING EDWARD IV: What, lords?</p> <p>WARWICK: And Warwick Clarence at the eyes of justice!</p> <p>KING EDWARD IV: Why,ere no more.</p> <p>CLARENCE:</p> <p>GLOUCESTER:</p> <p>CLARENCE:</p> <p>HASTINGS:</p> <p>KING RICHARD III: Death, brother, are you through my soul Sray to me, and leave me to my uncle?</p> <p>KING HENRY VI: This is thy brother's son in want these hence, Lest as I say, his Earl of Warwick, And tell himself to the Lord king to him, And he had been the will This comes.</p> <p>QUEEN MARGARET: Why thy words have there the blood for this land In that thy heart that should have. You, God's right I should have needful nothing set upon, Theself I am: and yet thy doth--</p> <p>QEN ELIZABETH: O nothing, that my lord Richard will have.</p> <p>KING RICHARDISET: Yet, as I come!</p> <p>KING HENRY VI: I know the name do march.</p> <p>QUEEN ELIZABETH: O, I wilt thou not know that sorrow hath To hold the world with thee, and make me think How I am of thine.</p> <p>KING RICHARD III: In whose from all the shame of save, ThatCORIOLANUS: Why, how's there,--</p> <p>VOLUMNIA: Let's hear your heart?</p> <p>MENENIUS:  much for my very word, I'--Come, let's go: I am please her I shall do it, sir.</p> <p>MENENIUS: It is a cause, Pray you, get your words.</p> <p>BRUTUS: What, our good lord?</p> <p>SICINIUS: He shall, you shall be; he are three gods Is full voice.</p> <p>First Senator:</p> <p>MENENIUS: Ay, but I will go.</p> <p>First Senator: I know your Rome.</p> <p>BRUTUS: Is the news prove true, my lord, and thySo, as I</p> <p>And see that this beable and mostadman: Hath not a high Mercutio? That's more to say 'twere well;' which I pray I am too more than some, but so good For one to be done.</p> <p>LEONTES: We know my friend, I am theWhat I of your body, if But who youath done the noble duke, But what is done.</p> <p>LEONTES: Good Marcius, you have lost thy devil, to lie all Good night.</p> <p>POLIUS: The people did.</p> <p>SICINIUS: Are you all Aufidius?</p> <p>First Senator: You would he were dead, but not so much I: But now I'll call for it.</p> <p>MENENIUS: Well, well, no more.</p> <p>CORIOLANUS: As I had forgot the world, you have not a kind of love Must be a child to be satisfied, For you being no man to her death.</p> <p>BRUTUS: Away! the arm Of your fair wife'st, For she was my enemy. What doth the man!</p> <p>DUKE VINCENTIO: But makes him, good father, Thy poor prisoner is your time, I'll have a brother of a son too; The side are all betwixt me and his brother. And I have need not; and, as I am not The goodly gentleman is too, do not But else 'INCENTIO: O,en O, good me, indeed and I'll thank thee not no He hath deservedUKEill live to do this; And, if this beNORine no man's death is cold.</p> <p>AUTOLYCUS: Away! he is not made good, sir.</p> <p>DUKE VINCENTIO: My heart, my good lord, did't not't.</p> <p>ANTIGONUS: It is of this; We know of you are now.</p> <p>Servant: My father is at hand, Who came Camillo: 'Tis goodly: I'll be the bosom on the world: When the common misfoler of this battle, To</p>"},{"location":"gpt/#iter-599988-loss-28334-time-7135ms","title":"iter 599988: loss 2.8334, time 71.35ms","text":"<p>iter 599989: loss 3.3947, time 71.09ms iter 599990: loss 3.6317, time 72.32ms iter 599991: loss 3.5352, time 74.15ms iter 599992: loss 3.2102, time 72.34ms iter 599993: loss 3.5483, time 71.71ms iter 599994: loss 3.5832, time 71.76ms iter 599995: loss 3.4675, time 71.01ms iter 599996: loss 3.3202, time 71.27ms iter 599997: loss 3.7681, time 71.95ms iter 599998: loss 3.6641, time 74.20ms iter 599999: loss 3.8146, time 71.89ms step 600000: train loss 3.6565, val loss 5.9145 saving checkpoint to out iter 600000: loss 3.3908, time 193.50ms</p> <p>number of parameters: 3.42M No meta.pkl found, assuming GPT-2 encodings...</p> <p>The state of men with him that, by his brother's, The very good men, and hisWhen we revenge to Myself, like being now in the airing.</p> <p>GLOUCESTER: This gentleman is set out of other.</p> <p>LADY, lord, give way, and go we to our cannot, And I will leave them to one the YORK: Why, then we may come to you to the: I would thou wouldst hear; war's still he thou done: O, is 'twThy graciousYou were at the heart.</p> <p>First ay: I did not stay?</p> <p>HERMIONE: You will not live But sir, nor little's by the he'll take it down To can. You are not fit to me?</p> <p>LEONTES: What, youPEY?</p> <p>MELMy words may bear't. The one would have so.</p> <p>ESCALUS: I cannot speak in heart to come by with her the thee: never only of your love, O, He has with him most peace; he'setheth once, And therefore do you any thing he would have you; That, in't your eye, well- ELman is so long a Jof which's made youity. If you, you may hear that you are, wtis a shepherd only may he say Bohemia.</p> <p>DUKE VINCENTIO: To your love.</p> <p>LUCIO:</p> <p>ANGELO: I am that king.</p> <p>DUKE VINCENTIO: I would I had been on to the A there: Yet must you be, sir, to all I know so.</p> <p>DUKE VINCENTIO: The duke shall know you say speed again to yourself you.</p> <p>Provost: I will be an't.</p> <p>DUKE VINCENTIO: It is a word of me.</p> <p>ANGELO: TISTRESS OVERDONE: Ah, howio! not all as he being As is a father of a e'er these adTan your brother is born.</p> <p>MAMILLIUS: I am a word to-morrow; youpt, But you might,</p> <p>I shall have had some to him thus.</p> <p>LADY CAPULET: If you were mad? 'Tis full of what you should have.</p> <p>CAPULET: What, say'st that I mean to me to thy name?</p> <p>JULIET: I am the more.</p> <p>Nurse: Is a word.</p> <p>JULIET: What is the news thou bring?</p> <p>ROMEO: How shallest what's a d see of them!</p> <p>ROMEO: O, give mewence, that comes in the time Of this. I am not born a happy day: The which is an ear thou now to make me speak, Nor how in that word, thy majesty worse, To Romeo, not to theage, thy dear queen, I am a comfort that is my wife. You that's a brother, to the duke's e'er, To have his mistress king, to-ake: This is the love I might have doneish the country, That I may live in theWSo name lords that means That ever had been to doway on! What think you, if you were you all, Will not my full very reason for a great bed, Uniansch high the heavens? answer this Of this fair prince's name?</p> <p>CAMILLO: I will, my lord.</p> <p>LEONTES: Pray your father! That's true-Sir, and you are son.</p> <p>POLIXENES: You are rough sir, give me Lord: let him go your seek.</p> <p>LEONTES: My fair lord, Were I but so much, or do I see, my more proud, On this most gracious lord.</p> <p>ANGELO: Thy great youth is the forth knows.</p> <p>ISABELLA: But 't, an confp Henry!' The which you seem not you both, which would well, That I with dearLE RICHENTTER: As now I have nothing: With quoth so, my lord, and all at night We cannot speak, let it to remember me.</p> <p>CLIFFENCE: Is some thought of this, we may be a cause.</p>"},{"location":"gpt/#king-edward-iv","title":"KING EDWARD IV","text":"<p>LADY CAPULET: And to me have me bawd, youngly, I would say, If you say so, it shall know the world thou thyself.</p> <p>LADY ANNE: And, I am that day to last with a thine.</p> <p>JULIET: O God's sake, is come! I'll make a years upon thy husband; And, all am grief of call thee all this good.</p> <p>QUEEN ELIZABETH: It is my father's; it is more A dead, a proud; for if she be king, I may not live another woman, I am not a father that will take it; And now, for my father, by my whose fineoe Provine and my wife's son brave father me: But I hope, my lord, for I was seen, With mine own love to-day; let me lest: So I have done, yet comes one.</p> <p>DUKE OF YORK: Thy kind-morrow spake for the grace-night!</p> <p>DUKE OF YORK: ay Richard, that dothst thou do to love thee?</p> <p>DUKE OF AUMERLE: Then, I am mine own again, or I, The truth of day; and with a kind house Hath made her dead, who have manyre many more That I'll hear him rather and say, for my death, I give a purpose.</p> <p>LUCIO: O living, my lord, it is gone to leave it, And you shall have of this good or'dN At my poor brother's kiss: and I have seen, The one that's made me welcome.</p> <p>DUKE VINCENTIO: This oath have as high as the wisest, then other mure of a chide on: the post of those: You have not there here are comeable.</p> <p>LUCIO: But in this while I should have them; if I cannot, I do put the fool: then, like I come to love thee With a set upon my master, which is his pence of the king; even so in his hands, As I havech you at his best, By that it may</p> <p>France, for honour! if you were now have all; I will be banish'd, do not to prove The corn of honour, and I will not The noble touke: but I will not have any name That I, and think it were, if I could stand, Most might be in this fair way thy hands And me shall the face my husband'sJShould be, To young princely to thee here, be long-s, Take it again in noCOR'er a happy depb not.</p> <p>ROMEO: O Romeo, nurse, how can your dU is a happy In mine honour or anBHAMELLA: He shall have a poor way inch by his honour Gless worthmen; I warrant my counsel was more.</p> <p>DUKE OF YORK: Let me I speak of such, my lord, That very good to be this, before the time Wept with Iixt these words.</p> <p>DUCHESS OF YORK: Why, so I am his wife, to do't, Yet hear my lord; 'tis so; and I, I do him!</p> <p>DUKE OF YORK: Int note was that ever wasR pleasure true: He which's anMENain'd now: heuck me not his bawd than I have content the old gold-bed, he's dead, That may not beoe to be thy face.</p> <p>DUKE OF AUMERLE: Whom is the way, to youQ is it so; For I will not: so she would thou hadst no time Than in me but not: but that--tis not so, For I should, I think, I please you, my sovereign, And by our country's breath shall hear thee, To lose a matter with a word; if we At the most little: to such nor thought it was, Unless I think had been yours, for I crown'd; And, with a word, poor soul, that thy love's will do it.</p> <p>BUCKINGHAM: I know the gods.</p> <p>GLOUCESTER: Pray, be these my bosom: for the time I'll pluck the pack of your house face.</p>"},{"location":"gpt/#king-henry-vi","title":"KING HENRY VI:","text":"<p>WARWICK: And Warwick's death will go and did to us. And yet not be fear'd in all. Go, Cates, and not thy brother and brother, And come, I'll swear the duke a good To be as free as little as, so myTis-- That side that would kill'd my husband, so Whose honourFor it is lost grave in-- Whither dost not be long as long as Henry's love My father, Edward, to my tenderbr own arms: Till your three days give good thine and your eyes.</p> <p>KING RICHARD II: O I wast thou not dead, say I know thy mind, Yet thou that dost in beseech at us, And not to the people that brought you to me And think you of our good rather shall be Be it to me but for my best good.</p> <p>First Senator: O Clifford, O, it is the more!</p> <p>MENENIUS: I would he had a people, But, were you not't; and you, my lord, You am of what you shall be so?</p> <p>BRUTUS: When you are should have bound 'em.</p> <p>MENENIUS: So, most it do.</p> <p>BRUTUS: Where is the love of this fellow, that must not?</p> <p>AUFIDIUS: We do not say: We were to do't.</p> <p>CORIOLANUS: You have been a cause to need.</p> <p>VOLUMNIA: O, indeed, I'll to desire o'er a counsel, And I will play the us.</p> <p>MENENIUS: My noble wife is me as good as well in true, To have an those water's better and isar'd. He pluck'd with him, and you'll have all the news-- And it is as good as Montague hath.</p> <p>Second Citizen: That, my master, which is his friar o'er-s, In that she had done the noble duke's from The noble head to the-night bed-like.</p> <p>First Citizen: Sond to the king: But I hear, madam, let him be heard it</p> <p>Of God's name, that is ill and great blood On thy be these; yet every w thought I with it, And none but that I doubt; and, in your love Is it right: but I, my poor dear cousin, I hope that I had not to this brother, But I will stay in the thing I say.</p> <p>DUKE OF AUMERLE: Why, lords, what aunes may?</p> <p>DUKE OF YORK: A gage, prince wouldst thou tell thee they! Thy brother's death!</p> <p>DUCHESS OF YORK: Unshe's aHath To Romeo's name the traitor; And you, God and I will see thee a and that Of living men thus they had been in this love To the duke.</p> <p>QUEEN: So, they are not to be the name of all.</p> <p>KING HENRY VI: But, madam, be content for thy thank; If thou dost sleep at thee? Now long rest is dead; thou wert not thy f after?</p> <p>QUEEN MARGARY: As thou as now I love'd myself of thee?</p> <p>QUEEN: But I shall fight with him.</p> <p>KING RICHARD II: O God's pity where long the o'er the world-and'd ! within I have done for the hour of thee Whereof thyself be too quick for my death, That enemy, with thy warlike blood, And made the king in arms at gone.</p> <p>DUCHESS OF YORK: So shall I do, to so late, Why, proud-hINCENT are lived told?</p> <p>DUCHESS OF YORK: No?</p> <p>KING EDWARD IV: I know you that is a father, to my?</p> <p>YORK: By fair, I thank thee, love thy face Which thou hast welcome of the fool, thou thyPR; And, now my poor queen willBYADYOP, For in my brother I king have play'd heaven: For Edward's face, being gone to Bolingbroke. TheAU's aH no other tongue to thee; For I have sent not to be of.</p>"},{"location":"gpt/#duke-v","title":"DUKE V","text":"<p>WhosePOLIXENBERTER: Not that that shall tell thee to my grief, But I will not be gone to thee, and thou a present tongue. 3 KING HENRY VI</p> <p>CLARerer: Take it with the day.</p> <p>BUCKINGHAM: Therefore, my lord, I let not beauteousors.</p> <p>FRIAR LAURENCE: Why, then, I pray thee, call thee bring me to me For this my gentleman's letters and her: 'GoodISTR in't.</p> <p>ROMEO: You must beL blood; And thou wert dead with a for him thou this!</p> <p>Nurse: Go, come, come the nurse; I mustETH: I pray thee I know thou canst wish it not say.</p> <p>JULIET: Though we have less, for ourHave set than me, So full of honour, I am gone to Warwick.</p> <p>? of ourmen born?</p> <p>Second feel so: this is well as true as you, That you are put up and see as fast as fit As far all-f- HINCDand children to my poor blood To this loving?</p> <p>LUCIO: Doth she, when her father's Claudio hath done. What's he? He is in the name of men, With tears of heaven, and their true-ouon put'st Ourself'st man; and, and so is they all; That thou, like an unf swift use of blood. O, I have thy king, and thy king, That thou art a rest, thou, then now in thy place, Take thy hand in thee to do thee most am dear.</p> <p>JULIET: O do this love, and be an O! O's thy title, Is more more than yet thouThis: now, and that thou art To be it? 'tis not a tas beg man in  seen an hour, having whom, he will not tell him. The means of you, my lord, is your lady's son.</p> <p>First Citizen: Away, my lord: we know they do us all.</p> <p>First Citizen: Woe to you? then you have said you were?</p>"},{"location":"gpt/#second","title":"Second","text":"<p>Gentlemen, may she be put for it. I but think it was a bawd, I had to do so; For, in good time, a very well-baww gracious.</p> <p>Nurse: Why, how now, I art gone, Saw-b, ere, I hearon!</p> <p>JULIET: OGLOUCESTER: Here, that would he were so sour to he.</p> <p>LADY ANNE: Why, Warwick, how now in day shall I be!</p> <p>GLOUCESTER:  gone, my liege, in what! If it be I had to die their high.</p> <p>KING EDWARD IV: Then am you patient; and therefore is Of all my husband Paris, to-day.</p> <p>GLOUCESTER: O, I would I had rather, but for thy son?</p> <p>KING EDWARD IV: Your death, my good, what! that I am there.</p> <p>GLOUCESTER: No, to thy name; but very it is not, For I have, to go with me; why, he's dead?</p> <p>heir: We shall not, my love, my lord; But, Warwick, do not justice her out; For therefore, so it is his hand that is: And yet our country, we are, nor I.</p> <p>QUEEN ELIZABETH: But what means, good father, be that state?</p> <p>KING RICHARD III: Tell 'p thee, an brow of all.</p> <p>QUEEN ELIZABETH: Good prince, so!</p> <p>KINGain: What do you thought, I hear it, I know you well: Your face I am not in your good counsel: Then be it then?</p> <p>KING RICHARD III: Ay, but he, but he's no more than a country.</p> <p>BUCKINGHAM: Is it none, good father; you hear no more.</p> <p>KING RICHARD III: We have done a better, our person.</p> <p>QUEEN MARGARET: Call so it, lords, have made him our hands: Berely as well as I have; for this, As for</p> <p>ESCALUS: I think much; but they find't their way out, but to die The people, and he hath yet show'd!</p> <p>ISABELLA: What you, I'll givehe outOUCCIUS: I am in need.</p> <p>ANGELO:</p> <p>I was a kind of all.</p> <p>CORIOLANUS: My gracious brother?</p> <p>LUCIO: ouson?</p> <p>ESCALUS: UC.' is there a thing?</p> <p>VOLUMNIA: I would it, sir.</p> <p>COMINIUS: Let me but stay.</p> <p>CORIOLANUS: The gods too word, my good nurse, I come from Rome and of the had the gods alt have been in the presence there that made; The people lives upon our TheABes; So therefore you, I cannot do you, you Were, my good with me, your father, his lady: One of you, he has done, by the honour To Coriolanus.</p> <p>CORIOLANUS: Haply, I mean to us and on.</p> <p>VOLUMNIA: ine, Lest, take up the duke out the traitor's son He was a like a father; who made My best son: I will wish you his love. Wilt thou? What's this? what? will this, so I here, Were in me by my master, I am like.</p> <p>JULIET:  Richard had his grace, Nor, since the life that it hath most his, For much more shall be, and in that word.</p> <p>Nurse:</p> <p>JULIET: O nurse, I fear it were night.</p> <p>LADY CAPULET: Pray, you have all this day a may have youak. What, is not so long, you would have been long A noble deputy, which you come toius; And you the people is, you shall find again To see you knows the place.</p> <p>CORIOLANUS: Away!</p> <p>Second Senator: Come, I pray you go to you: you will hear me: Come on, madam.</p>"},{"location":"gpt/#menen","title":"MENEN","text":"<p>DUKE VINCENTIO: What, if you do not, you should be been well That you shall have; and to the alone of my heart: Do not think that it is hard to take.</p> <p>LUCIO: And in that world where he cannot be; for, I do see You that never, I have heard, but not go; I'll the souls of more and more That is a good way to hand; take TheSIC he my C art, and myself to please. Good ladyENS are thou what an openon 's tooNot, nor what can part in this fair speak.</p> <p>NORTHUMBERLAND: Come, cousin, you standNow down toWhich as these blood As thou wert so now in a comfort's hand.</p> <p>KING RICHARD III: My dear love, my lord, my sovereign liege, MostFrom earth I come for Edward's death; And longum thou, the fault, but not thy lord: I look'd, to be fear'd for me to live.</p> <p>GLOUCESTER: I never will, I'll speak this.</p> <p>First Murderer: How now, like! what's the day?</p> <p>CATESBY: Marry, my lords, shall you seem inh nor wits, Or take you by the once.</p> <p>Second Murderer: O God's brother, thou art mad, and begish'd.</p> <p>Second Murderer: 'Tis never gentleman, but what of my counsel But to my will at morning.</p> <p>Second Murderer: How long as I?</p> <p>Second Murderer: What with a name, was this?</p> <p>First Murderer: Alas'Twixt me, and must be thy daughter: Doth set the world upon thy counsel with thy thee o' the face, thou hast made them aHere.</p> <p>Second Murderer: 'Tis more but not, dost thou havest Lewis, That he hath leave of more unto of this Richard.</p> <p>CLIFFORD: WhoCAP thou wilt fall so of he had been of!</p> <p>RICHARD: And bid me stay.</p> <p>RICHARD:</p> <p>Messenger: Give me thy oath I</p>"},{"location":"gpt/#1000","title":"1000","text":"<p>iter 997: loss 5.8675, time 724.04ms iter 998: loss 5.9554, time 722.33ms iter 999: loss 5.8129, time 730.23ms step 1000: train loss 5.9102, val loss 6.0530 iter 1000: loss 5.3077, time 1634.94ms wandb: Waiting for W&amp;B process to finish... (success). wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped) wandb: Run history: wandb:       iter \u2581\u2582\u2582\u2583\u2584\u2585\u2585\u2586\u2587\u2587\u2588 wandb:         lr \u2581\u2588\u2588\u2587\u2586\u2585\u2584\u2583\u2582\u2582\u2582 wandb: train/loss \u2588\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581 wandb:   val/loss \u2588\u2582\u2582\u2582\u2582\u2581\u2582\u2581\u2581\u2581\u2581 wandb: wandb: Run summary: wandb:       iter 1000 wandb:         lr 6e-05 wandb: train/loss 5.91025 wandb:   val/loss 6.05303</p> <p>I my, your the am; By areU he: WAR</p> <p>H</p> <p>That a me, I am father Or: And</p> <p>to her I</p> <p>I, I</p> <p>ROM, lord:ANG is IET. ITER,</p> <p>He</p> <p>Hold can for my your am,</p> <p>And if yet be'll to the the a life the the he a my;</p> <p>P: Sh, have this, my,</p> <p>A,,</p> <p>A thee- I a tell:</p> <p>O. A be any,</p> <p>Your you, I my death</p> <p>For I, this. You, my</p> <p>As I and the</p> <p>PET's artUS, My life than.</p> <p>Have see! and hand to God of stand,</p> <p>With, a many me? Where of have think, it to I have not, That that that pray, As the my I not thy the she lord shall a thyIO and would poor, for the:</p> <p>and: What and he, ' so it, did a will his king, a is Th:  Butour</p> <p>Will,</p> <p>Were,,. She, COR the her as,</p> <p>Good</p> <p>When.</p> <p>For lords. and butET is there your me? and shall king the this.</p> <p>C, thy mine.</p> <p>O</p> <p>The shallUS, That:</p> <p>GL: That, That,</p> <p>Then, here the</p> <p>But,</p> <p>What: H the,</p> <p>D and, NOR toEN! if must, The the,US? To my the's poor.</p> <p>Why's will have he'll can how man</p> <p>Some in cannot than come, Even a in, him. Is you anyENT me; so say, be sir, the the Itis the, be'll man I them.</p> <p>What.</p> <p>So thisAB he,</p> <p>That that the will,</p> <p>That the'll:I a king,</p> <p>That '</p> <p>Would</p> <p>Now, have my the a:</p> <p>To kingUM,</p> <p>I'll</p> <p>b the must a do thou, H.</p>"},{"location":"gpt/#were-his-thy-the-the-the-ill-or-all-cannot-i","title":"Were, his thy the the the I'll, or a'll cannot, I","text":"<p>To No for they not such time, name?</p> <p>And was have to not me, Come of must know,, I be the yourUS his such I be my.</p> <p>How,</p> <p>For me the have have: ROMING</p> <p>To to when to, My: as And men,</p> <p>An a B all or</p> <p>And thou is,</p> <p>To man,</p> <p>And the:</p> <p>Come, am sir, An,</p> <p>And:</p> <p>Lord queen for, they my, that he part</p> <p>This! It in my trueG do in:</p> <p>Is? And we most, that the</p> <p>BKE: Is an NES?</p> <p>From say; you and, to's knowING your</p> <p>I his  But V for it:</p> <p>I lordUL from well, Go in me, it the be I was. but: the her as</p> <p>IU the he our life; if his I most in I the is,</p> <p>I</p> <p>But in hast:</p> <p>Thus and your noble the do take she be: ' I'll a I your d ever, be not allEN COL to aOL, and not he, you is I make, This you not? I</p> <p>And, beELL what there:</p> <p>Do her thy here, not not</p> <p>Not crown your in a that, if death would we you not the w made of his me and butI not,</p> <p>What, H it</p> <p>P can that The the,</p> <p>So:</p> <p>COR H</p> <p>This: if'll B, butET with will hand, I the a</p> <p>N to must a, If,</p> <p>Which I would your- have by the am isIO, What no come is</p> <p>This aIO:</p> <p>MEN been d: WAR in a not, '; name: To sir, I most</p> <p>NotUE men, I What and d me:. my? The's have a us he the I lordose,</p> <p>You not did, Here, do an a she, my we a he: BR thy</p> <p>Why she.</p> <p>P love,, COR this the that how,</p> <p>Of what out</p> <p>H thy:</p> <p>COR his me you, And as NOR you as and that But I Yet. I no crown, say:</p> <p>As have: and wereTER:To:</p> <p>KING KING. ROM be you my the yet, some one? Second their a theI, the father this it not the his.</p> <p>A as not: ' it thou I theICH.</p> <p>O a lord.I it. That theES to he So. But!</p> <p>That not do. I:</p> <p>And your</p> <p>Q. I</p> <p>What</p> <p>IIO, is lords, he the stay that my come:</p> <p>How it were. H not, D. And, that be'sEN:</p> <p>H P:</p> <p>And my that have that not't to they the thou thy were</p> <p>If in; and the for know N In: for my the- never do tell R d it, Not,</p> <p>First, of I Come</p> <p>I be be hath a be her these me by this: and the it goodUT</p> <p>As</p> <p>My when, MER must. H And have the you- sir: and your To be aT, which is; That one shall must you the a,</p> <p>That make I that No'd.</p> <p>This;</p> <p>If now, good dIO most you time, My.</p> <p>N you, and this is have will am,</p> <p>ROM of were shall lord toUS, ROM is be his him: Sh: and her their: H to beEN I the name, Prov not all the you thee, The it, that was,IC How,</p> <p>As such not no IINC, our I and this is not,</p> <p>C. By but I W will as his</p> <p>Sh!</p> <p>you, To him: and say; she. Sir at notEN.</p> <p>Your me, for what is,</p> <p>Q them: Is Sir, one</p> <p>a him</p> <p>NOR with ROM mother that be that see in,</p> <p>H.</p> <p>I D, the so,, This man to</p> <p>She come?</p> <p>D</p> <p>Who, but; by</p> <p>He, H,</p> <p>I</p> <p>I I should my sir.</p> <p>As, take my as or.</p> <p>Let:</p> <p>Is Where his he, No his you be</p> <p>D have,And you He that in man thatIO</p> <p>And You in blood should</p> <p>That:</p> <p>As was lady. Now with: First, theICHEO isI very: Ah, will an- I blood him a, house, that part, my: MER, so, And</p> <p>I but you:</p> <p>What: Your come, Q, To,</p> <p>Now, will he see: Be, His to his an shall then,-- I. I most, your the this By will'll and</p> <p>For a the a a would he</p> <p>At</p> <p>I'll?</p> <p>I: Un my head; They thou am,</p> <p>I.</p> <p>It: To not, my noble in so, and O. By art?</p> <p>Let, they is have thou: COR; and I</p> <p>The But Th '</p> <p>An are letOL my.</p> <p>And My will,</p> <p>What me, A, A good</p> <p>Second.</p> <p>Then: Sir:To am art D.</p> <p>I the thetis, we one.</p> <p>I Lord Th. D, let,</p> <p>Now, MEN, the, To which</p> <p>And. TheUS so that an be give, be so, Come then him. That can the:Y with by; you give to'll</p> <p>A this to be the letsIO to be the And have'll, These is a thy! I And: OfEN cannot'llUE with he my do The did:</p>"},{"location":"gpt/#of-thou-say-so","title":"Of thou say so;","text":"<p>be, best</p> <p>The our</p> <p>What:</p> <p>In can should of a he</p> <p>I</p> <p>To, Which J: I: He of his sir- am, If sweet the</p> <p>Now. ROM To, their. men? D, would king:</p> <p>And And one</p> <p>And'll himly name. COM, sir with,</p> <p>And:</p> <p>N am's that you of there thisOL heart: You if son But: WereET:</p> <p>if I never, Your in your not?</p> <p>goodIO, or:</p> <p>How Give not in; Come yourEN have most: H:So the I do, If my my I</p> <p>And the good I this or love in think:</p> <p>My Come's and some not I call, to mine:</p> <p>KING you '. Of</p> <p>To</p> <p>But life, be,</p> <p>B you, you,</p> <p>And go:</p> <p>Good theUS and love</p> <p>W forTER to'll II them:But'll an. If</p> <p>' will, and's part be bear here,</p> <p>A:</p> <p>We you How, Make thisEO's his would love, a when not:</p> <p>N him it, are you, a thou then, How. Cl a a for your! be the part, And take the But, sir, That:</p> <p>Ay, well! This, Second all-: If a I the'll all withUS: Totis death; sir of:</p> <p>And his her thee to this'd: Un, see and a KING, The the be; thy man, some do:</p> <p>And thou ' the the some thy To the this</p> <p>As. That--IO, The I the aKE thou in give!</p> <p>It shall some thou have I I I you the a To I d not am the thyKE a my the this he:</p> <p>Would my life,,,</p> <p>Well is thy, Which: Which a well.</p> <p>There R, the a B so: and</p> <p>UE</p> <p>MEN not in</p> <p>I tell withI if If in the R</p> <p>AsUS. but</p> <p>I the me when you,</p> <p>Good And him.</p> <p>b poor, One MER: To all: and is I makeant upon it I we a blood</p> <p>I. You Is, the, myIOL would First</p> <p>R, a he, Your queen: no people? TY: I. Is shalltw: And 'ES youtis</p> <p>Which his my your my art we haveUE me S his but man, which come: That</p> <p>H the your the, b, His the a a my king?</p> <p>And</p> <p>Go to his Second hath I his more man up, That,</p> <p>What. And do'll a a</p> <p>As He in he have, I my willIO: And, That he I isU You, But.</p> <p>you? Which to a the a, To You a, have the my him, a these this and a him: R most love: that no do make if her</p> <p>For</p> <p>I know, my grace. AEN the am your your the I lord? Who, I the with But: I, a</p> <p>Ns to have so such:</p> <p>KING: J a</p> <p>I day is D crown'd, That</p> <p>But the the.</p> <p>Against when it J. MEN a the. If</p> <p>It  love</p> <p>Give theKEant, E, go.</p> <p>Sh: I ' as I ownUEAN:</p> <p>Thus will myIO of And, Of queen: IUS of my lord! it,</p> <p>He would thou? His,</p> <p>And that mother;</p> <p>And</p> <p>N I have, for his if shall, Now, to the am, there that great must betis he</p> <p>D this.</p> <p>C the do,</p> <p>To an, As a them,: ROM, Third, First: For the see,</p>"},{"location":"gpt/#i-the-a-a","title":"I the a a,","text":"<p>,</p> <p>Now</p> <p>I was,'s that I it you the done</p> <p>Th with do my, That that it: O: Your, our'll And the that '</p> <p>him like but, a honouron.</p> <p>I dead to her</p> <p>some I: He,</p> <p>If:</p> <p>KING:</p> <p>R thyUS. And Too: For a be theELL, our, And many the but am this,</p> <p>Why, They</p> <p>that the this make,</p> <p>I:</p> <p>Is have am her my my he all,, when the will the to be,</p> <p>This, As may I my their have the</p> <p>To him: H know is say YU ETER, Let.</p> <p>Now. A give is of shall thou,</p> <p>There you, P, I poor, a the some have the your are the for do for you this to your a for or good do, or noble: But</p> <p>And shall he be</p> <p>And good them with Cl's</p> <p>The are a do you. That</p> <p>notown, Sh,</p> <p>I be do it,U O you I be die, Her, by I; she, To be to that sweet all, We be:</p> <p>D more.</p> <p>For the WAR: a the-'s she, that And a thy what,</p> <p>And It, and these. The thetw's know.</p> <p>Like of makeIO.</p> <p>A But I speak: with and: not,</p> <p>PR:</p> <p>Come we If his,EN hear: To I I, N; Of, I,</p> <p>First so the head:</p> <p>To that hisI be you the: That you. You? ' shall I be</p> <p>As</p> <p>He is KING, come</p> <p>KING, the do the the So,</p> <p>With, And shalloth such me,, you by:</p> <p>That to her for I like. Our, As in this love:</p>"},{"location":"gpt/#000","title":"000","text":"<p>iter 4990: loss 4.7843, time 730.76ms iter 4991: loss 4.9219, time 722.85ms iter 4992: loss 4.6760, time 731.14ms iter 4993: loss 4.8503, time 699.10ms iter 4994: loss 4.7151, time 721.49ms iter 4995: loss 4.7852, time 687.31ms iter 4996: loss 4.5192, time 732.55ms iter 4997: loss 5.0381, time 727.84ms iter 4998: loss 4.6365, time 694.68ms iter 4999: loss 4.8973, time 691.50ms step 5000: train loss 4.7097, val loss 5.5308 iter 5000: loss 4.3929, time 1421.90ms wandb: Waiting for W&amp;B process to finish... (success). wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped) wandb: Run history: wandb:       iter \u2581\u2582\u2582\u2583\u2584\u2585\u2585\u2586\u2587\u2587\u2588 wandb:         lr \u2581\u2588\u2588\u2587\u2586\u2585\u2584\u2583\u2582\u2582\u2582 wandb: train/loss \u2588\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581\u2581\u2581 wandb:   val/loss \u2588\u2582\u2582\u2582\u2581\u2582\u2581\u2581\u2581\u2581\u2581 wandb: wandb: Run summary: wandb:       iter 5000 wandb:         lr 6e-05 wandb: train/loss 4.70968 wandb:   val/loss 5.53077</p> <p>number of parameters: 81.52M No meta.pkl found, assuming GPT-2 encodings...</p> <p>Not that; You.</p> <p>And it, I to the mother on my son.', PR: And the suour of, Quke,</p> <p>That, not is this earth And not,</p> <p>Now more years will the part: The hands; Not,</p> <p>My son,</p> <p>To I do my queen. TellY: Darest by strength and. And, As Provife's side, And I not the gOM look, which: AUTUS:</p> <p>May not men to dU and you, So, LUEut's lie on a would I can! The suilman, The noble lord up I I do nothing in your end, DUCatter thou have my r LA,</p> <p>For, with to the earth to your wife, Not my or not his hands With you do a friends, His loss, Should have not, as Ibians My mostt to I lord, the world, take you not that you the cause, IOL OFCES: To you, if her my father, I can be your Tower To do my name. That the hands to me. Icius,</p> <p>LE: Why, LUCIO: LELCUTIO: To thy lord, to my day with me? And you more for, For never my power,</p> <p>Her heart; DUE:</p> <p>Good great noble father, this In to an father? And be do for the friends! The lord ClOL OF YORK: And he will he of my hour. And if Will some thing at the lord Bove's father have her; Darep the counsel. As will be those the one, go; come How me: Madunes!</p> <p>By me. And a curse of my. ' I hast my lord Not,</p> <p>And, my lord; He. O Do you have be With blood, R VI: Tell your foe is a king-eseous death, Sir a most mind. That: Who I have ProvUoWARD</p> <p>But, O</p> <p>And in a go, From sweet high is joy upon my, FirstICan had this? WARICHCES V Lay: Come about a people, IUCUS:</p> <p>But this land'd's father, And Could To my will; let my ancient lord Unless my lord, but That, And I shall be I, farewell, if I have said their head, And yourly the time All it which thou have, Which not will; an eye! In me of her not. How I would I DUCost it have the lord, to you is my d'll my common d understand What will not.The business! Glouace; and you, Why your king is your great</p> <p>And</p> <p>Mess not's in heaven on me Say It thy day.IUS: And FirstIC VU,</p> <p>Be that I? AndtwEN Which Best you no is to thou should I do not, Be thy life;</p> <p>And and</p> <p>If you. And I not. A: And he callWARD: To their most we do yours,</p> <p>Dost; Who the first: To be't? A: To my king but Once will But. Thou hast our loving dADWARD IV: The Duke;</p> <p>Sself is the father, and be make you Why,</p> <p>Blbroksarry; From a Lord of that she? As this, Which I have but I spoke, since was the lords, Well, And your course!</p> <p>Sir. Do this grace they were in heaven</p> <p>NEENIUS: Look's, BowY:</p> <p>With in the word. L: But I wost to not the heart To all thee, LU' the my heart,</p> <p>Hre the heavens. And he, we art shall be be your other the last in this quarrel.</p> <p>B me to my royal prince, My life, it may bear hist; SecondUS: But in your, good day, And you, that, And it; it, to give him, From true may be not</p> <p>AB, Look to you will My, In thee-OM do the less aself,</p> <p>Before the, For I not better 'er she not you here:</p> <p>And be a heavy un Senator: MENall him It,</p> <p>It be my suit</p> <p>KINGELBY: Yes! Is my father,</p> <p>To the best, a grace. YATHolding, but such me I cause your sovereign! KINGABILLES: Nor what shall do a ear of the word's tribricMour him PER be. A:</p> <p>Sweet sister, My self,</p> <p>That the grave,</p> <p>The lie' so thy case in put,</p> <p>And my wrong, MENre father. Your child, I do be our will Nor your That KINGOU RABit's with a sovereign's heart as, and been But, good lOW:</p> <p>From your court will you me they friends withESSyly I-US:</p> <p>On the mind, Iie, And if That the good thing the very poorICIN With this is him. POLam'd me Say,</p> <p>And thou I do be be all my word, be my noble day, a Tower to you,</p> <p>Or,</p> <p>That them, sir</p> <p>By my sister; HILLES: Or than was this, Or it, LUS: For none.</p> <p>Have all your dINGS: HULEfore. Of her, Who Th OFABall Burse: IUS: Dcius. But time, when I will be you it the lie me,</p> <p>So me, So my lords, Be but bear all more His better I have thee to not by thy dU me's more may, And he.</p> <p>Go,</p> <p>That the words, which I besinks would he'd in hisENTumerine! Had I will, There has, but when</p> <p>Stand with him,</p> <p>FirstUS: Why:</p> <p>Our father, in CO;</p> <p>Like you it me's lord, But,' he heaven? Be you may the life. Doth my lord, but was you is dead, AETH</p> <p>And see your words. Ander thy will all down, Or in my suit, And at this f Murdaced not,</p> <p>To;</p> <p>LUS: From all the very and his And I must it shall am I am you you,</p> <p>Which, My friend with</p> <p>Inay again: For they traitor; For you but an country? To had the</p> <p>LU, here, had That thou, do the heart,</p> <p>IUS:</p> <p>A: IUartarry. But I but MEN:</p> <p>FirstUS: And they not, LE OFELA Marshal:</p> <p>Are not to heard theICINNow, sir, RABELLARRIUman.</p> <p>Well.And he a eye, and.And show to I be your death have this lords me that, in the king And this a times from I would say, then, your father, FUCUS: R YORK: Now.</p> <p>To see with my queen,</p> <p>GiveBERIO: for your sister, For it. Of your land! And</p> <p>For, I be use their case; do have too as see his fault And I speak Who I more stay? Let the or ent not, and now all you by a gods, you I say dU your war,</p> <p>In me as that:</p> <p>The end. God no more thus;</p> <p>GLCES OFUant; And I, O of HENO,</p> <p>But,</p> <p>ToASIONISHorn! Which</p> <p>The world,</p> <p>Why to, Which. Who have tost it shall done.Iona me. JOHN: And it to his lord. To be dead for peace, for me; She I they as that,</p> <p>Which art. Which be a soldiers</p> <p>And a rest with an soul, and of me to all for her, MERARDULBRES: Now. CORUT'll give me, And a house,</p> <p>Give your gentle be l'd for Good death, KING R HEN'B the honour,</p> <p>To be ourself, Firsthouse. MEN and the father!</p> <p>? You'll forUCKONT thee; Of his gentleman,</p> <p>He will more's: ThINIUS: To I stand! The head. No, the brother's this, nor so the world that in a bo', then, Most justice, So you, as the life, What,</p> <p>With her this breath, sir,</p> <p>You thousand uncle;</p> <p>When he the world, but And these brother the people.</p> <p>That I besiss? the good father;</p> <p>And,</p> <p>LUKE: Why, I, And for the king,</p> <p>HEN' so to And to you. KING RABETH: Th me,</p> <p>Cer; Let haste, now LETER:</p> <p>To't, And Quke! And this, I of to the eyes, In your blood we all here this sovereign: And if a my time, As my hand, Three life:</p> <p>Than to your power?</p> <p>That,</p> <p>FUuUCKIN Ile? LUCIO: Your head.</p> <p>The head, no thy people in you can your heart,</p> <p>HERuck thee,</p> <p>They be the life.</p> <p>Dague to me For not's kingdom, From the death, this loss, DUS: BBY: O is my as it my noble trible, and nothing,--And my quarrel would what you, being not, Q YORK: WAR YORK:</p> <p>Why Now, With a my side? En them,</p> <p>E: As I know is my other's poor They have you is, DAR LA II:</p> <p>That's more, for me to myself that I be a queen and be a heart: IS VI: SIO: Why and this lord, MontM the crown: May think. To this's hand, and your hands, Are not I not I not's very man, He you, I be done, QUC love upon the cause of my air</p> <p>In you I he do pass, FADESSINFor my father, Bret to But here, sir? WhKE: We</p> <p>Q be, FU, LE: DUall what and, On, LU, you I'll, There,</p> <p>LUS:</p> <p>And you, Theark any?</p> <p>Which no that,</p> <p>COR thou be in 'er</p> <p>And There in the child, LARDELLOU VI: If plWARDASTICK: GL YORK: The crown, as my VolKE: Lome, For I come thy life,</p> <p>And</p> <p>HERESSou I to you shall, on true have-ighth up And lay Dague,</p> <p>Y:</p> <p>GREY: Who,</p> <p>To have your ears's lord; that now. But than I thing! LE OFUCH'd, Your death. FIO:</p> <p>'T: To in the soul, sir on the word.</p> <p>Like OF YORK: GLARD III: The air, As There? Peace; What a love, FICK: but is the end, And were the friend B thee, for a king, ' he: And And that is an l me to.IUS:</p> <p>So, SwESS OF RentleY ANICou we did art your breath, weENTona? Say It that,</p> <p>At your man and His uncle. And I have him, And thou look is thee, And this very good, that go; that to time? MENENES: And here's, sir, Ay: My prisoner's me. My daughter! IENCE:</p> <p>This, And your restrah is your great! LARADEW' the other fair land.IAD me you may we be he live, KINGELUTET: And many hands, And he thou came in thy sea. This your sister,</p> <p>And I set wABiful; While'd, with this cause, and done,</p> <p>DAB II: Or can our breast, Henry shall were my oath! Which thatness-- T,</p> <p>She I have live in some man off be me now not may my lord,</p> <p>In a people; Which</p> <p>' the words to his, If mine you should my name; I have Now in a lords, And my life with him, KINGUS: And you, poor looks's you on your father have light, If 'em. GLUions when men my</p> <p>On your lord?</p> <p>But his grace.</p> <p>Go,,</p> <p>CBRESTER: an sweet LUge,</p> <p>O, with your world. And I well to true is the Lord. Lordugh, LU and how you; My soul,</p> <p>With, And</p> <p>What:</p> <p>And, To-US:</p> <p>To that is your life as in. My hands.</p> <p>And it it to be Ct is our soul. You now, As both a queen, like once and any more, Like you be a brother! SUMGABENI would he, and I see a blood We do Clarence</p> <p>Well me, To time, we spICIN</p> <p>GRE me-ICINJENALIO: And the quarrel, 'T of a my the Tower, CIUS: On the case; Let him,</p> <p>She that shall be we power!</p> <p>To be your, And</p> <p>And a right with that'sENTOLou you he, And that!</p> <p>LE:</p> <p>DUiol you. And, Will be be you of mine that we more for the father. And IENTIO: For to right upon the death'd.IINGS: Now, His field, I be my gods's land,</p> <p>FW'll. KINGOUES: And thou If not to the father? HETH: LE:--</p> <p>Look must you</p> <p>Who know man by her. POLopit you it man's to the other were make my d my lord to the one. BYts you; His time's more is this eyes, IS RARWICK: LUish a men is to such this brother, O, That must he it out? We can be</p> <p>There him that more's more me, eunes, And</p> <p>IC I not is your the lord. Ander before it. And thou were, a peace, And Scak down with a, AndT II:</p> <p>Which and him the king;</p> <p>QAENI had me to set sorrow, He with the lord of my wrong. He, CY:</p> <p>And were a gentle lord, And I had justice. He, aICan's to be your prince. The better and once have be have none! And he is him, I may this: Yet come are the king,</p> <p>Andn all. From our life. Shful blood'd, and not Shre is what that, Jutful men all day, my better you to your own earth,</p> <p>I do</p> <p>LICHCBRHAM: Who, And my night, My life! What this name. With the side: How And our further with ourselves, If are for the pleasure: And is; The own life, The father; And I stay. We be the fault, FirstUS:</p> <p>F mayENTfm. Of my death it,</p> <p>Firstoler. IICK OFICHINC scorn me, ThINTo the heart! Of thy while man, of him</p> <p>To take me, You. It by those the in me, As So no world,-- To put off's man</p> <p>CORtis going's land, Her counsel at your father than both you,</p> <p>Why more; But you, For most world-ICanly Richard, Make no need is me thee;</p> <p>The And so! POLKE: DOUO: FirstUS: Thus,</p> <p>Must shall not but I,</p> <p>You, lords, farewell</p> <p>And will not. How'sbher dost, and be, LUEENO, even or so I</p> <p>For in my queen's good king, To fear,</p> <p>The hand and, to my man:</p> <p>And the voices, Here aem word, And will all to a dUman: Who by her with him.</p>"},{"location":"gpt/#jricest-a-bo","title":"Jricest a bo","text":"<p>R with your IIO: And we in him am the lord is.</p> <p>And As To not is great Have you to in it, Mess so is my high on and the time! That I do your lord, He shall made?</p> <p>O you of a best, theyt with her of her must with the high me, and the master at my brother, if it you not not I in the suful house to they desire, hear fulled thy grace And your FirstUS: GLOUUTIO: O.</p> <p>A: Of, This it with?</p> <p>First should for theself: To the hand, Or you, SICIN Ay, He in me again!</p> <p>Which go with the time. You come's!</p> <p>Here myself,</p> <p>L:</p> <p>A: IUS: Or that he your blood's and he are And know your king.</p> <p>And With't will a son, DAD your is an old's king in him to thy house;</p> <p>While yourt in me, Are bear,</p> <p>' they. T: ROMO,</p> <p>QW: DOUES ANIO: And true, he a day, T: To to you than, and so; If he is me from me is my one. The kingdom in our lord; And the hand upon BolCHp Henry.</p> <p>MEN: For I would the earth, The crown, Your bed, I not ISARDENES: Alure,</p> <p>And more to;</p> <p>MadKE VINC say CORES: MethESS:</p> <p>She of a more do IIZARD:</p> <p>And you, And you, I turn not the presence.</p> <p>To gone: And I will th, I say. our voices,</p> <p>IUS: O, KINGABours. And you hear my face, for they more I will his king, thy bosENES: Sir should have go, LU, If I be none, my soul is your Duke,</p> <p>And he. And a more ' it for the son, His kind, He, being she</p> <p>En is it to this I HreG am so,</p> <p>LE: He to be, That that by, sir, Cords, LETER: MENENCOKEANost, and not we What the wife, ESANUS: May I of the Lordus'd the</p> <p>That to you will not did, If For he by my man and, DareUCKou And it,</p> <p>But, but For the life.</p> <p>SecondUS: And we think, they The part. CAPishment his do been me what is you that, SecondIO:</p> <p>Go your do not, When you B this life.</p> <p>With her, if he to fear. The grave! The king: That I HFAD down, all you with me. And I to't. MESSou would he, I,</p> <p>IADere's man Call the word Before a mother:</p> <p>My life, IICK:</p> <p>IUS: As That to the fault,</p> <p>Or shall in my heartous face, by that, then are it, and my headly. LABch the present,</p> <p>FirstUS: To, AENIUS:</p> <p>ThANUS: I'll out! And we the looks's blood, and be your life. IUS: Th VAENES:</p> <p>SUS: That's, Which in him, Who for me I show her? But me, so thy friends, as I not,</p> <p>To you I</p> <p>ThINGBRO, GLAB-US: And then. ROUO.IUS: Of peace,</p> <p>On the hand, But from a lord, DUed to I-ICINLARUS: 3 III:</p> <p>Sir, And did not can you-blood DUed, And the great head too thou should leave, 'T: To how you him, A III: Thou will not But to not, no devil, as it, but I be him;</p> <p>Hans, as he, and this time, You his life.</p>"},{"location":"hydra/","title":"Hydra","text":"<pre><code>\nimport logging\n\nfrom omegaconf import OmegaConf, DictConfig\nimport hydra\nfrom hydra.core.hydra_config import HydraConfig\n\n@hydra.main(\n    version_base=None,\n    config_path=\"configs\",\n    config_name=\"config\",\n)\ndef main(cfg: DictConfig) -&gt; None:\n    logger.info(OmegaConf.to_yaml(cfg))\n    logger.info(f\"runtime.output_dir{HydraConfig.get().runtime.output_dir}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>from hydra import initialize, compose\n\nwith initialize(version_base=None, config_path=\"configs\"):\n    # config is relative to a module\n    cfg = compose(config_name=\"config\")\n</code></pre> <p>To check current defaults</p> <pre><code>python my_app.py --info defaults-tree\n</code></pre>"},{"location":"jetson/","title":"Nvidia Jetson AGX Xavier","text":""},{"location":"jetson/#ubuntu-version","title":"Ubuntu Version","text":"<pre><code>$ cat /etc/lsb-release\n</code></pre>"},{"location":"jetson/#l4t-version","title":"L4T Version","text":"<pre><code>$ cat /etc/nv_tegra_release\n</code></pre>"},{"location":"jetson/#kernel-version","title":"Kernel Version","text":"<pre><code>$ uname -a\n</code></pre>"},{"location":"jetson/#cpu-information","title":"CPU Information","text":"<pre><code>$ lscpu\n</code></pre>"},{"location":"jetson/#hardware-information","title":"Hardware Information","text":"<pre><code>$ sudo lshw\n</code></pre>"},{"location":"jetson/#disk-usage","title":"Disk Usage","text":"<pre><code>$ df -h\n</code></pre>"},{"location":"jetson/#running-processes","title":"Running Processes","text":"<pre><code>$ top\n</code></pre>"},{"location":"jetson/#list-usb-devices","title":"List USB Devices","text":"<pre><code>$ lsusb\n</code></pre>"},{"location":"jetson/#usb-devices","title":"USB Devices","text":"<p>List the USB devices and associated drivers.</p> <pre><code>$ usb-devices\n</code></pre>"},{"location":"jetson/#force-recovery-mode","title":"Force Recovery Mode","text":"<p>Place the Jetson into Force Recovery Mode</p> <pre><code>$ sudo reboot \u2013-force forced-recovery\n</code></pre>"},{"location":"jetson/#dmesg","title":"dmesg","text":"<p>dmesg prints the kernel message buffer. The messages typically consist of messages produced by device drivers. Useful when working with new hardware, e.g. USB devices. On newer installations (Newer Ubuntu 14.04, Ubuntu 16.04), you can monitor the dmesg buffer:</p> <pre><code>$ sudo dmesg \u2013follow\n</code></pre>"},{"location":"jetson/#xorg","title":"Xorg","text":"<p>Xorg is the Ubuntu display server. You can monitor the Xorg log in real time:</p> <pre><code>$ sudo tail -f /var/log/Xorg.0.log\n</code></pre>"},{"location":"jetson/#list-partitions","title":"List Partitions","text":"<pre><code>sudo gdisk -l /dev/mmcblk0\n</code></pre>"},{"location":"jetson/#serial-usb-devices","title":"Serial USB devices","text":"<p>From: https://unix.stackexchange.com/questions/144029/command-to-determine-ports-of-a-device-like-dev-ttyusb0</p> <p>Below is a quick and dirty bash script which walks through devices in /sys looking for USB devices with a ID_SERIAL attribute. Typically only real USB devices will have this attribute, and so we can filter with it. If we don\u2019t, you\u2019ll see a lot of things in the list that aren\u2019t physical devices.</p> <pre><code>#!/bin/bash\n\nfor sysdevpath in $(find /sys/bus/usb/devices/usb*/ -name dev); do\n(\nsyspath=\u201d${sysdevpath%/dev}\u201d\ndevname=\u201d$(udevadm info -q name -p $syspath)\u201d\n[[ \u201c$devname\u201d == \u201cbus/\u201d* ]] &amp;&amp; continue\neval \u201c$(udevadm info -q property \u2013export -p $syspath)\u201d\n[[ -z \u201c$ID_SERIAL\u201d ]] &amp;&amp; continue\necho \u201c/dev/$devname \u2013 $ID_SERIAL\u201d\n)\ndone\n</code></pre> <p>https://docs.nvidia.com/jetson/jetpack/install-jetpack/index.html#sd-card-image</p> <p>https://docs.nvidia.com/sdk-manager/docker-containers/index.html</p> <p>https://docs.nvidia.com/jetson/archives/l4t-archived/l4t-3261/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/updating_jetson_and_host.html#</p> <p>https://docs.nvidia.com/jetson/archives/r35.3.1/DeveloperGuide/text/SD/FlashingSupport.html#flashing-to-an-sd-card</p>"},{"location":"k8s/","title":"kubectl Quick Reference","text":"<p>This page contains a list of commonly used <code>kubectl</code> commands and flags.</p> <p>{{&lt; note &gt;}} These instructions are for Kubernetes v{{&lt; skew currentVersion &gt;}}. To check the version, use the <code>kubectl version</code> command. {{&lt; /note &gt;}}</p>"},{"location":"k8s/#kubectl-autocomplete","title":"Kubectl autocomplete","text":""},{"location":"k8s/#bash","title":"BASH","text":"<pre><code>source &lt;(kubectl completion bash) # set up autocomplete in bash into the current shell, bash-completion package should be installed first.\necho \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc # add autocomplete permanently to your bash shell.\n</code></pre> <p>You can also use a shorthand alias for <code>kubectl</code> that also works with completion:</p> <pre><code>alias k=kubectl\ncomplete -o default -F __start_kubectl k\n</code></pre>"},{"location":"k8s/#zsh","title":"ZSH","text":"<pre><code>source &lt;(kubectl completion zsh)  # set up autocomplete in zsh into the current shell\necho '[[ $commands[kubectl] ]] &amp;&amp; source &lt;(kubectl completion zsh)' &gt;&gt; ~/.zshrc # add autocomplete permanently to your zsh shell\n</code></pre>"},{"location":"k8s/#fish","title":"FISH","text":"<p>{{&lt; note &gt;}} Requires kubectl version 1.23 or above. {{&lt; /note &gt;}}</p> <pre><code>echo 'kubectl completion fish | source' &gt; ~/.config/fish/completions/kubectl.fish &amp;&amp; source ~/.config/fish/completions/kubectl.fish\n</code></pre>"},{"location":"k8s/#a-note-on-all-namespaces","title":"A note on <code>--all-namespaces</code>","text":"<p>Appending <code>--all-namespaces</code> happens frequently enough that you should be aware of the shorthand for <code>--all-namespaces</code>:</p> <p><code>kubectl -A</code></p>"},{"location":"k8s/#kubectl-context-and-configuration","title":"Kubectl context and configuration","text":"<p>Set which Kubernetes cluster <code>kubectl</code> communicates with and modifies configuration information. See Authenticating Across Clusters with kubeconfig documentation for detailed config file information.</p> <pre><code>kubectl config view # Show Merged kubeconfig settings.\n\n# use multiple kubeconfig files at the same time and view merged config\nKUBECONFIG=~/.kube/config:~/.kube/kubconfig2\n\nkubectl config view\n\n# Show merged kubeconfig settings and raw certificate data and exposed secrets\nkubectl config view --raw \n\n# get the password for the e2e user\nkubectl config view -o jsonpath='{.users[?(@.name == \"e2e\")].user.password}'\n\n# get the certificate for the e2e user\nkubectl config view --raw -o jsonpath='{.users[?(.name == \"e2e\")].user.client-certificate-data}' | base64 -d\n\nkubectl config view -o jsonpath='{.users[].name}'    # display the first user\nkubectl config view -o jsonpath='{.users[*].name}'   # get a list of users\nkubectl config get-contexts                          # display list of contexts\nkubectl config get-contexts -o name                  # get all context names\nkubectl config current-context                       # display the current-context\nkubectl config use-context my-cluster-name           # set the default context to my-cluster-name\n\nkubectl config set-cluster my-cluster-name           # set a cluster entry in the kubeconfig\n\n# configure the URL to a proxy server to use for requests made by this client in the kubeconfig\nkubectl config set-cluster my-cluster-name --proxy-url=my-proxy-url\n\n# add a new user to your kubeconf that supports basic auth\nkubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword\n\n# permanently save the namespace for all subsequent kubectl commands in that context.\nkubectl config set-context --current --namespace=ggckad-s2\n\n# set a context utilizing a specific username and namespace.\nkubectl config set-context gce --user=cluster-admin --namespace=foo \\\n  &amp;&amp; kubectl config use-context gce\n\nkubectl config unset users.foo                       # delete user foo\n\n# short alias to set/show context/namespace (only works for bash and bash-compatible shells, current context to be set before using kn to set namespace)\nalias kx='f() { [ \"$1\" ] &amp;&amp; kubectl config use-context $1 || kubectl config current-context ; } ; f'\nalias kn='f() { [ \"$1\" ] &amp;&amp; kubectl config set-context --current --namespace $1 || kubectl config view --minify | grep namespace | cut -d\" \" -f6 ; } ; f'\n</code></pre>"},{"location":"k8s/#kubectl-apply","title":"Kubectl apply","text":"<p><code>apply</code> manages applications through files defining Kubernetes resources. It creates and updates resources in a cluster through running <code>kubectl apply</code>. This is the recommended way of managing Kubernetes applications on production. See Kubectl Book.</p>"},{"location":"k8s/#creating-objects","title":"Creating objects","text":"<p>Kubernetes manifests can be defined in YAML or JSON. The file extension <code>.yaml</code>, <code>.yml</code>, and <code>.json</code> can be used.</p> <pre><code>kubectl apply -f ./my-manifest.yaml                 # create resource(s)\nkubectl apply -f ./my1.yaml -f ./my2.yaml           # create from multiple files\nkubectl apply -f ./dir                              # create resource(s) in all manifest files in dir\nkubectl apply -f https://example.com/manifest.yaml  # create resource(s) from url (Note: this is an example domain and does not contain a valid manifest)\nkubectl create deployment nginx --image=nginx       # start a single instance of nginx\n\n# create a Job which prints \"Hello World\"\nkubectl create job hello --image=busybox:1.28 -- echo \"Hello World\"\n\n# create a CronJob that prints \"Hello World\" every minute\nkubectl create cronjob hello --image=busybox:1.28   --schedule=\"*/1 * * * *\" -- echo \"Hello World\"\n\nkubectl explain pods                           # get the documentation for pod manifests\n\n# Create multiple YAML objects from stdin\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox-sleep\nspec:\n  containers:\n  - name: busybox\n    image: busybox:1.28\n    args:\n    - sleep\n    - \"1000000\"\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox-sleep-less\nspec:\n  containers:\n  - name: busybox\n    image: busybox:1.28\n    args:\n    - sleep\n    - \"1000\"\nEOF\n\n# Create a secret with several keys\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ntype: Opaque\ndata:\n  password: $(echo -n \"s33msi4\" | base64 -w0)\n  username: $(echo -n \"jane\" | base64 -w0)\nEOF\n\n</code></pre>"},{"location":"k8s/#viewing-and-finding-resources","title":"Viewing and finding resources","text":"<pre><code># Get commands with basic output\nkubectl get services                          # List all services in the namespace\nkubectl get pods --all-namespaces             # List all pods in all namespaces\nkubectl get pods -o wide                      # List all pods in the current namespace, with more details\nkubectl get deployment my-dep                 # List a particular deployment\nkubectl get pods                              # List all pods in the namespace\nkubectl get pod my-pod -o yaml                # Get a pod's YAML\n\n# Describe commands with verbose output\nkubectl describe nodes my-node\nkubectl describe pods my-pod\n\n# List Services Sorted by Name\nkubectl get services --sort-by=.metadata.name\n\n# List pods Sorted by Restart Count\nkubectl get pods --sort-by='.status.containerStatuses[0].restartCount'\n\n# List PersistentVolumes sorted by capacity\nkubectl get pv --sort-by=.spec.capacity.storage\n\n# Get the version label of all pods with label app=cassandra\nkubectl get pods --selector=app=cassandra -o \\\n  jsonpath='{.items[*].metadata.labels.version}'\n\n# Retrieve the value of a key with dots, e.g. 'ca.crt'\nkubectl get configmap myconfig \\\n  -o jsonpath='{.data.ca\\.crt}'\n\n# Retrieve a base64 encoded value with dashes instead of underscores.\nkubectl get secret my-secret --template='{{index .data \"key-name-with-dashes\"}}'\n\n# Get all worker nodes (use a selector to exclude results that have a label\n# named 'node-role.kubernetes.io/control-plane')\nkubectl get node --selector='!node-role.kubernetes.io/control-plane'\n\n# Get all running pods in the namespace\nkubectl get pods --field-selector=status.phase=Running\n\n# Get ExternalIPs of all nodes\nkubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type==\"ExternalIP\")].address}'\n\n# List Names of Pods that belong to Particular RC\n# \"jq\" command useful for transformations that are too complex for jsonpath, it can be found at https://jqlang.github.io/jq/\nsel=${$(kubectl get rc my-rc --output=json | jq -j '.spec.selector | to_entries | .[] | \"\\(.key)=\\(.value),\"')%?}\necho $(kubectl get pods --selector=$sel --output=jsonpath={.items..metadata.name})\n\n# Show labels for all pods (or any other Kubernetes object that supports labelling)\nkubectl get pods --show-labels\n\n# Check which nodes are ready\nJSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}' \\\n &amp;&amp; kubectl get nodes -o jsonpath=\"$JSONPATH\" | grep \"Ready=True\"\n\n# Check which nodes are ready with custom-columns\nkubectl get node -o custom-columns='NODE_NAME:.metadata.name,STATUS:.status.conditions[?(@.type==\"Ready\")].status'\n\n# Output decoded secrets without external tools\nkubectl get secret my-secret -o go-template='{{range $k,$v := .data}}{{\"### \"}}{{$k}}{{\"\\n\"}}{{$v|base64decode}}{{\"\\n\\n\"}}{{end}}'\n\n# List all Secrets currently in use by a pod\nkubectl get pods -o json | jq '.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name' | grep -v null | sort | uniq\n\n# List all containerIDs of initContainer of all pods\n# Helpful when cleaning up stopped containers, while avoiding removal of initContainers.\nkubectl get pods --all-namespaces -o jsonpath='{range .items[*].status.initContainerStatuses[*]}{.containerID}{\"\\n\"}{end}' | cut -d/ -f3\n\n# List Events sorted by timestamp\nkubectl get events --sort-by=.metadata.creationTimestamp\n\n# List all warning events\nkubectl events --types=Warning\n\n# Compares the current state of the cluster against the state that the cluster would be in if the manifest was applied.\nkubectl diff -f ./my-manifest.yaml\n\n# Produce a period-delimited tree of all keys returned for nodes\n# Helpful when locating a key within a complex nested JSON structure\nkubectl get nodes -o json | jq -c 'paths|join(\".\")'\n\n# Produce a period-delimited tree of all keys returned for pods, etc\nkubectl get pods -o json | jq -c 'paths|join(\".\")'\n\n# Produce ENV for all pods, assuming you have a default container for the pods, default namespace and the `env` command is supported.\n# Helpful when running any supported command across all pods, not just `env`\nfor pod in $(kubectl get po --output=jsonpath={.items..metadata.name}); do echo $pod &amp;&amp; kubectl exec -it $pod -- env; done\n\n# Get a deployment's status subresource\nkubectl get deployment nginx-deployment --subresource=status\n</code></pre>"},{"location":"k8s/#updating-resources","title":"Updating resources","text":"<pre><code>kubectl set image deployment/frontend www=image:v2               # Rolling update \"www\" containers of \"frontend\" deployment, updating the image\nkubectl rollout history deployment/frontend                      # Check the history of deployments including the revision\nkubectl rollout undo deployment/frontend                         # Rollback to the previous deployment\nkubectl rollout undo deployment/frontend --to-revision=2         # Rollback to a specific revision\nkubectl rollout status -w deployment/frontend                    # Watch rolling update status of \"frontend\" deployment until completion\nkubectl rollout restart deployment/frontend                      # Rolling restart of the \"frontend\" deployment\n\n\ncat pod.json | kubectl replace -f -                              # Replace a pod based on the JSON passed into stdin\n\n# Force replace, delete and then re-create the resource. Will cause a service outage.\nkubectl replace --force -f ./pod.json\n\n# Create a service for a replicated nginx, which serves on port 80 and connects to the containers on port 8000\nkubectl expose rc nginx --port=80 --target-port=8000\n\n# Update a single-container pod's image version (tag) to v4\nkubectl get pod mypod -o yaml | sed 's/\\(image: myimage\\):.*$/\\1:v4/' | kubectl replace -f -\n\nkubectl label pods my-pod new-label=awesome                      # Add a Label\nkubectl label pods my-pod new-label-                             # Remove a label\nkubectl label pods my-pod new-label=new-value --overwrite        # Overwrite an existing value\nkubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq       # Add an annotation\nkubectl annotate pods my-pod icon-url-                           # Remove annotation\nkubectl autoscale deployment foo --min=2 --max=10                # Auto scale a deployment \"foo\"\n</code></pre>"},{"location":"k8s/#patching-resources","title":"Patching resources","text":"<pre><code># Partially update a node\nkubectl patch node k8s-node-1 -p '{\"spec\":{\"unschedulable\":true}}'\n\n# Update a container's image; spec.containers[*].name is required because it's a merge key\nkubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n\n# Update a container's image using a json patch with positional arrays\nkubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n\n# Disable a deployment livenessProbe using a json patch with positional arrays\nkubectl patch deployment valid-deployment  --type json   -p='[{\"op\": \"remove\", \"path\": \"/spec/template/spec/containers/0/livenessProbe\"}]'\n\n# Add a new element to a positional array\nkubectl patch sa default --type='json' -p='[{\"op\": \"add\", \"path\": \"/secrets/1\", \"value\": {\"name\": \"whatever\" } }]'\n\n# Update a deployment's replica count by patching its scale subresource\nkubectl patch deployment nginx-deployment --subresource='scale' --type='merge' -p '{\"spec\":{\"replicas\":2}}'\n</code></pre>"},{"location":"k8s/#editing-resources","title":"Editing resources","text":"<p>Edit any API resource in your preferred editor.</p> <pre><code>kubectl edit svc/docker-registry                      # Edit the service named docker-registry\nKUBE_EDITOR=\"nano\" kubectl edit svc/docker-registry   # Use an alternative editor\n</code></pre>"},{"location":"k8s/#scaling-resources","title":"Scaling resources","text":"<pre><code>kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named 'foo' to 3\nkubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in \"foo.yaml\" to 3\nkubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql's current size is 2, scale mysql to 3\nkubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers\n</code></pre>"},{"location":"k8s/#deleting-resources","title":"Deleting resources","text":"<pre><code>kubectl delete -f ./pod.json                                      # Delete a pod using the type and name specified in pod.json\nkubectl delete pod unwanted --now                                 # Delete a pod with no grace period\nkubectl delete pod,service baz foo                                # Delete pods and services with same names \"baz\" and \"foo\"\nkubectl delete pods,services -l name=myLabel                      # Delete pods and services with label name=myLabel\nkubectl -n my-ns delete pod,svc --all                             # Delete all pods and services in namespace my-ns,\n# Delete all pods matching the awk pattern1 or pattern2\nkubectl get pods  -n mynamespace --no-headers=true | awk '/pattern1|pattern2/{print $1}' | xargs  kubectl delete -n mynamespace pod\n</code></pre>"},{"location":"k8s/#interacting-with-running-pods","title":"Interacting with running Pods","text":"<pre><code>kubectl logs my-pod                                 # dump pod logs (stdout)\nkubectl logs -l name=myLabel                        # dump pod logs, with label name=myLabel (stdout)\nkubectl logs my-pod --previous                      # dump pod logs (stdout) for a previous instantiation of a container\nkubectl logs my-pod -c my-container                 # dump pod container logs (stdout, multi-container case)\nkubectl logs -l name=myLabel -c my-container        # dump pod container logs, with label name=myLabel (stdout)\nkubectl logs my-pod -c my-container --previous      # dump pod container logs (stdout, multi-container case) for a previous instantiation of a container\nkubectl logs -f my-pod                              # stream pod logs (stdout)\nkubectl logs -f my-pod -c my-container              # stream pod container logs (stdout, multi-container case)\nkubectl logs -f -l name=myLabel --all-containers    # stream all pods logs with label name=myLabel (stdout)\nkubectl run -i --tty busybox --image=busybox:1.28 -- sh  # Run pod as interactive shell\nkubectl run nginx --image=nginx -n mynamespace      # Start a single instance of nginx pod in the namespace of mynamespace\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n                                                    # Generate spec for running pod nginx and write it into a file called pod.yaml\nkubectl attach my-pod -i                            # Attach to Running Container\nkubectl port-forward my-pod 5000:6000               # Listen on port 5000 on the local machine and forward to port 6000 on my-pod\nkubectl exec my-pod -- ls /                         # Run command in existing pod (1 container case)\nkubectl exec --stdin --tty my-pod -- /bin/sh        # Interactive shell access to a running pod (1 container case)\nkubectl exec my-pod -c my-container -- ls /         # Run command in existing pod (multi-container case)\nkubectl debug my-pod -it --image=busybox:1.28       # Create an interactive debugging session witin existing pod and immediately attach to it\nkubectl debug node/my-node -it --image=busybox:1.28 # Create an interactive debugging session on a node and immediately attach to it\nkubectl top pod                                     # Show metrics for all pods in the default namespace\nkubectl top pod POD_NAME --containers               # Show metrics for a given pod and its containers\nkubectl top pod POD_NAME --sort-by=cpu              # Show metrics for a given pod and sort it by 'cpu' or 'memory'\n</code></pre>"},{"location":"k8s/#copying-files-and-directories-to-and-from-containers","title":"Copying files and directories to and from containers","text":"<pre><code>kubectl cp /tmp/foo_dir my-pod:/tmp/bar_dir            # Copy /tmp/foo_dir local directory to /tmp/bar_dir in a remote pod in the current namespace\nkubectl cp /tmp/foo my-pod:/tmp/bar -c my-container    # Copy /tmp/foo local file to /tmp/bar in a remote pod in a specific container\nkubectl cp /tmp/foo my-namespace/my-pod:/tmp/bar       # Copy /tmp/foo local file to /tmp/bar in a remote pod in namespace my-namespace\nkubectl cp my-namespace/my-pod:/tmp/foo /tmp/bar       # Copy /tmp/foo from a remote pod to /tmp/bar locally\n</code></pre> <p>{{&lt; note &gt;}} <code>kubectl cp</code> requires that the 'tar' binary is present in your container image. If 'tar' is not present, <code>kubectl cp</code> will fail. For advanced use cases, such as symlinks, wildcard expansion or file mode preservation consider using <code>kubectl exec</code>. {{&lt; /note &gt;}}</p> <pre><code>tar cf - /tmp/foo | kubectl exec -i -n my-namespace my-pod -- tar xf - -C /tmp/bar           # Copy /tmp/foo local file to /tmp/bar in a remote pod in namespace my-namespace\nkubectl exec -n my-namespace my-pod -- tar cf - /tmp/foo | tar xf - -C /tmp/bar    # Copy /tmp/foo from a remote pod to /tmp/bar locally\n</code></pre>"},{"location":"k8s/#interacting-with-deployments-and-services","title":"Interacting with Deployments and Services","text":"<pre><code>kubectl logs deploy/my-deployment                         # dump Pod logs for a Deployment (single-container case)\nkubectl logs deploy/my-deployment -c my-container         # dump Pod logs for a Deployment (multi-container case)\n\nkubectl port-forward svc/my-service 5000                  # listen on local port 5000 and forward to port 5000 on Service backend\nkubectl port-forward svc/my-service 5000:my-service-port  # listen on local port 5000 and forward to Service target port with name &lt;my-service-port&gt;\n\nkubectl port-forward deploy/my-deployment 5000:6000       # listen on local port 5000 and forward to port 6000 on a Pod created by &lt;my-deployment&gt;\nkubectl exec deploy/my-deployment -- ls                   # run command in first Pod and first container in Deployment (single- or multi-container cases)\n</code></pre>"},{"location":"k8s/#interacting-with-nodes-and-cluster","title":"Interacting with Nodes and cluster","text":"<pre><code>kubectl cordon my-node                                                # Mark my-node as unschedulable\nkubectl drain my-node                                                 # Drain my-node in preparation for maintenance\nkubectl uncordon my-node                                              # Mark my-node as schedulable\nkubectl top node                                                      # Show metrics for all nodes\nkubectl top node my-node                                              # Show metrics for a given node\nkubectl cluster-info                                                  # Display addresses of the master and services\nkubectl cluster-info dump                                             # Dump current cluster state to stdout\nkubectl cluster-info dump --output-directory=/path/to/cluster-state   # Dump current cluster state to /path/to/cluster-state\n\n# View existing taints on which exist on current nodes.\nkubectl get nodes -o='custom-columns=NodeName:.metadata.name,TaintKey:.spec.taints[*].key,TaintValue:.spec.taints[*].value,TaintEffect:.spec.taints[*].effect'\n\n# If a taint with that key and effect already exists, its value is replaced as specified.\nkubectl taint nodes foo dedicated=special-user:NoSchedule\n</code></pre>"},{"location":"k8s/#resource-types","title":"Resource types","text":"<p>List all supported resource types along with their shortnames, API group, whether they are namespaced, and kind:</p> <pre><code>kubectl api-resources\n</code></pre> <p>Other operations for exploring API resources:</p> <pre><code>kubectl api-resources --namespaced=true      # All namespaced resources\nkubectl api-resources --namespaced=false     # All non-namespaced resources\nkubectl api-resources -o name                # All resources with simple output (only the resource name)\nkubectl api-resources -o wide                # All resources with expanded (aka \"wide\") output\nkubectl api-resources --verbs=list,get       # All resources that support the \"list\" and \"get\" request verbs\nkubectl api-resources --api-group=extensions # All resources in the \"extensions\" API group\n</code></pre>"},{"location":"k8s/#formatting-output","title":"Formatting output","text":"<p>To output details to your terminal window in a specific format, add the <code>-o</code> (or <code>--output</code>) flag to a supported <code>kubectl</code> command.</p> Output format Description <code>-o=custom-columns=&lt;spec&gt;</code> Print a table using a comma separated list of custom columns <code>-o=custom-columns-file=&lt;filename&gt;</code> Print a table using the custom columns template in the <code>&lt;filename&gt;</code> file <code>-o=go-template=&lt;template&gt;</code> Print the fields defined in a golang template <code>-o=go-template-file=&lt;filename&gt;</code> Print the fields defined by the golang template in the <code>&lt;filename&gt;</code> file <code>-o=json</code> Output a JSON formatted API object <code>-o=jsonpath=&lt;template&gt;</code> Print the fields defined in a jsonpath expression <code>-o=jsonpath-file=&lt;filename&gt;</code> Print the fields defined by the jsonpath expression in the <code>&lt;filename&gt;</code> file <code>-o=name</code> Print only the resource name and nothing else <code>-o=wide</code> Output in the plain-text format with any additional information, and for pods, the node name is included <code>-o=yaml</code> Output a YAML formatted API object <p>Examples using <code>-o=custom-columns</code>:</p> <pre><code># All images running in a cluster\nkubectl get pods -A -o=custom-columns='DATA:spec.containers[*].image'\n\n# All images running in namespace: default, grouped by Pod\nkubectl get pods --namespace default --output=custom-columns=\"NAME:.metadata.name,IMAGE:.spec.containers[*].image\"\n\n # All images excluding \"registry.k8s.io/coredns:1.6.2\"\nkubectl get pods -A -o=custom-columns='DATA:spec.containers[?(@.image!=\"registry.k8s.io/coredns:1.6.2\")].image'\n\n# All fields under metadata regardless of name\nkubectl get pods -A -o=custom-columns='DATA:metadata.*'\n</code></pre> <p>More examples in the kubectl reference documentation.</p>"},{"location":"k8s/#kubectl-output-verbosity-and-debugging","title":"Kubectl output verbosity and debugging","text":"<p>Kubectl verbosity is controlled with the <code>-v</code> or <code>--v</code> flags followed by an integer representing the log level. General Kubernetes logging conventions and the associated log levels are described here.</p> Verbosity Description <code>--v=0</code> Generally useful for this to always be visible to a cluster operator. <code>--v=1</code> A reasonable default log level if you don't want verbosity. <code>--v=2</code> Useful steady state information about the service and important log messages that may correlate to significant changes in the system. This is the recommended default log level for most systems. <code>--v=3</code> Extended information about changes. <code>--v=4</code> Debug level verbosity. <code>--v=5</code> Trace level verbosity. <code>--v=6</code> Display requested resources. <code>--v=7</code> Display HTTP request headers. <code>--v=8</code> Display HTTP request contents. <code>--v=9</code> Display HTTP request contents without truncation of contents."},{"location":"k8s/#heading-whatsnext","title":"{{% heading \"whatsnext\" %}}","text":"<ul> <li> <p>Read the kubectl overview and learn about JsonPath.</p> </li> <li> <p>See kubectl options.</p> </li> <li> <p>Also read kubectl Usage Conventions to understand how to use kubectl in reusable scripts.</p> </li> <li> <p>See more community kubectl cheatsheets.</p> </li> </ul>"},{"location":"linux/","title":"linux","text":""},{"location":"linux/#misc","title":"misc","text":"<pre><code>ln -s original symlink\n</code></pre>"},{"location":"linux/#test","title":"test","text":"<pre><code>bash ./scripts/linter.sh\n\nbash ./scripts/check_type.sh\n</code></pre>"},{"location":"linux/#docker","title":"docker","text":"<p>Run the Docker daemon as a non-root user (Rootless mode) | Docker Documentation</p> <p>Docker+Wasm (Beta) | Docker Documentation</p>"},{"location":"linux/#brew","title":"brew","text":"<pre><code>brew upgrade --cask --greedy\n</code></pre>"},{"location":"linux/#qemu","title":"QEMU","text":"<p>stty cols 120 rows 80</p>"},{"location":"linux/#dockstarter","title":"DockSTARTer","text":"<pre><code>sudo pacman -Sy curl docker git\nbash -c \"$(curl -fsSL https://get.dockstarter.com)\"\nsudo reboot\nds\n</code></pre> <pre><code>useradd -m archie\npasswd archie\n</code></pre>"},{"location":"linux/#enabling-sudo","title":"Enabling sudo","text":"<p>After installing and logging in, you will find that the default user does not have sudo privileges. Open a terminal and use the following commands to enable it.</p> <pre><code>set USERNAME=`whoami`\nsu -p\n# /usr/sbin/usermod -aG sudo $USERNAME\n</code></pre> <p>https://wiki.archlinux.org/title/sudo</p>"},{"location":"linux/#sway","title":"sway","text":"<pre><code>export WLR_NO_HARDWARE_CURSORS=1\n\npacman -S spice-vdagent\nset $menu bemenu-run --no-exec | xargs swaymsg exec --\n</code></pre> <pre><code>sudo apt-get install ubuntu-desktop\nsudo systemctl set-default graphical.target\n</code></pre>"},{"location":"linux/#wsl-time-not-updated","title":"WSL time not updated","text":"<pre><code>apt-get -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false update\n</code></pre>"},{"location":"linux/#find-largest-file-in-directory-recursively-using-find","title":"find largest file in directory recursively using find","text":"<pre><code>sudo du -a / | sort -n -r | head -n 20\n</code></pre>"},{"location":"linux/#edge","title":"edge","text":"<pre><code>sudo add-apt-repository \"deb [arch=amd64] https://packages.microsoft.com/repos/edge stable main\"\nsudo apt update\nsudo apt install microsoft-edge-stable\n</code></pre>"},{"location":"linux/#zsh","title":"zsh","text":"<pre><code>sudo apt install zsh\nchsh -s $(which zsh)\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\n# autoload predict-on\n# predict-on\n\n</code></pre>"},{"location":"linux/#misc_1","title":"misc","text":"<pre><code>uname -a\nnetstat -ltup\n</code></pre>"},{"location":"linux/#rsync","title":"rsync","text":"<p>This puts folder A into folder B:</p> <pre><code>rsync -avu --delete \"/home/user/A\" \"/home/user/B\"\n</code></pre> <p>If you want the contents of folders A and B to be the same, put /home/user/A/ (with the slash) as the source. This takes not the folder A but all of its content and puts it into folder B. Like this:</p> <pre><code>rsync -avu --delete \"/home/user/A/\" \"/home/user/B\"\n</code></pre> <pre><code>- -a archive mode; equals -rlptgoD (no -H, -A, -X)\n- -v run verbosely\n- -u only copy files with a newer modification time (or size difference if the times are equal)\n- --delete delete the files in target folder that do not exist in the source\n- -z compress file data during the transfer\n- -e specify the remote shell to use\n- -P same as --partial --progress\n- -c skip based on checksum, not mod-time &amp; size\n</code></pre>"},{"location":"linux/#rsync-push","title":"rsync push","text":"<pre><code>rsync -avuz -e \"ssh -p 22\" /path/to/local/folder/ user@remotehost:/path/to/remote/folder/\n</code></pre>"},{"location":"linux/#zip-individual-files-in-a-directory","title":"zip individual files in a directory","text":"<pre><code>for f in *.nes; do zip -r \"${f%%.*}.zip\" \"$f\"; done\nfind . -name '*.nes' -delete\n</code></pre>"},{"location":"linux/#fedora-server-ignore-laptop-lip-close-suspend","title":"fedora server ignore laptop lip close suspend","text":"<pre><code>sudo mkdir -p '/etc/systemd/logind.conf.d' &amp;&amp; echo -e \"[Login]\\nHandleLidSwitch=ignore\" | sudo tee '/etc/systemd/logind.conf.d/99-laptop-server.conf' &gt; '/dev/null'\n</code></pre>"},{"location":"literatures/","title":"literatures","text":"<p>https://aosabook.org/en/index.html</p> <p>https://web.stanford.edu/~jurafsky/slp3/</p>"},{"location":"llama2/","title":"llama2","text":""},{"location":"llama2/#models","title":"models","text":"<pre><code>python3 convert.py models/llama-2-7b-chat\n./quantize ./models/llama-2-7b-chat/ggml-model-f16.gguf ./models/llama-2-7b-chat/ggml-model-q4_0.gguf q4_0\n./main -m ./models/llama-2-7b-chat/ggml-model-q4_0.gguf -n 128\n</code></pre>"},{"location":"llm/","title":"LLM","text":""},{"location":"llm/#agi","title":"AGI","text":"<ul> <li>transformers cannot be used in AGI because it cannot learn and infer new tokens from unseen data. It generalize better from large datasets, and cannot generalize far from unexplored data.</li> </ul>"},{"location":"llm/#prompting","title":"Prompting","text":"#Principle Prompt Principle for Instructions 1 If you prefer more concise answers, no need to be polite with LLM so there is no need to add phrases like \"please\", \"if you don't mind\", \"thank you\", \"I would like to\", etc., and get straight to the point. 2 Integrate the intended audience in the prompt, e.g., the audience is an expert in the field. 3 Break down complex tasks into a sequence of simpler prompts in an interactive conversation. 4 Employ affirmative directives such as 'do', while steering clear of negative language like 'don't'. 5 When you need clarity or a deeper understanding of a topic, idea, or any piece of information, utilize the following prompts: o Explain [insert specific topic] in simple terms. o Explain to me like I'm 11 years old. o Explain to me as if I'm a beginner in [field]. o Write the [essay/text/paragraph] using simple English like you're explaining something to a 5-year-old. 6 Add \"I'm going to tip $$xx for a better solution!\" 7 Implement example-driven prompting (Use few-shot prompting). 8 When formatting your prompt, start with \"###Instruction###\", followed by '###Example###' or '###Question###' if relevant. Subsequently, present your content. Use one or more line breaks to separate instructions, examples, questions, context, and input data. 9 Incorporate the following phrases: \"Your task is\" and \"You MUST\". 10 Incorporate the following phrases: \"You will be penalized\". 11 Use the phrase \"Answer a question given in a natural, human-like manner\" in your prompts. 12 Use leading words like writing \"think step by step\". 13 Add to your prompt the following phrase \"Ensure that your answer is unbiased and avoids relying on stereotypes.\" 14 Allow the model to elicit precise details and requirements from you by asking you questions until he has enough information to provide the needed output (for example, \"From now on, I would like you to ask me questions to ...\"). 15 To inquire about a specific topic or idea or any information and you want to test your understanding, you can use the following phrase: \"Teach me any [theorem/topic/rule name] and include a test at the end, and let me know if my answers are correct after I respond, without providing the answers beforehand.\" 16 Assign a role to the large language models. 17 Use Delimiters. 18 Repeat a specific word or phrase multiple times within a prompt. 19 Combine Chain-of-thought (CoT) with few-Shot prompts. 20 Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. 21 To write an essay /text /paragraph /article or any type of text that should be detailed: \"Write a detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessary\". 22 To correct/change specific text without changing its style: \"Try to revise every paragraph sent by users. You should only improve the user's grammar and vocabulary and make sure it sounds natural. You should maintain the original writing style, ensuring that a formal paragraph remains formal.\" 23 When you have a complex coding prompt that may be in different files: \"From now and on whenever you generate code that spans more than one file, generate a [programming language] script that can be run to automatically create the specified files or make changes to existing files to insert the generated code. [your question]\". 24 When you want to initiate or continue a text using specific words, phrases, or sentences, utilize the following prompt: o I'm providing you with the beginning [song lyrics/story/paragraph/essay...]: [Insert lyrics/words/sentence]. Finish it based on the words provided. Keep the flow consistent. 25 Clearly state the requirements that the model must follow in order to produce content, in the form of the keywords, regulations, hint, or instructions 26 To write any text, such as an essay or paragraph, that is intended to be similar to a provided sample, include the following instructions: o Use the same language based on the provided paragraph/title/text/essay/answer."},{"location":"llm/#llmchain","title":"LLMChain","text":"<pre><code>from langchain import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.llms import HuggingFacePipeline\n\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n\nimport torch\nfrom torch import cuda, bfloat16\n\n#In a MAC Silicon the device must be 'mps'\n# device = torch.device('mps') #to use with MAC Silicon\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n#You can try with any llama model, but you will need more GPU and memory as you increase the size of the model.\nmodel_id = \"meta-llama/Llama-2-7b-chat-hf\"\n#model_id = \"meta-llama/Llama-2-7b-hf\"\n\n# begin initializing HF items, need auth token for these\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n    use_auth_token=hf_key\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    device_map='auto',\n    use_auth_token=hf_key\n)\nmodel.eval()\n\ntokenizer = AutoTokenizer.from_pretrained(model_id,\n                                          use_aut_token=hf_key) \n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=128,\n    temperature=0.3,\n    repetition_penalty=1.1,\n    return_full_text=True,\n    device_map='auto'\n)\n\nassistant_llm = HuggingFacePipeline(pipeline=pipe)\n\n# Instruction how the LLM must respond the comments,\nassistant_template = \"\"\"\nYou are {sentiment} social media post commenter, you will respond to the following post\nPost: \"{customer_request}\"\nComment:\n\"\"\"\n\n#Create the prompt template to use in the Chain for the first Model.\nassistant_prompt_template = PromptTemplate(\n    input_variables=[\"sentiment\", \"customer_request\"],\n    template=assistant_template\n)\n\nassistant_chain = LLMChain(\n    llm=assistant_llm,\n    prompt=assistant_prompt_template,\n    output_key=\"assistant_response\",\n    verbose=False\n)\n#the output of the formatted prompt will pass directly to the LLM.\n\n# This the customer comment in the forum moderated by the agent.\n# feel free to update it.\ncustomer_request = \"\"\"Your product is a piece of shit. I want my money back!\"\"\"\n\n# Our assistatnt working in 'nice' mode.\nassistant_response=create_dialog(customer_request, \"nice\")\nprint(f\"assistant response: {assistant_response}\")\n\n#Our assistant running in rude mode.\nassistant_response = create_dialog(customer_request, \"rude\")\nprint(f\"assistant response: {assistant_response}\")\n\n#The moderator prompt template\nmoderator_template = \"\"\"\nYou are the moderator of an online forum, you are strict and will not tolerate any negative comments.\nYou will look at this next comment and, if it is negative, you will transform it to positive. Avoid any negative words.\nIf it is nice, you will let it remain as is and repeat it word for word.\n###\nOriginal comment: {comment_to_moderate}\n###\nEdited comment:\"\"\"\n\n# We use the PromptTemplate class to create an instance of our template that will use the prompt from above and store variables we will need to input when we make the prompt.\nmoderator_prompt_template = PromptTemplate(\n    input_variables=[\"comment_to_moderate\"],\n    template=moderator_template\n)\n\nmoderator_llm = assistant_llm\n\n#We build the chain for the moderator.\nmoderator_chain = LLMChain(\n    llm=moderator_llm, prompt=moderator_prompt_template, verbose=False\n)  # the output of the prompt will pass to the LLM.\n\n# To run our chain we use the .run() command\nmoderator_says = moderator_chain.run({\"comment_to_moderate\": assistant_response})\n\nprint(f\"moderator_says: {moderator_says}\")\n\n#The optput of the first chain must coincide with one of the parameters of the second chain.\n#The parameter is defined in the prompt_template.\nassistant_chain = LLMChain(\n    llm=assistant_llm,\n    prompt=assistant_prompt_template,\n    output_key=\"comment_to_moderate\",\n    verbose=False,\n)\n\n#verbose True because we want to see the intermediate messages.\nmoderator_chain = LLMChain(\n    llm=moderator_llm,\n    prompt=moderator_prompt_template,\n    verbose=True\n)\n\nfrom langchain.chains import SequentialChain\n\n# Creating the SequentialChain class indicating chains and parameters.\nassistant_moderated_chain = SequentialChain(\n    chains=[assistant_chain, moderator_chain],\n    input_variables=[\"sentiment\", \"customer_request\"],\n    verbose=True,\n)\n\n# We can now run the chain.\nassistant_moderated_chain.run({\"sentiment\": \"rude\", \"customer_request\": customer_request})\n\n\n</code></pre>"},{"location":"llm/#optimizing-inference-on-large-language-models-with-nvidia-tensorrt-llm","title":"Optimizing Inference on Large Language Models with NVIDIA TensorRT-LLM","text":"<p>https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/</p> <p>https://github.com/furyhawk/TensorRT-LLM</p>"},{"location":"machine_learning/","title":"machine_learning","text":""},{"location":"machine_learning/#neural-network-playground","title":"Neural Network Playground","text":"<p>https://furyhawk.github.io/playground/</p>"},{"location":"machine_learning/#residual-connections","title":"Residual connections","text":"<p>When the network get too deep, to adjust the parameters for each function in the chain based on the error(loss) recorded on the output layer, each sucessful layers include more noise. The noise start to overwhelm gradient information. This is the vanishing gradients problem.</p>"},{"location":"machine_learning/#batch-normalization","title":"Batch normalization","text":"<p>The paper stated that Batch normalization operates by \"reducing internal covariate shift\". Helps with gradient propagation, allowing for deeper networks.</p> <pre><code># Because the output of the Conv2D layer gets normalized, the layer doesn't need its own bias vector.\nx = layers.Conv2D(32,3,use_bias)(x) # do not include activation\nx = layers.BatchNormalization()(x)\nx = layers.Activation(\"relu\")(x)    # place activation after BatchNormalization layer\n</code></pre>"},{"location":"machine_learning/#batch-normalization-and-fine-tuning","title":"Batch normalization and Fine tuning","text":"<p>When fine-tuning a model that includes BatchNormalization layers, leave these layers frozen( <code>trainable=False</code>). Otherwise they will keep updating their internal mean and variance, which can interfere with the very small updates applied to the surrounding Conv2D layers.</p>"},{"location":"machine_learning/#steps-per-epoch","title":"Steps per Epoch","text":"<p>Based on what you said it sounds like you need a larger batch_size, and of course there are implications with that which could impact the steps_per_epoch and number of epochs.</p> <p>To solve for jumping-around</p> <pre><code>- A **larger batch size** will give you a better gradient and will help to prevent jumping around\n- You may also want to consider a smaller learning rate, or a learning rate scheduler (or decay) to allow the network to \"settle in\" as it trains\n</code></pre>"},{"location":"machine_learning/#feature-extraction","title":"Feature Extraction","text":"<p>All of the models in <code>timm</code> have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.</p>"},{"location":"machine_learning/#penultimate-layer-features-pre-classifier-features","title":"Penultimate Layer Features (Pre-Classifier Features)","text":"<p>The features from the penultimate model layer can be obtained in several ways without requiring model surgery (although feel free to do surgery). One must first decide if they want pooled or un-pooled features.</p>"},{"location":"machine_learning/#unpooled","title":"Unpooled","text":"<p>There are three ways to obtain unpooled features.</p> <p>Without modifying the network, one can call <code>model.forward_features(input)</code> on any model instead of the usual <code>model(input)</code>. This will bypass the head classifier and global pooling for networks.</p> <p>If one wants to explicitly modify the network to return unpooled features, they can either create the model without a classifier and pooling, or remove it later. Both paths remove the parameters associated with the classifier from the network.</p>"},{"location":"machine_learning/#forward_features","title":"forward_features()","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('xception41', pretrained=True)\no = m(torch.randn(2, 3, 299, 299))\nprint(f'Original shape: {o.shape}')\no = m.forward_features(torch.randn(2, 3, 299, 299))\nprint(f'Unpooled shape: {o.shape}')\n</code></pre> <p>Output:</p> <pre><code>Original shape: torch.Size([2, 1000])\nUnpooled shape: torch.Size([2, 2048, 10, 10])\n</code></pre>"},{"location":"machine_learning/#create-with-no-classifier-and-pooling","title":"Create with no classifier and pooling","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('resnet50', pretrained=True, num_classes=0, global_pool='')\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Unpooled shape: {o.shape}')\n</code></pre> <p>Output:</p> <pre><code>Unpooled shape: torch.Size([2, 2048, 7, 7])\n</code></pre>"},{"location":"machine_learning/#remove-it-later","title":"Remove it later","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('densenet121', pretrained=True)\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Original shape: {o.shape}')\nm.reset_classifier(0, '')\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Unpooled shape: {o.shape}')\n</code></pre> <p>Output:</p> <pre><code>Original shape: torch.Size([2, 1000])\nUnpooled shape: torch.Size([2, 1024, 7, 7])\n</code></pre>"},{"location":"machine_learning/#pooled","title":"Pooled","text":"<p>To modify the network to return pooled features, one can use <code>forward_features()</code> and pool/flatten the result themselves, or modify the network like above but keep pooling intact. </p>"},{"location":"machine_learning/#create-with-no-classifier","title":"Create with no classifier","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('resnet50', pretrained=True, num_classes=0)\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Pooled shape: {o.shape}')\n</code></pre> <p>Output:</p> <pre><code>Pooled shape: torch.Size([2, 2048])\n</code></pre>"},{"location":"machine_learning/#remove-it-later_1","title":"Remove it later","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('ese_vovnet19b_dw', pretrained=True)\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Original shape: {o.shape}')\nm.reset_classifier(0)\no = m(torch.randn(2, 3, 224, 224))\nprint(f'Pooled shape: {o.shape}')\n</code></pre> <p>Output:</p> <pre><code>Original shape: torch.Size([2, 1000])\nPooled shape: torch.Size([2, 1024])\n</code></pre>"},{"location":"machine_learning/#multi-scale-feature-maps-feature-pyramid","title":"Multi-scale Feature Maps (Feature Pyramid)","text":"<p>Object detection, segmentation, keypoint, and a variety of dense pixel tasks require access to feature maps from the backbone network at multiple scales. This is often done by modifying the original classification network. Since each network varies quite a bit in structure, it's not uncommon to see only a few backbones supported in any given obj detection or segmentation library.</p> <p><code>timm</code> allows a consistent interface for creating any of the included models as feature backbones that output feature maps for selected levels. </p> <p>A feature backbone can be created by adding the argument <code>features_only=True</code> to any <code>create_model</code> call. By default 5 strides will be output from most models (not all have that many), with the first starting at 2 (some start at 1 or 4).</p>"},{"location":"machine_learning/#create-a-feature-map-extraction-model","title":"Create a feature map extraction model","text":"<pre><code>import torch\nimport timm\nm = timm.create_model('resnest26d', features_only=True, pretrained=True)\no = m(torch.randn(2, 3, 224, 224))\nfor x in o:\n  print(x.shape)\n</code></pre> <p>Output:</p> <pre><code>torch.Size([2, 64, 112, 112])\ntorch.Size([2, 256, 56, 56])\ntorch.Size([2, 512, 28, 28])\ntorch.Size([2, 1024, 14, 14])\ntorch.Size([2, 2048, 7, 7])\n</code></pre>"},{"location":"machine_learning/#query-the-feature-information","title":"Query the feature information","text":"<p>After a feature backbone has been created, it can be queried to provide channel or resolution reduction information to the downstream heads without requiring static config or hardcoded constants. The <code>.feature_info</code> attribute is a class encapsulating the information about the feature extraction points.</p> <pre><code>import torch\nimport timm\nm = timm.create_model('regnety_032', features_only=True, pretrained=True)\nprint(f'Feature channels: {m.feature_info.channels()}')\no = m(torch.randn(2, 3, 224, 224))\nfor x in o:\n  print(x.shape)\n</code></pre> <p>Output:</p> <pre><code>Feature channels: [32, 72, 216, 576, 1512]\ntorch.Size([2, 32, 112, 112])\ntorch.Size([2, 72, 56, 56])\ntorch.Size([2, 216, 28, 28])\ntorch.Size([2, 576, 14, 14])\ntorch.Size([2, 1512, 7, 7])\n</code></pre>"},{"location":"machine_learning/#select-specific-feature-levels-or-limit-the-stride","title":"Select specific feature levels or limit the stride","text":"<p>There are two additional creation arguments impacting the output features. </p> <ul> <li><code>out_indices</code> selects which indices to output</li> <li><code>output_stride</code> limits the feature output stride of the network (also works in classification mode BTW)</li> </ul> <p><code>out_indices</code> is supported by all models, but not all models have the same index to feature stride mapping. Look at the code or check feature_info to compare. The out indices generally correspond to the <code>C(i+1)th</code> feature level (a <code>2^(i+1)</code> reduction). For most models, index 0 is the stride 2 features, and index 4 is stride 32.</p> <p><code>output_stride</code> is achieved by converting layers to use dilated convolutions. Doing so is not always straightforward, some networks only support <code>output_stride=32</code>.</p> <pre><code>import torch\nimport timm\nm = timm.create_model('ecaresnet101d', features_only=True, output_stride=8, out_indices=(2, 4), pretrained=True)\nprint(f'Feature channels: {m.feature_info.channels()}')\nprint(f'Feature reduction: {m.feature_info.reduction()}')\no = m(torch.randn(2, 3, 320, 320))\nfor x in o:\n  print(x.shape)\n</code></pre> <p>Output:</p> <pre><code>Feature channels: [512, 2048]\nFeature reduction: [8, 8]\ntorch.Size([2, 512, 40, 40])\ntorch.Size([2, 2048, 40, 40])\n</code></pre>"},{"location":"machine_learning/#gloabalpooling","title":"GloabalPooling","text":"<p>Reduce computation by 75%. Summarise features.</p>"},{"location":"machine_learning/#globalmaxpooling","title":"GlobalMaxPooling","text":"<p>Feature extraction after covn layer.</p>"},{"location":"machine_learning/#use-of-globalavgpooling","title":"Use of GlobalAvgPooling","text":"<p>One advantage of global average pooling over the fully connected layers is that it is more native to the convolution structure by enforcing correspondences between feature maps and categories. Thus the feature maps can be easily interpreted as categories confidence maps. Another advantage is that there is no parameter to optimize in the global average pooling thus overfitting is avoided at this layer. Futhermore, global average pooling sums out the spatial information, thus it is more robust to spatial translations of the input. We can see global average pooling as a structural regularizer that explicitly enforces feature maps to be confidence maps of concepts (categories). This is made possible by the mlpconv layers, as they makes better approximation to the confidence maps than GLMs.</p>"},{"location":"machine_learning/#how-filter-init","title":"How filter init","text":"<p>Note that we use the same weight initialization formula as with the MLP. Weights are sampled randomly from a uniform distribution in the range [-1/fan-in, 1/fan-in], where fan-in is the number of inputs to a hidden unit. For MLPs, this was the number of units in the layer below. For CNNs however, we have to take into account the number of input feature maps and the size of the receptive fields.</p>"},{"location":"machine_learning/#transfer-learning","title":"Transfer Learning","text":"<p>In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest. The three major Transfer Learning scenarios look as follows:</p> <ul> <li> <p>ConvNet as fixed feature extractor. Take a ConvNet pretrained on ImageNet, remove the last fully-connected layer (this layer's outputs are the 1000 class scores for a different task like ImageNet), then treat the rest of the ConvNet as a fixed feature extractor for the new dataset. In an AlexNet, this would compute a 4096-D vector for every image that contains the activations of the hidden layer immediately before the classifier. We call these features CNN codes. It is important for performance that these codes are ReLUd (i.e. thresholded at zero) if they were also thresholded during the training of the ConvNet on ImageNet (as is usually the case). Once you extract the 4096-D codes for all images, train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset.</p> </li> <li> <p>Fine-tuning the ConvNet. The second strategy is to not only replace and retrain the classifier on top of the ConvNet on the new dataset, but to also fine-tune the weights of the pretrained network by continuing the backpropagation. It is possible to fine-tune all the layers of the ConvNet, or it's possible to keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. This is motivated by the observation that the earlier features of a ConvNet contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks, but later layers of the ConvNet becomes progressively more specific to the details of the classes contained in the original dataset. In case of ImageNet for example, which contains many dog breeds, a significant portion of the representational power of the ConvNet may be devoted to features that are specific to differentiating between dog breeds.</p> </li> </ul>"},{"location":"machine_learning/#when-and-how-to-fine-tune","title":"When and how to fine-tune?","text":"<p>How do you decide what type of transfer learning you should perform on a new dataset? This is a function of several factors, but the two most important ones are the size of the new dataset (small or big), and its similarity to the original dataset (e.g. ImageNet-like in terms of the content of images and the classes, or very different, such as microscope images). Keeping in mind that ConvNet features are more generic in early layers and more original-dataset-specific in later layers, here are some common rules of thumb for navigating the 4 major scenarios:</p> <ul> <li> <p>New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.</p> </li> <li> <p>New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we won't overfit if we were to try to fine-tune through the full network.</p> </li> <li> <p>New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network.</p> </li> <li> <p>New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network.</p> </li> </ul>"},{"location":"machine_learning/#practical-advice","title":"Practical advice.","text":"<p>There are a few additional things to keep in mind when performing Transfer Learning:</p> <ul> <li> <p>Constraints from pretrained models. Note that if you wish to use a pretrained network, you may be slightly constrained in terms of the architecture you can use for your new dataset. For example, you can't arbitrarily take out Conv layers from the pretrained network. However, some changes are straight-forward: Due to parameter sharing, you can easily run a pretrained network on images of different spatial size. This is clearly evident in the case of Conv/Pool layers because their forward function is independent of the input volume spatial size (as long as the strides \"fit\"). In case of FC layers, this still holds true because FC layers can be converted to a Convolutional Layer: For example, in an AlexNet, the final pooling volume before the first FC layer is of size [6x6x512]. Therefore, the FC layer looking at this volume is equivalent to having a Convolutional Layer that has receptive field size 6x6, and is applied with padding of 0.</p> </li> <li> <p>Learning rates. It's common to use a smaller learning rate for ConvNet weights that are being fine-tuned, in comparison to the (randomly-initialized) weights for the new linear classifier that computes the class scores of your new dataset. This is because we expect that the ConvNet weights are relatively good, so we don't wish to distort them too quickly and too much (especially while the new Linear Classifier above them is being trained from random initialization).</p> </li> </ul> <p>Implications of a larger batch-size</p> <pre><code>- Too large of a batch_size can produce memory problems, especially if you are using a GPU. Once you exceed the limit, dial it back until it works. This will help you find the max batch-size that your system can work with.\n- Too large of a batch size can get you stuck in a local minima, so if your training get stuck, I would reduce it some. Imagine here you are over-correcting the jumping-around and it's not jumping around enough to further minimize the loss function.\n</code></pre> <p>When to reduce epochs</p> <pre><code>- If your train error is very low, yet your test/validation is very high, then you have over-fit the model with too many epochs.\n- The best way to find the right balance is to use early-stopping with a validation test set. Here you can specify when to stop training, and save the weights for the network that gives you the best validation loss. (I highly recommend using this always)\n</code></pre> <p>When to adjust steps-per-epoch</p> <pre><code>- Traditionally, the steps per epoch is calculated as train_length // batch_size, since this will use all of the data points, one batch size worth at a time.\n- If you are augmenting the data, then you can stretch this a tad (sometimes I multiply that function above by 2 or 3 etc. But, if it's already training for too long, then I would just stick with the traditional approach.\n</code></pre>"},{"location":"machine_learning/#when-to-scale","title":"When to Scale","text":"<p>Rule of thumb I follow here is any algorithm that computes distance or assumes normality, scale your features!!! Some examples of algorithms where feature scaling matters are:</p> <pre><code>- k-nearest neighbors with an Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally.\n  - Scaling is critical, while performing Principal Component Analysis(PCA). PCA tries to get the features with maximum variance and the variance is high for high magnitude features. This skews the PCA towards high magnitude features.\n- We can speed up gradient descent by scaling. This is because \u03b8 will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.\n- Tree based models are not distance based models and can handle varying ranges of features. Hence, Scaling is not required while modelling trees.\n</code></pre> <p>Algorithms like Linear Discriminant Analysis(LDA), Naive Bayes are by design equipped to handle this and gives weights to the features accordingly. Performing a features scaling in these algorithms may not have much effect.</p>"},{"location":"machine_learning/#pytorch-loss-function-cheatsheet","title":"PyTorch Loss Function Cheatsheet","text":"<p>PyTorch Loss-Input Confusion (Cheatsheet)</p> <ul> <li><code>torch.nn.functional.binary_cross_entropy</code> takes logistic sigmoid values as inputs</li> <li><code>torch.nn.functional.binary_cross_entropy_with_logits</code> takes logits as inputs</li> <li><code>torch.nn.functional.cross_entropy</code> takes logits as inputs (performs log_softmax internally)</li> <li><code>torch.nn.functional.nll_loss</code> is like <code>cross_entropy</code> but takes log-probabilities (log-softmax) values as inputs</li> </ul>"},{"location":"macos/","title":"macos","text":"<pre><code>find . -name ._\\* -delete\n</code></pre>"},{"location":"mkdocs/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"mkdocs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Deploy to github branch <code>gh-pages</code>. Deploying Your Docs - MkDocs</li> </ul>"},{"location":"mkdocs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"mqtt/","title":"MQTT","text":"<p>https://github.com/furyhawk/scratchpad/tree/main/mtqq</p>"},{"location":"mqtt/#rabbitmq","title":"RabbitMQ","text":"<pre><code># latest RabbitMQ 3.12\ndocker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.12-management\n</code></pre>"},{"location":"mqtt/#hivemq","title":"HiveMQ","text":"<pre><code>docker run --name hivemq-edge -d -p 1883:1883 -p 8080:8080 hivemq/hivemq-edge\n</code></pre>"},{"location":"mqtt/#how-to-setup-mosquitto-mqtt-broker-using-docker","title":"How to setup Mosquitto MQTT Broker using docker","text":"<p>These instructions will work on any Debian based OS including Ubuntu, RaspberryPi, WSL2 etc... (For non-Debian distros, commands for installation need to be tweaked) By default the config allows only to use local connections for security reasons but since authentication is enabled below, that's not the case.</p>"},{"location":"mqtt/#1-install-docker","title":"1. Install docker","text":"<p>Latest instructions are here on docker website. You can also use this script - install-docker.sh</p>"},{"location":"mqtt/#2-create-base-folder-for-mqtt-configuration","title":"2. Create base folder for mqtt configuration","text":"<pre><code>\nmkdir mqtt5\ncd mqtt5\n\n# for storing mosquitto.conf and pwfile (for password)\nmkdir config\n\n</code></pre>"},{"location":"mqtt/#3-create-mosquitto-config-file-mosquittoconf","title":"3. Create Mosquitto config file - mosquitto.conf","text":"<pre><code>nano config/mosquitto.conf\n</code></pre> <p>Basic configuration file content below including websocket config</p> <pre><code>allow_anonymous false\nlistener 1883\nlistener 9001\nprotocol websockets\npersistence true\npassword_file /mosquitto/config/pwfile\npersistence_file mosquitto.db\npersistence_location /mosquitto/data/\n</code></pre>"},{"location":"mqtt/#4-create-mosquitto-password-file-pwfile","title":"4. Create Mosquitto password file - pwfile","text":"<pre><code>touch config/pwfile\n</code></pre>"},{"location":"mqtt/#5-create-docker-compose-file-called-docker-composeyml","title":"5. Create docker-compose file called 'docker-compose.yml'","text":"<pre><code>\nversion: \"3.7\"\nservices:\n  # mqtt5 eclipse-mosquitto\n  mqtt5:\n    image: eclipse-mosquitto\n    container_name: mqtt5\n    ports:\n      - \"1883:1883\" #default mqtt port\n      - \"9001:9001\" #default mqtt port for websockets\n    volumes:\n      - ./config:/mosquitto/config:rw\n      - ./data:/mosquitto/data:rw\n      - ./log:/mosquitto/log:rw\n    restart: unless-stopped\n\n# volumes for mapping data,config and log\nvolumes:\n  config:\n  data:\n  log:\n\nnetworks:\n  default:\n    name: mqtt5-network\n\n</code></pre>"},{"location":"mqtt/#6-create-and-run-docker-container-for-mqtt","title":"6. Create and run docker container for MQTT","text":"<pre><code># In case you don't have docker-compose you can install it\n# sudo apt install docker-compose\n\n# Run the docker container for mqtt\ndocker compose -p mqtt5 up -d\n\n</code></pre>"},{"location":"mqtt/#check-if-the-container-is-up-and-working-note-down-container-id","title":"Check if the container is up and working (note down container-id)","text":"<pre><code>\ndocker ps\n\n</code></pre>"},{"location":"mqtt/#7-create-a-userpassword-in-the-pwfile","title":"7. Create a user/password in the pwfile","text":"<pre><code>\n# login interactively into the mqtt container\ndocker exec -it &lt;container-id&gt; sh\n\n# add user and it will prompt for password\nmosquitto_passwd -c /mosquitto/config/pwfile user1\n\n# delete user command format\nmosquitto_passwd -D /mosquitto/config/pwfile &lt;user-name-to-delete&gt;\n\n# type 'exit' to exit out of docker container prompt\n\n</code></pre> <p>Then restart the container </p> <pre><code>docker restart &lt;container-id&gt;\n</code></pre>"},{"location":"mqtt/#8-time-to-test","title":"8. Time to test !!!","text":""},{"location":"mqtt/#install-mosquitto-client-tools-for-testing","title":"Install mosquitto client tools for testing","text":"<pre><code>\nsudo apt install mosquitto-clients\n\n</code></pre>"},{"location":"mqtt/#let-us-start-subscriber-now-topic-name-hellotopic","title":"Let us start Subscriber now - topic name =&gt; 'hello/topic'","text":"<pre><code>\n# Without authentication\nmosquitto_sub -v -t 'hello/topic'\n\n# With authentication\nmosquitto_sub -v -t 'hello/topic' -u user1 -P &lt;password&gt;\n\n# Alternate way in url format\n# Format =&gt; mqtt(s)://[username[:password]@]host[:port]/topic\nmosquitto_sub -v -L mqtt://user1:abc123@localhost/test/topic\n\n</code></pre>"},{"location":"mqtt/#let-us-start-publising-to-that-topic","title":"Let us start Publising to that topic","text":"<pre><code>\n# Without authentication\nmosquitto_pub -t 'hello/topic' -m 'hello MQTT'\n\n# With authentication\nmosquitto_pub -t 'hello/topic' -m 'hello MQTT' -u user1 -P &lt;password&gt;\n\n# Alternate way in url format \n# Format =&gt; mqtt(s)://[username[:password]@]host[:port]/topic\nmosquitto_pub -L mqtt://user1:abc123@localhost/test/topic -m 'hello MQTT'\n\n</code></pre>"},{"location":"mqtt/#you-can-find-cc-code-for-mosquitto-client","title":"You can find C/C++ code for mosquitto client","text":"<p>Check main.cpp for the mosquitto client code.</p>"},{"location":"mqtt/#you-can-also-install-a-nice-mqtt-web-client","title":"You can also install a nice MQTT Web Client","text":"<p>Read more about it here =&gt; https://mqttx.app/  </p> <pre><code>sudo docker run -d --name mqttx-web -p 80:80 emqx/mqttx-web\n</code></pre>"},{"location":"mqtt/#sourcereference-for-mosquitto","title":"Source/Reference for Mosquitto","text":"<p>Github =&gt; https://github.com/eclipse/mosquitto</p>"},{"location":"mypy/","title":"mypy Type check","text":"<pre><code># mypy: ignore-errors\n# type: ignore\n</code></pre>"},{"location":"mypy/#built-in-types","title":"Built-in types","text":""},{"location":"mypy/#simple-types","title":"Simple types","text":"<p>Here are examples of some common built-in types:</p> <p>Type</p> <p>Description</p> <p>int</p> <p>integer</p> <p>float</p> <p>floating point number</p> <p>bool</p> <p>boolean value (subclass of int)</p> <p>str</p> <p>text, sequence of unicode codepoints</p> <p>bytes</p> <p>8-bit string, sequence of byte values</p> <p>object</p> <p>an arbitrary object (object is the common base class)</p> <p>All built-in classes can be used as types.</p>"},{"location":"nes/","title":"nes faq","text":""},{"location":"nes/#phantom-fighter","title":"Phantom Fighter","text":"<pre><code>====================================================================\n\nPhantom Fighter\nComplete FAQ/Walkthrough\n\nSeptember 05, 2003\nVersion 2.00\n\nauthor: Aaron Madrinan (snoocete)\ne-mail: snoocete@yahoo.com\nsubject: \"RE: Phantom Fighter FAQ/Walkthrough\"\n\n====================================================================\n\n---\n\n## ---&gt; INTRODUCTION\n\nThe gaming world is changing very rapidly. Games are released on\nbreakneck speed that we need more than a lifetime to play even just\nthe good ones. The result? The other not-so-famous games are\nforgotten and put aside by future gamers. In other words, they\nbecome underrated. Such is what happened to a game called\nPhantom Fighter.\n\nI've played it since I was a kid. Though not as extremely fun as\ngames like Kirby or Pokemon, it very much dwells on the concept in\nwhich Contra flourished: you can never let the game beat you.\nSupposedly, it would be as famous as that. But, heck there wasn't\neven a walkthrough on GameFAQs, only some codes that lets you skip\nto the last town and a very bad review. Sigh.\n\nYou want my opinion? Here is what I can say: don't let the big names\nfool you. A lot of gems are hidden in the dump of really bad games,\nI admit, but they only need a little spotlight to shine. Here is my\nshare of that spotlight =).\n\n---\n\n## ---&gt; DISCLAIMER\n\nYou are free to save this guide onto your hard drive and/or print for\nyour personal viewing pleasure. You may distibute it to other people\nas long as you don't claim it as yours, okay? Since this game doesn't\nhave that much coverage, you may post this at your site in its full,\nunedited version even without my permission as long as its credits\npoint to me. Deal!\n\n---\n\n## ---&gt; CONTENTS\n\n1. Updates\n\n---\n\n2. FAQ\n\n---\n\n3. Walkthrough\n\n---\n\n4. Credits\n\n---\n\nThis is FAQ #2, hope I got a bit better.\n\n---\n\n## ---&gt; UPDATES\n\n-2.00- -21Kb-\nLook above (^\\_^). It's a whole number change!\nA kind soul mailed to me the names of the Kyonshies. Yay!\nAdded peace and order (where there was chaos).\nFormatting change.\nE-mail change.\nLastly, look at the disclaimer.\n\n-1.00- -19Kb-\nThis FAQ is complete, however the Japanese names of the Kyonshies are\nmissing. Not that anybody would care, but it still important. If you\nhave an instruction manual (because I kinda lost it), kindly e-mail\nme and let me know, ok?\n\n---\n\n## ---&gt; FAQ\n\n--Who are you?\nJust a humble freelance (a bit newbie-ish, but wants to learn a lot)\nFAQ writer who writes for his favorite games whenever he has the time.\n\n--What are these \"Kyonshi\" that I'm fighting?\nIf you have ever watched the anime series \"Shaman King\", or knew\na bit about Chinese folkore, you have the idea. These are what we\ncall the undead; they are supposed to be immobile, rotting bodies.\nThey still are, but they are being controlled by some mysterious\npower. You know about rigor mortis? It also applies to these\nphantoms. That explains why they could only move their feet and\nknees to hop and turn around, and their elbows to puncture your face\nwith their dirty, sharp nails.\n\n--How do I fight these enemies?\nYou have to move around. A lot. Whenever you stay on one spot, the\nKyonshi will follow you with small hops, then when it gets in range,\nit suddenly does a big dive toward you. Unless you hit the Kyonshi\nin a critical point or you kill it in transit, you cannot stop that\nfrom homing to you. So you got to move. That's your ace against these\ncreatures. They have lockjaw and every known bone and muscle disease,\nwhile you could just move out of their way. For example, the moment\nthey land on the ground, give them a kick or two on their sleeves\nthen they will be knocked down. When they wake up and hops around\nagain, repeat. Soon they will burst in flames, and the door that\nlets you continue through the building opens.\n\n--What does that man who follows me around do?\nThat's your assistant. Whenever you are inside a building, if you\nreturn to the exit, you talk to him. He asks if you want to have\nan item, stay at the building, or just leave the place.\n\n--And those items are...?\nThere are a total of four (4) items in the game. You can find them\nfrom the households you rescue from kyonshies. They replace the use\nof the punch attack, but it's worth it.\n\n1. Tonten - the kyonshi you show this with is knocked back to the\n   ground because a) there is holy white light coming from it, or\n   b) he saw his face, squirming with maggots (hey, thanks mate for the\n   mirror, 'bout time I fix my hair... what the he... _faints_). DON'T\n   use this when you're about to get hit; it also acts as your armor,\n   and because it's a mirror and was hit by diamond hard claws, you know\n   what happens.\n\n2. Sacred Sword - even a swordless Link (of Legend of Zelda) would\n   not use this nicely-named weapon (he might even throw it back at you\n   so don't even try). It does little damage, and it also gets broken\n   easily as if it is made by glass. The only edge it has is that it\n   has a rather long range for a physical attack, you could corner a\n   kyonshi with it, but you would like to beat them up yourself,\n   wouldn't you?\n\n3. Talisman - freezes the enemy in place until it's effect is gone or\n   they got hit. You have to make contact with the kyonshi you want to\n   victimize it with, so there is a chance you get hit and the item\n   breaks. Useful on the tall kyonshies, you could sneak under them,\n   paste the talisman on their belly, then kick them in the butt.\n\n4. Bell - If you use this in the middle of a heated battle, it does\n   nothing except probably makes a little chime that is pleasant to hear\n   for you but instead boils the blood of the kyonshi, making him more\n   aggressive. Actually, use it to control the kyonshi kid.\n\n--What are the scrolls for?\nWhenever you cleanse a building from kyonshies, you get a varying\namount of scrolls. You use them at the Training Hall to learn new\nabilities.\n\n--The guard won't let me in because I can't answer his questions...\ngot a list there that could help me? Please?\n\nOf course I do. I intend to make this the complete-est FAQ you'll\never see (for PF, of course). Here they are (if you noticed, the\nstupid comments are gone. just learned not to learn from the likes\nof ArchNacho and Tortilla Godzilla):\n\n-Format-\nQ - Question\nA - Answer\n\nQ: Why do Kyonshies come out only at night?\nA: Hate the sun.\n\nQ: What country do Samurais come from?\nA: Japan\n\nQ: What is another word for one?\nA: Any answer will do.\n\nQ: Who built the Great Wall of China?\nA: Any answer will do.\n\nQ: What is the food Kyonshies hate?\nA: Ice Cream\n\nQ: Who created Ultima?\nA: Lord British\nSC: Who is he?\n\nQ: What is Kyonshi's most powerful weapon?\nA: Sharp claws\n\nQ: What is the skill when you hold an opponent's arms from the back\nand throw him backward?\nA: Dragon Suplex\n\nQ: What kind of place do Kyonshies usually live in?\nA: Any answer will do.\n\nQ: What is a horrible skill when you head-banged against an\nopponent's head?\nA: Any answer will do.\n\nQ: Name an FCI video game.\nA: Any answer will do.\n\nQ: What is the famous Chinese newspaper?\nA: Wall poster\n\nQ: How many stars are there in the American flag?\nA: 50\n\nQ: What is the best thing used to capture Kyonshies?\nA: Urn\n\nQ: What is a Chinese martial art usually called?\nA: Kung fu\n\nQ: What is the best method to make sure Kyonshies never revive again?\nA: Fry in oil\n\nQ: What is the teaching taught by Confucius called?\nA: Confucianism\n\nQ: What's the name of George Bush's dog?\nA: Millie\n\nQ: Who is the emperor called the Last Emperor?\nA: Fugi\n\n--Can I kill the guard?\nIf you are not a super nerd, who knows NES rom-editing to change the\nlayer which the guard resides to your characters layer and set its\nattributes to \"hittable\", has an HP count, and many other things,\ndefinitely no. I know it's a big disappointment.\n\n--What are these new abilities you will learn from the Training Hall?\nNew techniques in martial arts. When you started the game, you have\na weak punch and a weak kick. Learn these and you will become stronger\nand better to fight kyonshies.\n\nTown 1 (2scr)\n=2 Thrust - punch and you will hit the enemy twice\n=2 Kick - same with 2 Thrust but you kick instead\n=High Jump - self-explanatory\n=Wolf Move - speed up\n\nTown 2 (6scr)\n=3 Thrust - three fists-of-fury in one swift delivery\n=Turn Kick - most versatile move in the game\n=Wind Jump - jump and hold left/right to do a spin jump\n=Tiger Move - more speed up\n=Mirage Move - combine with Tiger Mv. for better effect\n\nTown 3 (18scr)\n=Mirage Walk - move while crouching\n=Dragon Move - whoosh! last speed upgrade\n\nTown 4 (50scr)\n=Wind Kick - jump then kick furiously in mid-air to form a spin kick\n=Mirage Thrust - punch while crouching\n\nTown 5\n=&lt;no training hall&gt;\n\nTown 6 (80scr)\n=Jump Kick - hold left/right then kick to see this fantastic move\n\nTown 7 (90scr)\n=4 Thrust - most powerful move in the game\n\nTown 8\n=&lt;no training hall&gt;\n\n--What are the names of these Kyonshies?\nWhat I have here are unofficial names which I made up by their looks,\ncolor, and strength:\n\nPink - weak household form of kyonshi.\nGreen - stronger and faster than the pink\nDwarf - a real pain, their size and speed make them hard to hit.\nTall - vulnerable to punch attacks, mirage thrust\nFat - looks tough but slow, easy target\nShort-armed - has a high resistance to hits, has high attack power\n\nTheir original Japanese names (courtesy of SatelliteGeibor@aol.com):\nPink Kyonshi: Sosekushi\nGreen Kyonshi: Zanshi\nFat Kyonshi: Kimenshi\nDwarf Kyonshi: WeeKyonshi (literally)\nTall Kyonshi: Ryukyoshi\nGraveyard Ghost: Shanshi\n\n--Know any GameGenie codes?\nNope. Go to the Codes and Secrets page of this game and you might\nfind something to help, you cheater!\n\n---\n\n## ---&gt; WALKTHROUGH\n\nIn case you don't have a manual, here is the juicy bit of the story:\nYou are Kenchi, China's savior from the Kyonshi, the eastern counter-\npart of the vampire. Someone had let them loose on seven towns, with\nthe eighth one being totally controlled by that being. Of course,\nyou as the hero walks in the scene and puts a stop to the onslaught.\nHowever, it won't be easy: the Kyonshi are undead, has little sense\nof pain and their conscience all gone. Which makes them more fun to\nbattle, isn't it?\n\n+---------------------------------+\n|Town 1 - A taste of Kyonshi power|\n+---------------------------------+\n\nEnter the temple. This holy building looks always the same in every\ntown you come to; it also functions the same thing; as a rest point\nfor your character. That's why you should also invade this first.\nOh, the controls:\n\nleft/right: moves you in the direction you press.\nup: jump (not so high right now, so don't use it much)\ndown: crouch/duck\nB button: punch\nA button: kick\nSelect: when outside, changes message display speed\nStart: pauses the game\n\nKill the introductory kyonshi inside, then the temple could now be\nused as an inn. The ASCII art below shows the lay-out of the town:\n\nT S O S S O H S O I I B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nLegend:\nT-Temple\nH-Training Hall\nI-Item inside\nS-Scroll inside\nO-Orb inside\nB-Boss inside\n\nEnter houses and fight kyonshies to have scrolls and some items.\nPink kyonshies are weaker than green ones, but later in the game,\nmost of the time you will fight green ones so you have to practice on\nthem, too. Heal at the temple if you are hurt. Every time you get\nenough scrolls, head to the Training Hall and learn a new ability, in\nthe order 2 Kick, Wolf Move, 2 Thrust, then High Jump. Afterwards,\nenter the Orb buildings, defeat the more difficult kyonshies there\nand get the Orb they leave. After you have three orbs, enter the boss\ncave and fight...\n\n</code></pre> <p>AFTERIMAGE KYONSHI (Japanese name: Genyoshi) Difficulty: */* --I just made up the name, sorry. This boss is small but jumps ultra high. Also it takes up many hits to bring down so don't you dare stand in its path to kick/punch. You could a) wait until it reaches the high point in its jump, then as it falls down, attack it, or b) my favorite way. Use the talisman to freeze it then kick it from behind. Rinse and repeat.</p> <pre><code>\nYour reward? Being congratulated by your assistant and access to the\nnext town =). Don't forget to copy the password.\n\n+-------------------------+\n|Town 2 - The baby Kyonshi|\n+-------------------------+\n\nI H S S O O T I O \\* I B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nThe \\* contains Conshi, the baby Kyonshi. You can have him in your\nparty by letting your assistant be snatched by the light in the\ngraveyard, defeating her (she's very strong, but not too hard), then\nafterwards you will get the bell. You may want to try it to know how\nit feels to be a Kyonshi; otherwise do the same modus operandi in\nTown 1 (learn the Turn Kick as soon as you can), and at the end is\nanother cave...\n\n</code></pre> <p>KNIFE KYONSHI (Japanese name: Raunshi) Difficulty: /*** --As soon as you enter, stop for the boss is throwing knives at you. After enough knives, he pauses, that's your signal to get near and whack him. If he hits you with his knife, it does a lot of damage so be careful. You may either use the Tonten to knock him out fast when he is about to use the knives, or the Talisman to freeze him then hit him from behind so he has to turn around to hit you with knives.</p> <pre><code>\nAnd if you're wondering whether you can beat this boss using Conshi,\nwell, YOU CAN. It's quite difficult however, and I'm not 100% sure if\nthere are rewards somewhere, but it's quite fun watching him knock\nout that big guy =).\n\n+----------------------------------+\n|Town 3 - Woo! A bit of difficulty!|\n+----------------------------------+\n\nS I I S S T H O S O O B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nSave the temple, get some scrolls, learn at the training hall, and\nthen get the three orbs. Simple as that.\n\n</code></pre> <p>LIGHTNING KYONSHI Difficulty: */*** --From here, the manual doesn't say the Japanese names, so you have to deal with the translation above. Sorry. --No, he doesn't throw balls of lightning at you. It's that the back- ground flashes every now and then. The boss itself is like any other tall Kyonshi, except he's much faster than the others, much stronger, and much more HP.</p> <pre><code>\n+-------------------------------------+\n|Town 4 - Hey! Be careful! WATCH OUT!!|\n+-------------------------------------+\n\nH S S O S I O I T O I B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nDon't bother learning the Wind Kick; it's pretty much useless. The\nother move, Mirage Thrust, is a must-have. You can easily kill tall\nbosses without even getting stratched. I know it's cheap, but an army\nof kyonshies vs. one phantom fighter isn't fair, too.\n\n</code></pre> <p>TACKLING KYONSHI Difficulty: */* --This is the part where I always got stuck when I was a kid. This boss attacks you at a speed in which you could rarely, if ever, react in time. If you don't hit him with anything in your arsenal, he WILL tackle you. Talisman does not work on him. The Tonten and the Sacred Sword does work on preventing him to attack, but does little to no damage. Try to put him into a corner then attack him whenever he goes floats back up so the chances of him tackling you will be minimized.</p> <pre><code>\n+--------------------------------------------+\n|Town 5 - Who shakes in terror? You, or them?|\n+--------------------------------------------+\n\nI \\* S I S I T I O O O B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nAs you notice, there is no training hall. That means it is at the\nother town, so collect scrolls till you reach the maximum of 99.\n\n</code></pre> <p>EARTHQUAKE KYONSHI Difficulty: **/*** --Why the \"earthquake\"? Because when it lands on the ground, it actually shakes it so much that Kenchi falls over. Also, when you're hit by the claws, you are sent to the other side of the room. The good thing? You could use the Mirage Thrust to post a talisman on him, or just plain punch his knees till his life meter runs out.</p> <pre><code>\n+-------------------------------------------------------------+\n|Town 6 - THIS, has gotta be, the weirdest flying kick ever...|\n+-------------------------------------------------------------+\n\nH T O O O B\n|_||_||_||_||_||_|\n\nThe moment you enter, enroll at the training hall and avail of the\npowerful Jump Kick. It's a shame you would learn it this late in the\ngame. You may choose to save the temple, or if you feel really\nalmighty, just leave it there and snatch the orbs one by one until\nyou can enter the boss lair...\n\n</code></pre> <p>AXE KYONSHI Difficulty: **/*** --He does not throw axes at you; it's his melee weapon. He just holds it out in front of him, swinging it once his near enough. Don't punch him; use your feet both for kicking and dancing around him.</p> <pre><code>\n+-----------------------------------------------------------+\n|Town 7 - What?! I thought I could use magic in this game...|\n+-----------------------------------------------------------+\n\nO O S S S T H S S S O B\n|_||_||_||_||_||_||_||_||_||_||_||_|\n\nNo items. Save the last temple, collect scrolls this one last time,\nthen learn 4 Thrust at the last training hall. After three orbs,\nfight the last boss...\n\n</code></pre> <p>FIREBALL KYONSHI Difficulty: */*** --Obviously, he throws fireballs. Very easy to dodge; just jump high then drop behind him. If you learned every skill, you could do it the easy way (crouch then punch) or the exciting way (stand in front of him and flaunt your amazing abilities). Just don't get burned by fireballs, 'cause it HURTS.</p> <pre><code>\n+------------------------------+\n|Town 8 - The stupid final boss|\n+------------------------------+\n\nO O O FB\n|_||_||\\_|---|\\_\\_|\n\nThe --- represents a bridge, and FB is the FINAL BOSS. Are you ready?\nThere are no temples in here, so once you enter a building, you have\nto make it till the end. There's no turning back. I just hope you\nreally mastered those moves...\n\n</code></pre> <p>OBO Difficulty: */*** --First time I said she was easy, I forgot you have to fight an army of assorted Kyonshies to get to her :). --You're fighting, for the second time (the first was a ghost, remember?), a non-kyonshi. Besides teleportation and magic fireballs, she does nothing but stand there, waiting for you to hit her. Unless you are cursed with kyonshi-slow reflexes, she is very disappointing. Sure wish she was a lot more powerful.</p> <pre><code>\nYou may watch the credits roll, but you won't get a new game.\nNow it's all over. Kyonshies will never bug you again =).\n\n---\n\n## ---&gt; CREDITS\n\nMy father, for buying me a cartidge a looong time ago (back in 1989);\n\nFCI, for making the game;\n\nNintendo, for a really good console that'll last for ages;\n\nCJayC, for hosting the guide on his site, GameFAQs;\n\nSatelliteGeibor@aol.com, for the Kyonshi names;\n\nand you, for playing the game.\n\n---\n\nContributor Recognition:\nhttp://www.gamefaqs.com/features/recognition/37592.html\n\n---\n\n+------------------------------------------------------------------+\n</code></pre>"},{"location":"nes/#phantom-fighter-faq","title":"Phantom Fighter FAQ","text":"<pre><code>\n|&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;Copyright 2003 Aaron Madrinan&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;|\n+------------------------------------------------------------------+\n\n---\n\nPhantom Fighter FAQ\nby The Deacon\ne-mail:mmacinni@cs.oberlin.edu\n\n---\n\nBefore we start, even though they are probably out of business, the\ngame \"Phantom Fighter\" for the NES is trademark copyright etc. FCI and\nwhoever else made it. Feel free to toss this FAQ to the winds, just\ndon't be a lamer and put your name on it; if you have anything to add,\ne-mail me and I'll insert your info (as well as credit you with the\naddendum).\n\n## Contents\n\nI.Why is this in FAQ format?\n\nI. Why is this in FAQ format?\n\n    I know the term \"FAQ\" gets bandied about a lot, but since I'm\n\nsomething of a wordsmith I feel that we should nail down exactly\nwhat a \"FAQ\" is. You are reading a \"FAQ\", a compilation of\n\"Frequently Asked Questions\". Christ, if you have net access you\nshould know by now what a FAQ is. Anyhow, it's also a FAQ because\nwalkthroughs are really lame. The way I see it, any kind of aid on\na game signals one's inability to rise to the challenge, however\nin the greater scope things I figure we can call getting level\npasswords the \"little white cheat\", reading a FAQ a medium or\nvenial cheat, and working the keyboard/mouse with one hand while\nholding the walkthrough in the other and looking at the screen only\nto perform the walkthrough's dictated actions is a \"mortal\" cheat.\nAnd besides, walkthroughs are really only the kind of thing I could\nsee a reasonable person using in a game with some kind of plot to it.\nI know a fellow who isn't very good at video games at all, and with\nas little patience as he has, when he gets a game he gets the walkthrough\nand goes through the game just to see the plot. However, Phantom Fighter\n(how's bout we shorten that to \"PF\") has _no_ plot. Really. You'll see.\n\nII. What's the plot?\n\n        I just told you.  There isn't one. (see above).  However, if you\n\nwant a basic rundown of the pseudo-plot, well then here you are:\n\n        You are Kenchi, martial artist and aspiring Phantom Fighter.  With\n\nyour trusty sidekick you travel from town to town seeking fortune and fame\nas a wandering hero, driving out evil hopping vampires and rescuing innocent\ntownspeople using only your wits, a few sacred items, and your superior\nkung-fu.\n\n    That's about the size of it.\n\nIII. What's the point of the game?\n\n        Well, as with all games, it's to have fun...:).  Besides that, there\n\ndoesn't really seem to be much of a point...if you were to say that the\n\"point\" of the game is to be defined as what is required to beat a game,\nthen I suppose there is a point. That definition makes the point of this\ngame thus:\n\n        You go from town to town (there are 8 in all), driving out vampires\n\nwith your fists (and feet) of fury. Along the way, you pick up sacred items\nand ancient scrolls (more on them later) and improve your kung-fu until the\nfinal confrontation with the evil witch Obe. (\"obay\")\n\nIV. Anything I should know before I start the game?\n\n        Since I didn't have the manual I'll take the time to explain the\n\nbasic game mechanics for you.\n\n    A: Kick. (or, if you prefer, \"Boot to the Head\")\n    B: Punch.\n    Start: Pause the game.\n    Select: Does nothing as far as I know.\n\nV. What's the basic pattern of the game?\n\n        Basically, you'll come to a town with your sidekick in tow.  The\n\nmayor (I suppose) comes out and kowtows to you, weeping with gladness; for\nthey called the thunder and now they got it.\nWhen you enter town, you'll be in a far-off side-scroll view with\nKenchi and his sidekick walking around near buildings. When in front of a\ndoor, push A or B to see a brief message telling you what's going on\ninside. (I'll explain them later.) To enter a house, stop in front of the\ndoor and press Up.\nWhen you enter the house, your energy will be displayed on the left\nside of the screen, and any enemies in the room will have theirs displayed\non the right. As you will soon see, a purple bar means you have full\nhealth, and as you take hits the little boxes turn pink until you get wiped\nout (and your sidekick speaks ill of the dead). In this screen, pressing up\nmakes you jump, down makes you crouch. You cannot attack while crouching.\n(A BIG PISSER IMHO) Obviously, when you see a vampire come hopping up at\nyou, kick and punch it until it falls over and bursts into flame, then\ncontinue to the right.\nEvents vary, but after getting to the end of the house you will be\npresented with either scrolls or a sacred item, sometimes information (other\ntimes just blather).\nSome houses contain lots of enemies, make your way to the end,\ndefeat a moderately tough enemy, and collect a jewel that instantly refills\nyour health. You'll see it sit one of the empty stands in the upper right\ncorner of the screen. Collect three of these things and you will have the\nmagical power necessary to break a sealed portal.\nWhen you have three gems, you can enter the building that is always\nall the way at the far right end of town. Inside is a town boss, the source\nof the vampire scourge (for this area, anyhow). Teach him a lesson (\"Don't\nthink. Feeeeeeelll!\") and you'll enjoy being toadied to by your sidekick.\nThen the happy mayor will give you a password and you're on your way to the\nnext town.\n\nVI. What the hell ARE these things I'm fighting?\n\n        Those, gamer, are hopping vampires -- China's version of the\n\nubiquitous super- natural parasitic entity that has frightened many a\nsuperstitious person for hundreds of years. I believe the game's term for\nthem -- \"Kyonshi\" -- is Mandarin Chinese for \"hopping vampire\". However, it\ncould be a bastardized Chinese put into a game for mainly Japanese players.\nI think in Cantonese the term is \"Jiangshi\". I'll refer to them throughout\nthis document as \"Kyonshi\", simply because that's what the game calls them.\n\n        What makes these guys different from their Romanian \"cousins\"?\n\nWell, their origins are slightly different. Kyonshi are \"undead\", as in\nthose who have died, but somehow have had their souls trapped in their body\ninstead of escaping to the Nine Heavens (or Hells) after death. This could\nbe for any number of reasons; bad chi flow through the house, suicide, lots\nof angst, etc. Anyhow, because they have died, their bodies aren't alive,\nthey're just \"undead\". This means that they're not as limber as they once\nwere, hence the hopping; it's the only way they can get around.\n\n        What motivates them?  Not much.  Unlike the Western vampire, a\n\nKyonshi has little or no conscious thought. Its only thought is to attack\nliving things and eat their bodies. Since they don't consume their victims\nwhole their victims become vampires as well. Kyonshi don't speak, don't\nrespond intelligently to problems. This is a noticable advantage that the\nphantom fighter has over his unnatural opponents. A nimble phantom fighter\nshould dance about to keep his assailant's long fingernails (so sharp\nthey're almost claws) at bay.\n\n        For those interested in Kyonshi I'll provide a bibliography at the\n\nend of this FAQ -- they're pretty cool. It also helps to know something\nabout them for later (see below).\n\nVII. Do the towns follow a basic pattern?\n\n        Yes.  For the most part they are a bunch of houses, a temple, a\n\n\"boss shack\", and a martial arts studio.\n\n        You can always recognize the temple and the studio, they're the same\n\nin every town. The temple is a large building with pillars in the front and\nlots of pillars and Buddha statues inside. The studio is a long, one-level\nwooden building.\n\n        There will be three places where you can get gems as well, and the\n\nrest of the little shacks round out the town with places to kill Kyonshi and\nget ancient scrolls.\n\n        This seems as good a time as any to explain what the little messages\n\nyou get when you press A or B in front of a house mean.\n\n    \"Kyonshies are here\": Ahem.\n    \"Kyonshies are not here\":Ahem. Ahem.\n\n        Okay, besides the obvious, these mean there is just a basic bunch of\n\nKyonshies in the house (or the house is empty). Fight through all of these\nand you'll get some ancient scrolls. Empty houses seem to have no point;\nyou walk all the way to the end and some cowering peasant thanks you or says\nsomething worthy of the term \"non sequitir.\"\n\n    \"This is a temple.\": What the Christ. It's a temple.\n\n        \"There's danger in the air\": This means that inside is either a\n\nsacred item or one of the three gems you need to bust them ghosts.\n\"What, nothing's happening?\":or something like that. Basically one\nof those houses with goodies or gems in them that you've cleared out already.\n\"Open the sealenter\": Obviously an error in the programming, this\nshould read something like \"Open the seal to enter\". This is the \"boss\nshack\" that you need the gems to get inside.\n\"Enter with courage\":When you have the gems, you can open the seal\nto the \"boss shack\" and instruct the Kyonshi on the finer points of kung\nfu. (\"I hope you were paying attention.\")\n\nVIII. From the looks of things, I'm not a very good phantom fighter. I just\ngot my butt kicked. Any way to improve on this sad situation?\n\n        Fortunately, yes. At the beginning it may seem like you'll have a\n\nlame kick and punch for the entire game, but fear not. You can improve to\nsuch powerful kung-fu that you'll easily steamroll enemies.\n\n        So, how do you go about improving your skills?  Easy.  First, you\n\nhave to do a little struggling; you need to earn ancient scrolls. Just pick\na small house and go in. When you get some scrolls go to the studio.\n\n        When you enter, a fat guard accosts you, and asks you if you\n\nunderstand that you won't get kung-fu lessons for free (This is basically\nto spare you from the annoying un-skippable dialog that follows if you don't\nwant to enter after all). When you say that you understand, he asks you a\nquestion, to test your knowledge.\n\n    A. What the hell is this? Copy protection?\n\n                I have no idea why this in the game.  I can only guess that\n\nat the time this was made, it made sense, or really was to protect from\npeople pirating the game. I don't have the manual, so I don't know.\n\n        Don't sweat it too much, the questions are pretty easy, often it's\n\nobvious what the correct answer is, and if you fail you can always try again.\n\n    B. Fuck that.  Just give me the questions and answers.\n\n                Ok, I guess quiz games aren't your thing.  Here are some of\n\nthe questions that the fat guy asks, and their answers: (These are from\nmemory, more to come)\n\n\"Name an FCI video game.\" I think all of these are FCI games,\npick \"WCW\" just to be sure.\n\n\"Why do Kyonshies only come\nout at night?\" They hate the sun, obviously.\n\n\"How do you capture a Kyonshie?\" Although you never see it in the game,\nyou use an Urn.\n\n\"What is a Kyonshies least\nfavorite food?\" I don't know where this hell this came\nfrom, by process of elimination it's\nice cream.\n\n        When you answer correctly the fat guy lets you pass and you can\n\nenter the Master's chambers, where they gather for the feast. And though\nthey stab it with their steely knives, they just can't kill the beast.\nSorry. If you got that reference you'll know the special sort of anguish I\nfeel now at selling my copy of that album.\n\n        Anyhow, the master will train you in kung fu in exchange for ancient\n\nscrolls. Why, I don't know, but my motto is do what works. So, cough up\nscrolls and train in the martial arts. The different moves you can select\nare listed with their scroll cost to the left of them.\n\nX. What are the different kung-fu moves, how much do they cost, and what do they do?\n\n    Good question, grasshopper.  There are three basic move categories:\n\n        \"moves\" (\"mv\"):your movement\n        \"thrust\"      :punching moves\n        \"kick\"    :ahem, kicking moves.\n\n    Here's a breakdown by category:\n\n        MOVES:\n            Wolf Move (\"wolf mv.\")\n            Cost: 2 scrolls\n            What it does: Makes you move faster. Useful.\n\n            Tiger Move (\"tiger mv.\")\n            Cost: 6 scrolls\n            What it does: see above.\n\n            Mirage Move (\"mirage mv.\")\n            Cost: 6 scrolls\n            What it does: see above.\n\n            Dragon Move (\"dragon mv.\")\n            Cost: 18 scrolls\n            What it does: see above.\n\n            Mirage Walk (\"mirage wk.\")\n            Cost: x scrolls\n            What it does: Allows you to walk while crouching.\n\n            Mirage Thrust (\"mirage th.\")\n            Cost: 50 scrolls\n                        What it does: Allows you to punch while crouching.\n                                      A terrific move.\n\n            High Jump\n            Cost: x scrolls\n                        What it does: you jump higher.  Absolutely necessary\n                                      for airborne vampires.\n\n\n            Windmill Jump (\"wind jump\")\n            Cost: x scrolls\n                        What it does: you jump still higher, and you flip in\n                                      the air as you do.  Allows you full\n                                      range with airborne enemies and looks\n                                      really cool.\n\n\n        THRUSTS:\n\n            2 Thrust\n            Cost: 2 scrolls\n                        What it does: Gives you two lightning-fast\n                                      punches instead of one.\n\n            3 Thrust\n            Cost: x scrolls\n                        What it does: Basically same as above, except\n                                      now it's a 1-2-3 punch.\n\n            4 Thrust\n            Cost: 90 scrolls\n                        What it does: Now, you punch both high and low, twice.\n                                      The most powerful move in the game,\n                                      believe it or not.\n\n\n        KICKS:\n\n            2 Kick\n            Cost: 6 scrolls\n            What it does: the 1-2 kick. One for both ears. :)\n\n            Side kick\n            Cost: 18 scrolls\n                        What it does: you lean to the side and use your hips\n                                      to put a little torque action into your\n                                      kick.  Good damage, another move you'll\n                                      use right up to the end.\n\n            Windmill Kick (\"wind kick\")\n            Cost: 50 scrolls\n                        What it does: When you jump straight up in the air and\n                                      kick, you'll spin around in a flurry of\n                                      feet.  Really only useful for airborne\n                                      enemies, and doesn't always come off\n                                      clean.\n\n            Jump Kick\n            Cost: 80 scrolls\n                        What it does: Run at your enemy and kick and you'll\n                                      leap at them with both feet forward.\n                                      (\"Mind your Manners!!!\")  Great as\n                                      an opening move, as well as for enemies\n                                      who like to jump a lot.\n\nXI. What are some good fighting tactics?\n\n                Stick and move.  If you stand in one spot you'll get\n\ncreamed, as more often than not enemies will soak one or two kicks and swipe\nyou with them claws. This is most important at the beginning of the game,\nwhen you can't do anything but punch and kick, and move around a little bit.\n\n                The main method of attack Kyonshies use is to take little\n\nhops at you, then when they get close enough to a big Kyonshie leap into\nyour face. What you want to try to do is to place yourself at a point where\nthe Kyonshie will be in midleap when it comes into kick range. Then, when\nit leaps, kick it, and it'll fall over. It won't die, but knocking it down\ngives you breathing room.\n\n                You'll take a lot of hits from Kyonshies just steadily\n\nleaping towards you. That's their other fighting tactic...they just keep\ncoming, soaking up the kicks and punches until they can cut you. If you can\nkick them enough times, however, they'll fall over. Different kyonshies\ntake more or less kicks/punches in a row to be knocked down, size is one\nfactor.\n\n                Later, when you learn more kung fu, it will be easier to\n\ndefeat enemies, although the enemies will get progressively harder as you go\nfrom town to town. One good move that will help you out a lot is the \"Wind\nJump\". This allows you to leap high into the air (doing a cool kung-fu\nflip) above the reach of the dreaded hoppping demons. When enemies come at\nyou, kick them once or twice, and if they don't fall down hop over them just\nbefore they get to you. A little practice helps, but soon you will be able\nto drop down right on the other side of them and kick them in the back of\nthe head while they are turning around.\n\n                Kyonshies are very stupid.  It helps a lot to remember this,\n\nas the next trick shows. See, Kyonshies (as you will know if you read the\nabove section on them) are in the throes of rigor mortis, their bodies in an\narrested state of decay. So they can only see straight forward, right? So\nif you crouch down, they will turn back and forth, their tiny minds trying\nto figure out how you pulled your disappearing act. This will not be very\nuseful in the beginning, as you can't walk while crouching. DON'T try this\njust before a Kyonshie gets to you -- their turning back and forth motion\nwill still be able to hit you, as you are not completely under their arm\nlevel (unless you are fighting a really tall kyonshie, see below). This\nmove becomes more useful when you learn the Mirage Walk, as you'll be able\nto shuffle about under their vision, just don't attempt to get too close to\nthem as they can often still hit you. Later, when you learn Mirage Thrust,\nthis becomes a winning tactic, allowing you to stand under tall enemies and\nbosses and punch them in their unfeeling vampire gonads mercilessly.\n(WARNING: This is kind of a cheapo move, as you really can kill tall kyonshi\nbosses with this tactic. It certainly doesn't _look_ very exciting.)\n\nXII. Alright. I'm in town. What do I do first?\n\n        Wander through town until you find the temple, then try to fight\n\nyour way through it, shouldn't be to difficult. In the first town, it's one\nof the first buildings, later on it will be farther into town, or sometimes\nnonexistent. Anyhow, it's important to start here, so that you can fill up\nyour health, you'll need to often and there's only one other way to do it in\nthe game, and that involves more fighting.\n\n        Once you've done that, go to the kung-fu studio and see how many\n\nscrolls you'll need to learn the various kung-fu moves. The dialog trees\ncan be annoying, but get used to them because they are all through the\ngame. :P Anyhow, leave the studio with the moves you want to learn in mind,\nand find a house with Kyonshies in it. Then enter and work your way to get\nthe scrolls. Surprisingly (or perhaps not, depending on how well versed you\nare in \"game logic\"), you can enter the same house again and again,\ncontinuously obtaining scrolls. You can get up to 99, but don't bother\ntrying that here unless you are sick in bed with chicken pox or something --\nyou'll have better oppportunities later on when you recieve lots more\nscrolls for rescuing townspeople. Learn all the moves you can, when the\nmaster tells you you've tapped him out, you can move on.\n\n    A. Just to make it easier on myself, what moves should I learn first?\n\nSince your kung-fu is puny, learn attack moves first. Specifically, get 2\nKick and 2 Thrust. Throughout the game, when you have an opportunity to\nlearn an attack move, learn it, and learn the other moves later. While the\n\"Move\" moves may seem pointless, they are actually very useful, since being\nable to move quickly will allow you to dance in an out of a kyonshie's range\nwithout getting creamed every time you try to hit them. It's also highly\nimportant to learn the jump moves, since they allow you to attack airborne\nenemies, of which there are 3 in the game, all of them important. While I\nsuppose you could beat the game without all of the moves, I wouldn't\nrecommend it, simply because it wouldn't be as fun, as learning new moves is\none of the high points of the game.\n\n        After you've learned all the moves you care to, head for the houses\n\nwith the gems in them, collect the gems, and head for the boss shack. Don't\nforget to write down your password!\n\nXIII. Hey, these Kyonshies aren't all alike!\n\n        Quite right.  There are several different types of Kyonshies.\n\nBasically, there are four basic types of Kyonshi, differentiated by body\ntype: the little one, the medium one, the tall one, and the big fat one.\nWithin these different morphical categories there's lots of room for\nvariation in the different colors they wear. You'll no doubt become quite\nfamiliar with the types as you play the game, and certain ones will become\ninfamous. (\"ARgh! Not more green ones!\")\n\nXIV. Okay, so there's different types. What are they like?\n\n    Without further ado:\n\nlittle: This little bastard is fast and hard to hit. He'll be a toughie\nwhen you're duking it out in the first town and don't have awesome kung-fu.\nHis basic weakness is that he can't jump that far, and he's really short,\nmaking him easy to hop over. Fortunately he's still just tall enough to\nkick in the face.\n\nmedium: Your basic vanilla Kyonshi. Some types jump a lot, some are fast,\netc.\n\ntall: The tall guy moves ponderously slow, and thanks to his height is hard\nto jump over. He also jumps very high while attacking as well. Naturally\nenough this is a big mistake on his part; he jumps so high that you can\ncrouch and let him go over you, then \"boot to the head\" while he's turning\naround. Later on when you learn the Mirage Thrust the tall guy will be at\nyour mercy as your firsts pound mercilessly into his undead loins, and his\nturning back and forth schtick won't be able to nail you.\n\nfat: This guy is tougher than he looks. He's very strong, such that even\nthough he moves slowly, he packs a real wallop. Also, he doesn't jump that\nhigh, but is still tall enough that jumping over him is a bit of a sticky\nwicket. Your big advantage over him is speed. While he can soak up hits and\nreally wummox you when he gets a hit in, if you play it right you can kick\nonce or twice then get the hell out of the way when the Kyonshi express\ncomes through.\n\nXV. I won some kind of item, what does it do?\n\n        Aha, one of the coveted mystical items that you can use in the\n\ngame. Don't confuse these with scrolls -- ancient scrolls sound cool but\ndon't do jack except buy you kung-fu. However, the items are quite nice.\n\n        First, here's how to use an item once you've got it.  Whenever you\n\nobtain an item, you will see it appear at the top of the screen, in a long\nbox to the left of the stands that hold the three gems you'll need to get\nout of town. However, make no mistake, you are NOT carrying that item.\nYour faithful sidekick (who has no name that I could tell) is carrying\nthem. Thus, whenever you enter a building, and you want to use an item,\nturn back as if to leave. Your boy will pop his head in and ask if you want\nto split, use an item, or ignore him and get back to butt-kicking. Well,\nask for an item, and he'll give you a list: strangely enough, he lists all\nthe items you can get, even if you don't have them yet. Pick one, and it\nwill be outlined by a red square at the top of the screen. This means you\nare now carrying the item, and will use it instead of punching when you push\nA.\n\n    Now, here's all the items, and what they do.\n\n    Talisman: Freezes enemies in their tracks sometimes.\n    Tonten: Knocks baddies onto their cans with a flash of light.\n    Sword:  Knocks guys down, you can also slice 'em with it.\n    Bell:   Controls the demon-boy.\n\n        A note of warning: your items will also take hits for you if you get\n\nhit. However, this will also break the item, making it useless. Hey, it's\nan antique. Keep this in mind when fighting with an item. It's a good idea\nto grab them, they're nice for keeping enemies at bay, and the Tonten is\npretty damn invaluable for beating the game.\n\nXVI. I bought one of those Game Genies. Any codes for this game?\n\nCODE KEY IN . . . EFFECT . . .\n1 VTVKEGSA + KAVKOGNA Start with Sword\n2 VTVKEGSA + SAVKOGNA Start with Bell\n3 VTVKEGSA + UAVKOGNA Start with Tonten\n4 VTVKEGSA + XAVKOGNA Start with Talisman\n5 LASKNGAA + VAVKOGNA Start with 3 Scrolls\n6 TASKNGAA + VAVKOGNA Start with 6 Scrolls\n7 SXSZLUSE Infinite energy\n8 OVSZPLSV + PESZZLAA Take less damage when attacked\n\n(author's note: This is taken verbatim from Galoob's master list of all Game\nGenie codes for NES games that they ever published. There may, of course,\nbe some home- grown codes floating about. So all due credit goes to Galoob\nfor the above blurb.)\n\nXVII. This isn't the most complete FAQ I've ever read, you know...\n\n        Sorry.  This is mostly from memory.  If I get e-mails requesting\n\nupdates I'll saunter back into the game with my rightfully earned cheat\ncodes and research it fully for those who desire it. And besides, if you\nthink this FAQ is incomplete, check out some of the other (admittedly)\nsparse fare at TSR's NES FAQ page.\n\nFor right now I'll call an end to this FAQ, just because I figure this is\nenough to be written about any NES game that wasn't made by Square. :) I'll\nsend my regards first and foremost to TSR, who's NES page is truly one of\nthe best place for NES info on the 'net, not to mention skilled use of\ngraphics and delightful content like the NES oddity page. Also, here's to\nthe place that posted the ROM I used for this FAQ, Big Daddy's International\nHouse of ROMs, THE place to get ROMs on the 'net. In my experience, if he\ndoesn't have it here, it doesn't exist yet (at least for NES, anyhow). I'll\nalso send out greets to John Turk, who's NES Underground Library is probably\nthe most ambitious of all the NES pages I've seen. And finally I'll send\nshots out to all the other NES pages, all those who've stayed cool despite\nNESticle's appearance, and to all the fellows on IRC channels like\n#emuroms, #emulator, and #emu who are out there circulating coolness in less\nthan 200k. :) Also a shot out to my friends on #1980Warez, who have nothing\nto do with NES ROMs, but are cool anyway.\n\nJibes go to all those who feel the need to charge excessive amounts of money\nfor their emulators. Say what you will about effort and reward, guys, but\nin the end you're creating something used to do something that's, shall we\nsay, a trifle off-color in the eyes of the law. Jibes also go to those who\nrun IRC channels so huge that no chatting goes on in them, and channels that\nhave nothing but DCC bots in them. Thanks for helping turn IRC into a\nwasteland, guys.\n\nSo much have I written for gamers, now give me a drink!\n\nThe Deacon\nRestore Page\n\n</code></pre>"},{"location":"nes/#training-hall-quiz-questions-and-answers","title":"Training Hall Quiz Questions and Answers","text":"<pre><code>+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^+\n&lt;  //////  //  //    ///    ////  // //////   /////    //////////  &gt;\n&lt;  //  //  //  //   // //   // // //   //    //   //   //  //  //  &gt;\n&lt;  /////   //////  ///////  //  ////   //   //     //  //  //  //  &gt;\n&lt;  //      //  //  //   //  //   ///   //    //   //   //  //  //  &gt;\n&lt;  //      //  //  //   //  //    //   //     /////    //  //  //  &gt;\n&lt;                                                                  &gt;\n&lt;  //////  //   /////   //  // //////  //////  //////              &gt;\n&lt;  //      //  //       //  //   //    //      //  //              &gt;\n&lt;  ////    //  //  ///  //////   //    ////    ////                &gt;\n&lt;  //      //  //   //  //  //   //    //      // //               &gt;\n&lt;  //      //   /////   //  //   //    //////  //  //              &gt;\n+------------------------------------------------------------------+\n\n * * * * * * Training Hall Quiz Questions and Answers * * * * * *\n\nA guide by PinKirby (Pinku_Kirby@yahoo.com)\n\n+-----------------+\n----Version 1.0----\n+-----------------+\n\n June 9th, 2004\n   -Began this guide\n\n--------------------\n\nContents:\n1. Introduction\n2. The Training Hall\n3. The Questions and Answers\n4. Possible Messages\n5. Thanks\n6. Legal Info\n\n---------------------\n\n * * * * * * 1. Introduction * * * * * *\n\nPhantom Fighter is a game that is not very well-known, but is still,\nin my opinion, a great game. I've decided to make a guide on the\nquestions the guard of the Training Hall asks you. Most questions\nhave one correct answer, but some questions are asked in which ALL\nof the multiple choices are correct answers.\n\nHere's how to use this guide, using a sample question NOT asked\nin the game:\n\n***QUESTION: What game does this guide cover?\n    1. Super Mario Brothers (X)\n    2. Phantom Fighter      (O)\n    3. This game has no name(X)\n\n(X) - Means an incorrect answer, in which the guard throws you out.\n(O) - Means a correct answer, in which the guard lets you pass.\n\n---------------------------------------------------------------\n\n * * * * * * 2. The Training Hall * * * * * *\n\nAfter defeating the monsters, the sharp-nailed Chinese phantoms\nwhich are known as \"Kyonshies\", in houses and buildings, you can get\none or more scrolls. You use these scrolls to learn skills in the\nTraining Hall, but you can't see the master for free, as his guard\nexplains to you. To prove you are worthy of the master's time and\nattention, you must correctly answer a question with one of three\nmultiple choices. While many of the guard's questions pertain to\nyour foes the Kyonshies, some of the questions involve trivia.\nIf you get a question wrong, DON'T FRET! You can re-enter and try\nagain with another question.\n\nThe guard tells you, Kenchi: \"You can't see the master for free.\nDo you understand?\"\nIf you answer no, he'll laugh at your cowardice and kick you out.\nAnswer yes, and it's quiz time!\n\n---------------------------------------------------------------\n\n * * * * * * 3. The Questions and Answers * * * * * *\n\nQUESTION 1:\nHow many stars are there in the American flag?\n\n   1. 50 (O)\n   2. 28 (X)\n   3. 5  (X)\n\n---------------------\n\nQUESTION 2:\nWhat country do samurais come from?\n\n   1. India (X)\n   2. Japan (O)\n   3. Spain (X)\n\n---------------------\n\nQUESTION 3:\nWhat is the best method to make sure Kyonshies never revive again?\n\n   1. Big Stakes   (X)\n   2. Seal in Rock (X)\n   3. Fry in Oil   (O)\n\n---------------------\n\nQUESTION 4:\nWhat is the teaching taught by Confucius called?\n\n   1. Psychiatry   (X)\n   2. Confucianism (O)\n   3. Physiognomy  (X)\n\n---------------------\n\nQUESTION 5:\nWho built the Great Wall of China?\n\n   1. The Emperor (O)\n   2. Plasterer   (O)\n   3. Farmer      (O)\n\n---------------------\n\nQUESTION 6:\nWhat is Kyonshies' most powerful weapon?\n\n   1. Sharp Claws (O)\n   2. Sharp Eyes  (X)\n   3. Swift Moves (X)\n\n---------------------\n\nQUESTION 7:\nWhat is the horrible skill called when your head is banged against\nyour opponent's head?\n\n   1. Head Strike  (O)\n   2. Head batting (O)\n   3. Head to Head (O)\n\n---------------------\n\nQUESTION 8:\nWhat's the name of George Bush's dog? (This is George Bush Sr.!)\n\n   1. Millie (O)\n   2. Martha (X)\n   3. Pooch  (X)\n\n---------------------\n\nQUESTION 9:\nWho created Ultima?\n\n   1. Lord British (O)\n   2. Prince Chuck (X)\n   3. Mr. Exodus   (X)\n\n---------------------\n\nQUESTION 10:\nWhat is the best thing to use to capture Kyonshies?\n\n   1. Coffin      (X)\n   2. Urn         (O)\n   3. Jewelry Box (X)\n\n---------------------\n\nQUESTION 11:\nWhat is the famous Chinese Newspaper?\n\n   1. School Paper (X)\n   2. Wall Poster  (O)\n   3. Daily China  (X)\n\n---------------------\n\nQUESTION 11:\nWhat is the food Kyonshies hate?\n\n   1. Liver     (X)\n   2. Ice Cream (O)\n   3. Frog Eyes (X)\n\n---------------------\n\nQUESTION 12:\nSomething is used to beat Kyonshies. What is it?\n\n   1. Bird's Blood (O)\n   2. Lizard Scale (X)\n   3. Vulture Nail (X)\n\n---------------------\n\nQUESTION 13:\nWhy do Kyonshies only come out at night?\n\n   1. Play late    (X)\n   2. Shy          (X)\n   3. Hate the Sun (O)\n\n---------------------\n\nQUESTION 14:\nWhich emperor is often called the Last Emperor?\n\n   1. Sagi (X)\n   2. Higi (X)\n   3. Fugi (O)\n\n---------------------\n\nQUESTION 15:\nWhat kind of place do Kyoshies usually live in?\n\n   1. Wet place    (O)\n   2. New Jersey   (O)\n   3. Beverly Hill (O)\n\n---------------------\n\nQUESTION 16:\nWhat is the skill called when you hold your opponent's arms from the\nback and throw him backward?\n\n   1. Dragon Suplex (O)\n   2. Front Suplex  (X)\n   3. Side Suplex   (X)\n\n---------------------\n\nQUESTION 17:\nName an FCI Video Game.\n\n   1. Hydlide (O)\n   2. WCW     (O)\n   3. Ultima  (O)\n\n---------------------\n\nQUESTION 18:\nWhat is a Chinese martial art usually called?\n\n   1. Kung Fu      (O)\n   2. Martial Art  (X)\n   3. Phantom Kick (X)\n\n---------------------\n\nQUESTION 19:\nWhat is another word for one?\n\n   1. Uno  (O)\n   2. Ichi (O)\n   3. Un   (O)\n\n---------------------\n\n---------------------------------------------------------------\n\n * * * * * * 4. Possible Messages * * * * * *\n\n ----- CORRECT MESSAGES:\n\n - That's good. The master is waiting for you. Go and see him.\n\nIf you answer \"New Jersey\" or \"Beverly Hill\" to the question\nabout where Kyonshies usually live in:\n - That's right. Now as you know, that is the hangout of Kyonshi.\n   Go and enter.\n\n(I'm assuming the guard pities you so much that he just accepts it\nas a correct answer. :P )\n\n ----- INCORRECT MESSAGES:\n\n - Why are you trying to pretend you don't know the answer?\n\n - You, Kenchi, not know a thing like this? Worth a laugh! Ha ha ha!\n   Now, get out! Get out!\n\n - That was a pity. Train yourself and come again.\n\n - How little you know I'm stunned. Think it over and come back again.\n\n - Kenchi, you are really an idiot! Go home, try to learn more, and\n   come back when you are wiser.\n\nIf you answer \"5\" as to how many stars are on the US flag:\n - Dunce!\n\n---------------------------------------------------------------\n\n * * * * * * 5. Thanks * * * * * *\n\n - To my sister, Mom and Grandpa\n - To FCI and Pony Canyon for making this game\n - To YOU for taking the time to read this guide!\n\n * * * * * * 6. Legal Stuff * * * * * *\n\nThis guide is copyrighted (c) by PinKirby. You may copy SOME of this\nguide, but you MUST give me, PinKirby, credit. If you want to put\nthis guide up on your website, email me and I will see about it. If I\nfind that this guide is on a website NOT listed below, then I will have\nit removed.\n\nSITES THAT MAY HAVE THIS GUIDE UP:\n\nwww.GameFaqs.com\n\nPhatom Fighter is (c) 1989 by FCI and Pony Canyon.\nThe Nintendo Entertainment System and Nintendo of America\nare registered trademarks of Nintendo. All rights reserved.\n\nThis Phantom Fighter Training Hall Quiz Guide is (c) by PinKirby\nRestore Page\n</code></pre>"},{"location":"ollama/","title":"API","text":""},{"location":"ollama/#endpoints","title":"Endpoints","text":"<ul> <li>Generate a completion</li> <li>Generate a chat completion</li> <li>Create a Model</li> <li>List Local Models</li> <li>Show Model Information</li> <li>Copy a Model</li> <li>Delete a Model</li> <li>Pull a Model</li> <li>Push a Model</li> <li>Generate Embeddings</li> </ul>"},{"location":"ollama/#conventions","title":"Conventions","text":""},{"location":"ollama/#model-names","title":"Model names","text":"<p>Model names follow a <code>model:tag</code> format, where <code>model</code> can have an optional namespace such as <code>example/model</code>. Some examples are <code>orca-mini:3b-q4_1</code> and <code>llama2:70b</code>. The tag is optional and, if not provided, will default to <code>latest</code>. The tag is used to identify a specific version.</p>"},{"location":"ollama/#durations","title":"Durations","text":"<p>All durations are returned in nanoseconds.</p>"},{"location":"ollama/#streaming-responses","title":"Streaming responses","text":"<p>Certain endpoints stream responses as JSON objects and can optional return non-streamed responses.</p>"},{"location":"ollama/#generate-a-completion","title":"Generate a completion","text":"<pre><code>POST /api/generate\n</code></pre> <p>Generate a response for a given prompt with a provided model. This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.</p>"},{"location":"ollama/#parameters","title":"Parameters","text":"<ul> <li><code>model</code>: (required) the model name</li> <li><code>prompt</code>: the prompt to generate a response for</li> <li><code>images</code>: (optional) a list of base64-encoded images (for multimodal models such as <code>llava</code>)</li> </ul> <p>Advanced parameters (optional):</p> <ul> <li><code>format</code>: the format to return a response in. Currently the only accepted value is <code>json</code></li> <li><code>options</code>: additional model parameters listed in the documentation for the Modelfile such as <code>temperature</code></li> <li><code>system</code>: system message to (overrides what is defined in the <code>Modelfile</code>)</li> <li><code>template</code>: the prompt template to use (overrides what is defined in the <code>Modelfile</code>)</li> <li><code>context</code>: the context parameter returned from a previous request to <code>/generate</code>, this can be used to keep a short conversational memory</li> <li><code>stream</code>: if <code>false</code> the response will be returned as a single response object, rather than a stream of objects</li> <li><code>raw</code>: if <code>true</code> no formatting will be applied to the prompt. You may choose to use the <code>raw</code> parameter if you are specifying a full templated prompt in your request to the API</li> <li><code>keep_alive</code>: controls how long the model will stay loaded into memory following the request (default: <code>5m</code>)</li> </ul>"},{"location":"ollama/#json-mode","title":"JSON mode","text":"<p>Enable JSON mode by setting the <code>format</code> parameter to <code>json</code>. This will structure the response as a valid JSON object. See the JSON mode example below.</p> <p>Note: it's important to instruct the model to use JSON in the <code>prompt</code>. Otherwise, the model may generate large amounts whitespace.</p>"},{"location":"ollama/#examples","title":"Examples","text":""},{"location":"ollama/#generate-request-streaming","title":"Generate request (Streaming)","text":""},{"location":"ollama/#request","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\",\n  \"prompt\": \"Why is the sky blue?\"\n}'\n</code></pre>"},{"location":"ollama/#response","title":"Response","text":"<p>A stream of JSON objects is returned:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T08:52:19.385406455-07:00\",\n  \"response\": \"The\",\n  \"done\": false\n}\n</code></pre> <p>The final response in the stream also includes additional data about the generation:</p> <ul> <li><code>total_duration</code>: time spent generating the response</li> <li><code>load_duration</code>: time spent in nanoseconds loading the model</li> <li><code>prompt_eval_count</code>: number of tokens in the prompt</li> <li><code>prompt_eval_duration</code>: time spent in nanoseconds evaluating the prompt</li> <li><code>eval_count</code>: number of tokens the response</li> <li><code>eval_duration</code>: time in nanoseconds spent generating the response</li> <li><code>context</code>: an encoding of the conversation used in this response, this can be sent in the next request to keep a conversational memory</li> <li><code>response</code>: empty if the response was streamed, if not streamed, this will contain the full response</li> </ul> <p>To calculate how fast the response is generated in tokens per second (token/s), divide <code>eval_count</code> / <code>eval_duration</code>.</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T19:22:45.499127Z\",\n  \"response\": \"\",\n  \"done\": true,\n  \"context\": [1, 2, 3],\n  \"total_duration\": 10706818083,\n  \"load_duration\": 6338219291,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 130079000,\n  \"eval_count\": 259,\n  \"eval_duration\": 4232710000\n}\n</code></pre>"},{"location":"ollama/#request-no-streaming","title":"Request (No streaming)","text":""},{"location":"ollama/#request_1","title":"Request","text":"<p>A response can be received in one reply when streaming is off.</p> <pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"stream\": false\n}'\n</code></pre>"},{"location":"ollama/#response_1","title":"Response","text":"<p>If <code>stream</code> is set to <code>false</code>, the response will be a single JSON object:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T19:22:45.499127Z\",\n  \"response\": \"The sky is blue because it is the color of the sky.\",\n  \"done\": true,\n  \"context\": [1, 2, 3],\n  \"total_duration\": 5043500667,\n  \"load_duration\": 5025959,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 325953000,\n  \"eval_count\": 290,\n  \"eval_duration\": 4709213000\n}\n</code></pre>"},{"location":"ollama/#request-json-mode","title":"Request (JSON mode)","text":"<p>When <code>format</code> is set to <code>json</code>, the output will always be a well-formed JSON object. It's important to also instruct the model to respond in JSON.</p>"},{"location":"ollama/#request_2","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\",\n  \"prompt\": \"What color is the sky at different times of the day? Respond using JSON\",\n  \"format\": \"json\",\n  \"stream\": false\n}'\n</code></pre>"},{"location":"ollama/#response_2","title":"Response","text":"<pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-11-09T21:07:55.186497Z\",\n  \"response\": \"{\\n\\\"morning\\\": {\\n\\\"color\\\": \\\"blue\\\"\\n},\\n\\\"noon\\\": {\\n\\\"color\\\": \\\"blue-gray\\\"\\n},\\n\\\"afternoon\\\": {\\n\\\"color\\\": \\\"warm gray\\\"\\n},\\n\\\"evening\\\": {\\n\\\"color\\\": \\\"orange\\\"\\n}\\n}\\n\",\n  \"done\": true,\n  \"context\": [1, 2, 3],\n  \"total_duration\": 4648158584,\n  \"load_duration\": 4071084,\n  \"prompt_eval_count\": 36,\n  \"prompt_eval_duration\": 439038000,\n  \"eval_count\": 180,\n  \"eval_duration\": 4196918000\n}\n</code></pre> <p>The value of <code>response</code> will be a string containing JSON similar to:</p> <pre><code>{\n  \"morning\": {\n    \"color\": \"blue\"\n  },\n  \"noon\": {\n    \"color\": \"blue-gray\"\n  },\n  \"afternoon\": {\n    \"color\": \"warm gray\"\n  },\n  \"evening\": {\n    \"color\": \"orange\"\n  }\n}\n</code></pre>"},{"location":"ollama/#request-with-images","title":"Request (with images)","text":"<p>To submit images to multimodal models such as <code>llava</code> or <code>bakllava</code>, provide a list of base64-encoded <code>images</code>:</p>"},{"location":"ollama/#request_3","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llava\",\n  \"prompt\":\"What is in this picture?\",\n  \"stream\": false,\n  \"images\": [\"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\"]\n}'\n</code></pre>"},{"location":"ollama/#response_3","title":"Response","text":"<pre><code>{\n  \"model\": \"llava\",\n  \"created_at\": \"2023-11-03T15:36:02.583064Z\",\n  \"response\": \"A happy cartoon character, which is cute and cheerful.\",\n  \"done\": true,\n  \"context\": [1, 2, 3],\n  \"total_duration\": 2938432250,\n  \"load_duration\": 2559292,\n  \"prompt_eval_count\": 1,\n  \"prompt_eval_duration\": 2195557000,\n  \"eval_count\": 44,\n  \"eval_duration\": 736432000\n}\n</code></pre>"},{"location":"ollama/#request-raw-mode","title":"Request (Raw Mode)","text":"<p>In some cases, you may wish to bypass the templating system and provide a full prompt. In this case, you can use the <code>raw</code> parameter to disable templating. Also note that raw mode will not return a context.</p>"},{"location":"ollama/#request_4","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"mistral\",\n  \"prompt\": \"[INST] why is the sky blue? [/INST]\",\n  \"raw\": true,\n  \"stream\": false\n}'\n</code></pre>"},{"location":"ollama/#request-reproducible-outputs","title":"Request (Reproducible outputs)","text":"<p>For reproducible outputs, set <code>temperature</code> to 0 and <code>seed</code> to a number:</p>"},{"location":"ollama/#request_5","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"mistral\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"options\": {\n    \"seed\": 123,\n    \"temperature\": 0\n  }\n}'\n</code></pre>"},{"location":"ollama/#response_4","title":"Response","text":"<pre><code>{\n  \"model\": \"mistral\",\n  \"created_at\": \"2023-11-03T15:36:02.583064Z\",\n  \"response\": \" The sky appears blue because of a phenomenon called Rayleigh scattering.\",\n  \"done\": true,\n  \"total_duration\": 8493852375,\n  \"load_duration\": 6589624375,\n  \"prompt_eval_count\": 14,\n  \"prompt_eval_duration\": 119039000,\n  \"eval_count\": 110,\n  \"eval_duration\": 1779061000\n}\n</code></pre>"},{"location":"ollama/#generate-request-with-options","title":"Generate request (With options)","text":"<p>If you want to set custom options for the model at runtime rather than in the Modelfile, you can do so with the <code>options</code> parameter. This example sets every available option, but you can set any of them individually and omit the ones you do not want to override.</p>"},{"location":"ollama/#request_6","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"stream\": false,\n  \"options\": {\n    \"num_keep\": 5,\n    \"seed\": 42,\n    \"num_predict\": 100,\n    \"top_k\": 20,\n    \"top_p\": 0.9,\n    \"tfs_z\": 0.5,\n    \"typical_p\": 0.7,\n    \"repeat_last_n\": 33,\n    \"temperature\": 0.8,\n    \"repeat_penalty\": 1.2,\n    \"presence_penalty\": 1.5,\n    \"frequency_penalty\": 1.0,\n    \"mirostat\": 1,\n    \"mirostat_tau\": 0.8,\n    \"mirostat_eta\": 0.6,\n    \"penalize_newline\": true,\n    \"stop\": [\"\\n\", \"user:\"],\n    \"numa\": false,\n    \"num_ctx\": 1024,\n    \"num_batch\": 2,\n    \"num_gqa\": 1,\n    \"num_gpu\": 1,\n    \"main_gpu\": 0,\n    \"low_vram\": false,\n    \"f16_kv\": true,\n    \"vocab_only\": false,\n    \"use_mmap\": true,\n    \"use_mlock\": false,\n    \"rope_frequency_base\": 1.1,\n    \"rope_frequency_scale\": 0.8,\n    \"num_thread\": 8\n  }\n}'\n</code></pre>"},{"location":"ollama/#response_5","title":"Response","text":"<pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T19:22:45.499127Z\",\n  \"response\": \"The sky is blue because it is the color of the sky.\",\n  \"done\": true,\n  \"context\": [1, 2, 3],\n  \"total_duration\": 4935886791,\n  \"load_duration\": 534986708,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 107345000,\n  \"eval_count\": 237,\n  \"eval_duration\": 4289432000\n}\n</code></pre>"},{"location":"ollama/#load-a-model","title":"Load a model","text":"<p>If an empty prompt is provided, the model will be loaded into memory.</p>"},{"location":"ollama/#request_7","title":"Request","text":"<pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\"\n}'\n</code></pre>"},{"location":"ollama/#response_6","title":"Response","text":"<p>A single JSON object is returned:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-12-18T19:52:07.071755Z\",\n  \"response\": \"\",\n  \"done\": true\n}\n</code></pre>"},{"location":"ollama/#generate-a-chat-completion","title":"Generate a chat completion","text":"<pre><code>POST /api/chat\n</code></pre> <p>Generate the next message in a chat with a provided model. This is a streaming endpoint, so there will be a series of responses. Streaming can be disabled using <code>\"stream\": false</code>. The final response object will include statistics and additional data from the request.</p>"},{"location":"ollama/#parameters_1","title":"Parameters","text":"<ul> <li><code>model</code>: (required) the model name</li> <li><code>messages</code>: the messages of the chat, this can be used to keep a chat memory</li> </ul> <p>The <code>message</code> object has the following fields:</p> <ul> <li><code>role</code>: the role of the message, either <code>system</code>, <code>user</code> or <code>assistant</code></li> <li><code>content</code>: the content of the message</li> <li><code>images</code> (optional): a list of images to include in the message (for multimodal models such as <code>llava</code>)</li> </ul> <p>Advanced parameters (optional):</p> <ul> <li><code>format</code>: the format to return a response in. Currently the only accepted value is <code>json</code></li> <li><code>options</code>: additional model parameters listed in the documentation for the Modelfile such as <code>temperature</code></li> <li><code>template</code>: the prompt template to use (overrides what is defined in the <code>Modelfile</code>)</li> <li><code>stream</code>: if <code>false</code> the response will be returned as a single response object, rather than a stream of objects</li> <li><code>keep_alive</code>: controls how long the model will stay loaded into memory following the request (default: <code>5m</code>)</li> </ul>"},{"location":"ollama/#examples_1","title":"Examples","text":""},{"location":"ollama/#chat-request-streaming","title":"Chat Request (Streaming)","text":""},{"location":"ollama/#request_8","title":"Request","text":"<p>Send a chat message with a streaming response.</p> <pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama2\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"why is the sky blue?\"\n    }\n  ]\n}'\n</code></pre>"},{"location":"ollama/#response_7","title":"Response","text":"<p>A stream of JSON objects is returned:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T08:52:19.385406455-07:00\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \"The\",\n    \"images\": null\n  },\n  \"done\": false\n}\n</code></pre> <p>Final response:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T19:22:45.499127Z\",\n  \"done\": true,\n  \"total_duration\": 4883583458,\n  \"load_duration\": 1334875,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 342546000,\n  \"eval_count\": 282,\n  \"eval_duration\": 4535599000\n}\n</code></pre>"},{"location":"ollama/#chat-request-no-streaming","title":"Chat request (No streaming)","text":""},{"location":"ollama/#request_9","title":"Request","text":"<pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama2\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"why is the sky blue?\"\n    }\n  ],\n  \"stream\": false\n}'\n</code></pre>"},{"location":"ollama/#response_8","title":"Response","text":"<pre><code>{\n  \"model\": \"registry.ollama.ai/library/llama2:latest\",\n  \"created_at\": \"2023-12-12T14:13:43.416799Z\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \"Hello! How are you today?\"\n  },\n  \"done\": true,\n  \"total_duration\": 5191566416,\n  \"load_duration\": 2154458,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 383809000,\n  \"eval_count\": 298,\n  \"eval_duration\": 4799921000\n}\n</code></pre>"},{"location":"ollama/#chat-request-with-history","title":"Chat request (With History)","text":"<p>Send a chat message with a conversation history. You can use this same approach to start the conversation using multi-shot or chain-of-thought prompting.</p>"},{"location":"ollama/#request_10","title":"Request","text":"<pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama2\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"why is the sky blue?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"due to rayleigh scattering.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how is that different than mie scattering?\"\n    }\n  ]\n}'\n</code></pre>"},{"location":"ollama/#response_9","title":"Response","text":"<p>A stream of JSON objects is returned:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T08:52:19.385406455-07:00\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \"The\"\n  },\n  \"done\": false\n}\n</code></pre> <p>Final response:</p> <pre><code>{\n  \"model\": \"llama2\",\n  \"created_at\": \"2023-08-04T19:22:45.499127Z\",\n  \"done\": true,\n  \"total_duration\": 8113331500,\n  \"load_duration\": 6396458,\n  \"prompt_eval_count\": 61,\n  \"prompt_eval_duration\": 398801000,\n  \"eval_count\": 468,\n  \"eval_duration\": 7701267000\n}\n</code></pre>"},{"location":"ollama/#chat-request-with-images","title":"Chat request (with images)","text":""},{"location":"ollama/#request_11","title":"Request","text":"<p>Send a chat message with a conversation history.</p> <pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llava\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"what is in this image?\",\n      \"images\": [\"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\"]\n    }\n  ]\n}'\n</code></pre>"},{"location":"ollama/#response_10","title":"Response","text":"<pre><code>{\n  \"model\": \"llava\",\n  \"created_at\": \"2023-12-13T22:42:50.203334Z\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \" The image features a cute, little pig with an angry facial expression. It's wearing a heart on its shirt and is waving in the air. This scene appears to be part of a drawing or sketching project.\",\n    \"images\": null\n  },\n  \"done\": true,\n  \"total_duration\": 1668506709,\n  \"load_duration\": 1986209,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 359682000,\n  \"eval_count\": 83,\n  \"eval_duration\": 1303285000\n}\n</code></pre>"},{"location":"ollama/#chat-request-reproducible-outputs","title":"Chat request (Reproducible outputs)","text":""},{"location":"ollama/#request_12","title":"Request","text":"<pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama2\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello!\"\n    }\n  ],\n  \"options\": {\n    \"seed\": 101,\n    \"temperature\": 0\n  }\n}'\n</code></pre>"},{"location":"ollama/#response_11","title":"Response","text":"<pre><code>{\n  \"model\": \"registry.ollama.ai/library/llama2:latest\",\n  \"created_at\": \"2023-12-12T14:13:43.416799Z\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \"Hello! How are you today?\"\n  },\n  \"done\": true,\n  \"total_duration\": 5191566416,\n  \"load_duration\": 2154458,\n  \"prompt_eval_count\": 26,\n  \"prompt_eval_duration\": 383809000,\n  \"eval_count\": 298,\n  \"eval_duration\": 4799921000\n}\n</code></pre>"},{"location":"ollama/#create-a-model","title":"Create a Model","text":"<pre><code>POST /api/create\n</code></pre> <p>Create a model from a <code>Modelfile</code>. It is recommended to set <code>modelfile</code> to the content of the Modelfile rather than just set <code>path</code>. This is a requirement for remote create. Remote model creation must also create any file blobs, fields such as <code>FROM</code> and <code>ADAPTER</code>, explicitly with the server using Create a Blob and the value to the path indicated in the response.</p>"},{"location":"ollama/#parameters_2","title":"Parameters","text":"<ul> <li><code>name</code>: name of the model to create</li> <li><code>modelfile</code> (optional): contents of the Modelfile</li> <li><code>stream</code>: (optional) if <code>false</code> the response will be returned as a single response object, rather than a stream of objects</li> <li><code>path</code> (optional): path to the Modelfile</li> </ul>"},{"location":"ollama/#examples_2","title":"Examples","text":""},{"location":"ollama/#create-a-new-model","title":"Create a new model","text":"<p>Create a new model from a <code>Modelfile</code>.</p>"},{"location":"ollama/#request_13","title":"Request","text":"<pre><code>curl http://localhost:11434/api/create -d '{\n  \"name\": \"mario\",\n  \"modelfile\": \"FROM llama2\\nSYSTEM You are mario from Super Mario Bros.\"\n}'\n</code></pre>"},{"location":"ollama/#response_12","title":"Response","text":"<p>A stream of JSON objects. Notice that the final JSON object shows a <code>\"status\": \"success\"</code>.</p> <pre><code>{\"status\":\"reading model metadata\"}\n{\"status\":\"creating system layer\"}\n{\"status\":\"using already created layer sha256:22f7f8ef5f4c791c1b03d7eb414399294764d7cc82c7e94aa81a1feb80a983a2\"}\n{\"status\":\"using already created layer sha256:8c17c2ebb0ea011be9981cc3922db8ca8fa61e828c5d3f44cb6ae342bf80460b\"}\n{\"status\":\"using already created layer sha256:7c23fb36d80141c4ab8cdbb61ee4790102ebd2bf7aeff414453177d4f2110e5d\"}\n{\"status\":\"using already created layer sha256:2e0493f67d0c8c9c68a8aeacdf6a38a2151cb3c4c1d42accf296e19810527988\"}\n{\"status\":\"using already created layer sha256:2759286baa875dc22de5394b4a925701b1896a7e3f8e53275c36f75a877a82c9\"}\n{\"status\":\"writing layer sha256:df30045fe90f0d750db82a058109cecd6d4de9c90a3d75b19c09e5f64580bb42\"}\n{\"status\":\"writing layer sha256:f18a68eb09bf925bb1b669490407c1b1251c5db98dc4d3d81f3088498ea55690\"}\n{\"status\":\"writing manifest\"}\n{\"status\":\"success\"}\n</code></pre>"},{"location":"ollama/#check-if-a-blob-exists","title":"Check if a Blob Exists","text":"<pre><code>HEAD /api/blobs/:digest\n</code></pre> <p>Ensures that the file blob used for a FROM or ADAPTER field exists on the server. This is checking your Ollama server and not Ollama.ai.</p>"},{"location":"ollama/#query-parameters","title":"Query Parameters","text":"<ul> <li><code>digest</code>: the SHA256 digest of the blob</li> </ul>"},{"location":"ollama/#examples_3","title":"Examples","text":""},{"location":"ollama/#request_14","title":"Request","text":"<pre><code>curl -I http://localhost:11434/api/blobs/sha256:29fdb92e57cf0827ded04ae6461b5931d01fa595843f55d36f5b275a52087dd2\n</code></pre>"},{"location":"ollama/#response_13","title":"Response","text":"<p>Return 200 OK if the blob exists, 404 Not Found if it does not.</p>"},{"location":"ollama/#create-a-blob","title":"Create a Blob","text":"<pre><code>POST /api/blobs/:digest\n</code></pre> <p>Create a blob from a file on the server. Returns the server file path.</p>"},{"location":"ollama/#query-parameters_1","title":"Query Parameters","text":"<ul> <li><code>digest</code>: the expected SHA256 digest of the file</li> </ul>"},{"location":"ollama/#examples_4","title":"Examples","text":""},{"location":"ollama/#request_15","title":"Request","text":"<pre><code>curl -T model.bin -X POST http://localhost:11434/api/blobs/sha256:29fdb92e57cf0827ded04ae6461b5931d01fa595843f55d36f5b275a52087dd2\n</code></pre>"},{"location":"ollama/#response_14","title":"Response","text":"<p>Return 201 Created if the blob was successfully created, 400 Bad Request if the digest used is not expected.</p>"},{"location":"ollama/#list-local-models","title":"List Local Models","text":"<pre><code>GET /api/tags\n</code></pre> <p>List models that are available locally.</p>"},{"location":"ollama/#examples_5","title":"Examples","text":""},{"location":"ollama/#request_16","title":"Request","text":"<pre><code>curl http://localhost:11434/api/tags\n</code></pre>"},{"location":"ollama/#response_15","title":"Response","text":"<p>A single JSON object will be returned.</p> <pre><code>{\n  \"models\": [\n    {\n      \"name\": \"codellama:13b\",\n      \"modified_at\": \"2023-11-04T14:56:49.277302595-07:00\",\n      \"size\": 7365960935,\n      \"digest\": \"9f438cb9cd581fc025612d27f7c1a6669ff83a8bb0ed86c94fcf4c5440555697\",\n      \"details\": {\n        \"format\": \"gguf\",\n        \"family\": \"llama\",\n        \"families\": null,\n        \"parameter_size\": \"13B\",\n        \"quantization_level\": \"Q4_0\"\n      }\n    },\n    {\n      \"name\": \"llama2:latest\",\n      \"modified_at\": \"2023-12-07T09:32:18.757212583-08:00\",\n      \"size\": 3825819519,\n      \"digest\": \"fe938a131f40e6f6d40083c9f0f430a515233eb2edaa6d72eb85c50d64f2300e\",\n      \"details\": {\n        \"format\": \"gguf\",\n        \"family\": \"llama\",\n        \"families\": null,\n        \"parameter_size\": \"7B\",\n        \"quantization_level\": \"Q4_0\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"ollama/#show-model-information","title":"Show Model Information","text":"<pre><code>POST /api/show\n</code></pre> <p>Show information about a model including details, modelfile, template, parameters, license, and system prompt.</p>"},{"location":"ollama/#parameters_3","title":"Parameters","text":"<ul> <li><code>name</code>: name of the model to show</li> </ul>"},{"location":"ollama/#examples_6","title":"Examples","text":""},{"location":"ollama/#request_17","title":"Request","text":"<pre><code>curl http://localhost:11434/api/show -d '{\n  \"name\": \"llama2\"\n}'\n</code></pre>"},{"location":"ollama/#response_16","title":"Response","text":"<pre><code>{\n  \"modelfile\": \"# Modelfile generated by \\\"ollama show\\\"\\n# To build a new Modelfile based on this one, replace the FROM line with:\\n# FROM llava:latest\\n\\nFROM /Users/matt/.ollama/models/blobs/sha256:200765e1283640ffbd013184bf496e261032fa75b99498a9613be4e94d63ad52\\nTEMPLATE \\\"\\\"\\\"{{ .System }}\\nUSER: {{ .Prompt }}\\nASSSISTANT: \\\"\\\"\\\"\\nPARAMETER num_ctx 4096\\nPARAMETER stop \\\"\\u003c/s\\u003e\\\"\\nPARAMETER stop \\\"USER:\\\"\\nPARAMETER stop \\\"ASSSISTANT:\\\"\",\n  \"parameters\": \"num_ctx                        4096\\nstop                           \\u003c/s\\u003e\\nstop                           USER:\\nstop                           ASSSISTANT:\",\n  \"template\": \"{{ .System }}\\nUSER: {{ .Prompt }}\\nASSSISTANT: \",\n  \"details\": {\n    \"format\": \"gguf\",\n    \"family\": \"llama\",\n    \"families\": [\"llama\", \"clip\"],\n    \"parameter_size\": \"7B\",\n    \"quantization_level\": \"Q4_0\"\n  }\n}\n</code></pre>"},{"location":"ollama/#copy-a-model","title":"Copy a Model","text":"<pre><code>POST /api/copy\n</code></pre> <p>Copy a model. Creates a model with another name from an existing model.</p>"},{"location":"ollama/#examples_7","title":"Examples","text":""},{"location":"ollama/#request_18","title":"Request","text":"<pre><code>curl http://localhost:11434/api/copy -d '{\n  \"source\": \"llama2\",\n  \"destination\": \"llama2-backup\"\n}'\n</code></pre>"},{"location":"ollama/#response_17","title":"Response","text":"<p>Returns a 200 OK if successful, or a 404 Not Found if the source model doesn't exist.</p>"},{"location":"ollama/#delete-a-model","title":"Delete a Model","text":"<pre><code>DELETE /api/delete\n</code></pre> <p>Delete a model and its data.</p>"},{"location":"ollama/#parameters_4","title":"Parameters","text":"<ul> <li><code>name</code>: model name to delete</li> </ul>"},{"location":"ollama/#examples_8","title":"Examples","text":""},{"location":"ollama/#request_19","title":"Request","text":"<pre><code>curl -X DELETE http://localhost:11434/api/delete -d '{\n  \"name\": \"llama2:13b\"\n}'\n</code></pre>"},{"location":"ollama/#response_18","title":"Response","text":"<p>Returns a 200 OK if successful, 404 Not Found if the model to be deleted doesn't exist.</p>"},{"location":"ollama/#pull-a-model","title":"Pull a Model","text":"<pre><code>POST /api/pull\n</code></pre> <p>Download a model from the ollama library. Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.</p>"},{"location":"ollama/#parameters_5","title":"Parameters","text":"<ul> <li><code>name</code>: name of the model to pull</li> <li><code>insecure</code>: (optional) allow insecure connections to the library. Only use this if you are pulling from your own library during development.</li> <li><code>stream</code>: (optional) if <code>false</code> the response will be returned as a single response object, rather than a stream of objects</li> </ul>"},{"location":"ollama/#examples_9","title":"Examples","text":""},{"location":"ollama/#request_20","title":"Request","text":"<pre><code>curl http://localhost:11434/api/pull -d '{\n  \"name\": \"llama2\"\n}'\n</code></pre>"},{"location":"ollama/#response_19","title":"Response","text":"<p>If <code>stream</code> is not specified, or set to <code>true</code>, a stream of JSON objects is returned:</p> <p>The first object is the manifest:</p> <pre><code>{\n  \"status\": \"pulling manifest\"\n}\n</code></pre> <p>Then there is a series of downloading responses. Until any of the download is completed, the <code>completed</code> key may not be included. The number of files to be downloaded depends on the number of layers specified in the manifest.</p> <pre><code>{\n  \"status\": \"downloading digestname\",\n  \"digest\": \"digestname\",\n  \"total\": 2142590208,\n  \"completed\": 241970\n}\n</code></pre> <p>After all the files are downloaded, the final responses are:</p> <pre><code>{\n    \"status\": \"verifying sha256 digest\"\n}\n{\n    \"status\": \"writing manifest\"\n}\n{\n    \"status\": \"removing any unused layers\"\n}\n{\n    \"status\": \"success\"\n}\n</code></pre> <p>if <code>stream</code> is set to false, then the response is a single JSON object:</p> <pre><code>{\n  \"status\": \"success\"\n}\n</code></pre>"},{"location":"ollama/#push-a-model","title":"Push a Model","text":"<pre><code>POST /api/push\n</code></pre> <p>Upload a model to a model library. Requires registering for ollama.ai and adding a public key first.</p>"},{"location":"ollama/#parameters_6","title":"Parameters","text":"<ul> <li><code>name</code>: name of the model to push in the form of <code>&lt;namespace&gt;/&lt;model&gt;:&lt;tag&gt;</code></li> <li><code>insecure</code>: (optional) allow insecure connections to the library. Only use this if you are pushing to your library during development.</li> <li><code>stream</code>: (optional) if <code>false</code> the response will be returned as a single response object, rather than a stream of objects</li> </ul>"},{"location":"ollama/#examples_10","title":"Examples","text":""},{"location":"ollama/#request_21","title":"Request","text":"<pre><code>curl http://localhost:11434/api/push -d '{\n  \"name\": \"mattw/pygmalion:latest\"\n}'\n</code></pre>"},{"location":"ollama/#response_20","title":"Response","text":"<p>If <code>stream</code> is not specified, or set to <code>true</code>, a stream of JSON objects is returned:</p> <pre><code>{ \"status\": \"retrieving manifest\" }\n</code></pre> <p>and then:</p> <pre><code>{\n  \"status\": \"starting upload\",\n  \"digest\": \"sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711ab\",\n  \"total\": 1928429856\n}\n</code></pre> <p>Then there is a series of uploading responses:</p> <pre><code>{\n  \"status\": \"starting upload\",\n  \"digest\": \"sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711ab\",\n  \"total\": 1928429856\n}\n</code></pre> <p>Finally, when the upload is complete:</p> <pre><code>{\"status\":\"pushing manifest\"}\n{\"status\":\"success\"}\n</code></pre> <p>If <code>stream</code> is set to <code>false</code>, then the response is a single JSON object:</p> <pre><code>{ \"status\": \"success\" }\n</code></pre>"},{"location":"ollama/#generate-embeddings","title":"Generate Embeddings","text":"<pre><code>POST /api/embeddings\n</code></pre> <p>Generate embeddings from a model</p>"},{"location":"ollama/#parameters_7","title":"Parameters","text":"<ul> <li><code>model</code>: name of model to generate embeddings from</li> <li><code>prompt</code>: text to generate embeddings for</li> </ul> <p>Advanced parameters:</p> <ul> <li><code>options</code>: additional model parameters listed in the documentation for the Modelfile such as <code>temperature</code></li> <li><code>keep_alive</code>: controls how long the model will stay loaded into memory following the request (default: <code>5m</code>)</li> </ul>"},{"location":"ollama/#examples_11","title":"Examples","text":""},{"location":"ollama/#request_22","title":"Request","text":"<pre><code>curl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"all-minilm\",\n  \"prompt\": \"Here is an article about llamas...\"\n}'\n</code></pre>"},{"location":"ollama/#response_21","title":"Response","text":"<pre><code>{\n  \"embedding\": [\n    0.5670403838157654, 0.009260174818336964, 0.23178744316101074, -0.2916173040866852, -0.8924556970596313,\n    0.8785552978515625, -0.34576427936553955, 0.5742510557174683, -0.04222835972905159, -0.137906014919281\n  ]\n}\n</code></pre>"},{"location":"poetry/","title":"poetry","text":"<pre><code># Install poetry\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python3 -\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Install dependencies\npoetry install\n\n# Update Poetry\npoetry self update\n\n# Run\npoetry run python main.py\n\n# Run tests\npoetry run pytest\n\n# Run tests with coverage and open in browser\npoetry run pytest --cov=src --cov-report=html &amp;&amp; open htmlcov/index.html\n\n# Fix poetry shell not activating virtualenv\nsource \"$( poetry env list --full-path | grep Activated | cut -d' ' -f1 )/bin/activate\"\n\n# Add from requirements.txt\npoetry add $(cat requirements.txt)\n# or\ncat requirements.txt | xargs poetry add\n\n</code></pre>"},{"location":"rag/","title":"RAG","text":""},{"location":"rag/#huggingface","title":"Huggingface","text":"<p>Retriever used to get documents from vector queries. It retrieves the documents embeddings as well as the documents contents, and it formats them to be used with a RagModel.</p> <p>Examples:</p> <pre><code># To load the default \"wiki_dpr\" dataset with 21M passages from wikipedia (index name is 'compressed' or 'exact')\nfrom transformers import RagRetriever\n\nretriever = RagRetriever.from_pretrained(\n    \"facebook/dpr-ctx_encoder-single-nq-base\", dataset=\"wiki_dpr\", index_name=\"compressed\"\n)\n\n# To load your own indexed dataset built with the datasets library. More info on how to build the indexed dataset in examples/rag/use_own_knowledge_dataset.py\nfrom transformers import RagRetriever\n\ndataset = (\n    ...\n)  # dataset must be a datasets.Datasets object with columns \"title\", \"text\" and \"embeddings\", and it must have a faiss index\nretriever = RagRetriever.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\", indexed_dataset=dataset)\n\n# To load your own indexed dataset built with the datasets library that was saved on disk. More info in examples/rag/use_own_knowledge_dataset.py\nfrom transformers import RagRetriever\n\ndataset_path = \"path/to/my/dataset\"  # dataset saved via *dataset.save_to_disk(...)*\nindex_path = \"path/to/my/index.faiss\"  # faiss index saved via *dataset.get_index(\"embeddings\").save(...)*\nretriever = RagRetriever.from_pretrained(\n    \"facebook/dpr-ctx_encoder-single-nq-base\",\n    index_name=\"custom\",\n    passages_path=dataset_path,\n    index_path=index_path,\n)\n\n# To load the legacy index built originally for Rag's paper\nfrom transformers import RagRetriever\n\nretriever = RagRetriever.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\", index_name=\"legacy\")\n</code></pre> <p>RAG is a seq2seq model which encapsulates two core components: a question encoder and a generator. During a forward pass, we encode the input with the question encoder and pass it to the retriever to extract relevant context documents. The documents are then prepended to the input. Such contextualized inputs is passed to the generator.</p> <pre><code>from transformers import AutoTokenizer, RagRetriever, RagModel\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-token-base\")\nretriever = RagRetriever.from_pretrained(\n    \"facebook/rag-token-base\", index_name=\"exact\", use_dummy_dataset=True\n)\n# initialize with RagRetriever to do everything in one forward call\nmodel = RagModel.from_pretrained(\"facebook/rag-token-base\", retriever=retriever)\n\ninputs = tokenizer(\"How many people live in Paris?\", return_tensors=\"pt\")\noutputs = model(input_ids=inputs[\"input_ids\"])\n</code></pre> <pre><code>from transformers import AutoTokenizer, RagRetriever, RagSequenceForGeneration\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\nretriever = RagRetriever.from_pretrained(\n    \"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True\n)\n# initialize with RagRetriever to do everything in one forward call\nmodel = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n\ninputs = tokenizer(\"How many people live in Paris?\", return_tensors=\"pt\")\ntargets = tokenizer(text_target=\"In Paris, there are 10 million people.\", return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\nlabels = targets[\"input_ids\"]\noutputs = model(input_ids=input_ids, labels=labels)\n\n# or use retriever separately\nmodel = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", use_dummy_dataset=True)\n# 1. Encode\nquestion_hidden_states = model.question_encoder(input_ids)[0]\n# 2. Retrieve\ndocs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\ndoc_scores = torch.bmm(\n    question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n).squeeze(1)\n# 3. Forward to generator\noutputs = model(\n    context_input_ids=docs_dict[\"context_input_ids\"],\n    context_attention_mask=docs_dict[\"context_attention_mask\"],\n    doc_scores=doc_scores,\n    decoder_input_ids=labels,\n)\n</code></pre>"},{"location":"rag/#langchain","title":"langchain","text":"<p>https://python.langchain.com/docs/expression_language/cookbook/retrieval</p> <p>Let's look at adding in a retrieval step to a prompt and LLM, which adds up to a \"retrieval-augmented generation\" chain</p> <pre><code>pip install langchain openai faiss-cpu tiktoken\n``````\n\n```python\nfrom operator import itemgetter\n\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.vectorstores import FAISS\n\nvectorstore = FAISS.from_texts([\"harrison worked at kensho\"], embedding=OpenAIEmbeddings())\nretriever = vectorstore.as_retriever()\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nmodel = ChatOpenAI()\n\nchain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \n    | prompt \n    | model \n    | StrOutputParser()\n)\nchain.invoke(\"where did harrison work?\")\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\nAnswer in the following language: {language}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nchain = {\n    \"context\": itemgetter(\"question\") | retriever, \n    \"question\": itemgetter(\"question\"), \n    \"language\": itemgetter(\"language\")\n} | prompt | model | StrOutputParser()\n\nchain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})\n\n\n\n</code></pre>"},{"location":"random/","title":"Random","text":""},{"location":"random/#quartet","title":"Quartet","text":"<p>Hobby became dream.</p> <p>People who cry while eating always survive.</p> <p>https://github.com/aisingapore/PeekingDuck Problem: peeking duck is a opensource modular framework, built for Computer Vision inference. A need for training custom computer vision models with custom datasets. Task: To create a configurable training pipeline for Pytorch and Tensorflow framework for custom datasets for various tasks like classification and object detection.</p> <p>Actions: We used the C4 diagram to blueprint the architecture and selected Hydra as the best configuration framework. The training pipeline was built using the SOLID principles for sustainable development. </p> <p>Results: A highly configurable training pipeline for both Tensorflow and pytorch.</p> <p>Peeking Duck is an open-source modular framework built for Computer Vision inference. The team created a configurable training pipeline for Pytorch and Tensorflow frameworks for custom datasets for various tasks like classification and object detection. They used the C4 diagram to blueprint the architecture and selected Hydra as the best configuration framework. The training pipeline was built using the SOLID principles for sustainable development. The result is a highly configurable training pipeline for both Tensorflow and Pytorch.</p> <p>SOLID is an acronym for five design principles intended to make software designs more understandable, flexible and maintainable. The principles are Single Responsibility Principle (SRP), Open-Closed Principle (OCP), Liskov Substitution Principle (LSP), Interface Segregation Principle (ISP), and Dependency Inversion Principle (DIP).123</p> <p>SRP: A class should have only one reason to change. OCP: Software entities should be open for extension but closed for modification. LSP: Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program. ISP: A client should never be forced to implement an interface that it doesn\u2019t use or clients shouldn\u2019t be forced to depend on methods they do not use. DIP: High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions.</p>"},{"location":"resume/","title":"Resume","text":"<pre><code>\u2584\u2584\u258c \u2590 \u2584\u258c       \u2590 \u2584  \u2584\u2584 \u2022     \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 . \u2584\u2584\u00b7 \u2584 \u2022\u2584     \u2022 \u258c \u2584 \u00b7. \u2584\u2584\u2584 . \u2590 \u2584  \u2584\u2584 \u2022 \n\u2588\u2588\u00b7 \u2588\u258c\u2590\u2588\u25aa     \u2022\u2588\u258c\u2590\u2588\u2590\u2588 \u2580 \u25aa    \u2022\u2588\u2588  \u2580\u2584.\u2580\u00b7\u2590\u2588 \u258c\u25aa\u2588\u258c\u2584\u258c\u25aa    \u00b7\u2588\u2588 \u2590\u2588\u2588\u2588\u25aa\u2580\u2584.\u2580\u00b7\u2022\u2588\u258c\u2590\u2588\u2590\u2588 \u2580 \u25aa\n\u2588\u2588\u25aa\u2590\u2588\u2590\u2590\u258c \u2584\u2588\u2580\u2584 \u2590\u2588\u2590\u2590\u258c\u2584\u2588 \u2580\u2588\u2584     \u2590\u2588.\u25aa\u2590\u2580\u2580\u25aa\u2584\u2588\u2588 \u2584\u2584\u2590\u2580\u2580\u2584\u00b7    \u2590\u2588 \u258c\u2590\u258c\u2590\u2588\u00b7\u2590\u2580\u2580\u25aa\u2584\u2590\u2588\u2590\u2590\u258c\u2584\u2588 \u2580\u2588\u2584\n\u2590\u2588\u258c\u2588\u2588\u2590\u2588\u258c\u2590\u2588\u258c.\u2590\u258c\u2588\u2588\u2590\u2588\u258c\u2590\u2588\u2584\u25aa\u2590\u2588     \u2590\u2588\u258c\u00b7\u2590\u2588\u2584\u2584\u258c\u2590\u2588\u2588\u2588\u258c\u2590\u2588.\u2588\u258c    \u2588\u2588 \u2588\u2588\u258c\u2590\u2588\u258c\u2590\u2588\u2584\u2584\u258c\u2588\u2588\u2590\u2588\u258c\u2590\u2588\u2584\u25aa\u2590\u2588\n \u2580\u2580\u2580\u2580 \u2580\u25aa \u2580\u2588\u2584\u2580\u25aa\u2580\u2580 \u2588\u25aa\u00b7\u2580\u2580\u2580\u2580      \u2580\u2580\u2580  \u2580\u2580\u2580 \u00b7\u2580\u2580\u2580 \u00b7\u2580  \u2580    \u2580\u2580  \u2588\u25aa\u2580\u2580\u2580 \u2580\u2580\u2580 \u2580\u2580 \u2588\u25aa\u00b7\u2580\u2580\u2580\u2580 \n</code></pre> <p>20 years of software engineering experience. Reverse engineering codes with strong learning attitude.</p>"},{"location":"resume/#particulars","title":"Particulars","text":"Full Name as per passport: Wong Teck Meng Nationality: Singaporean \"Email: \"gfuryhawk@gmail.com Code repositories https://github.com/furyhawk https://www.kaggle.com/teckmengwong"},{"location":"resume/#experiences","title":"Experiences","text":""},{"location":"resume/#employment-history-20-years-software-engineering","title":"Employment history : 20+ years Software Engineering","text":"Period Employer Positions Responsibilities 2023-2024 UParcel AI Engineer Software Engineering 2022-2023 AI Singapore Associate AI Engineer MLOps 2020-2021 NCS Fiori developer SAP Edge Implementation 2019-2020 BHP Developer Fiori Project Implementation 2006-2019 NCS Senior Consultant SAP Consultant/ABAP/Fiori 2000-2006 Creative Associate Engineer Software QA"},{"location":"resume/#uparcel-2023-present","title":"UParcel : 2023 - present","text":"<p>AI Engineer</p> <ul> <li>Route Optimization: Improved delivery efficiency by optimizing routes using large-scale data analysis and heuristic algorithm parameter fine-tuning, resulting in a 20% increase in driver acceptance rates for listed jobs.</li> <li>Market Launch: Successfully launched optimized last-mile delivery solutions in the Malaysian market, expanding UParcel's presence and capabilities.</li> <li>CD/CI Pipeline Management: Managed the project pipeline for UParcel's Continuous Deployment/Continuous Integration (CD/CI) using AWS tech stack CDK, ensuring seamless and efficient development operations and maintaining a high degree of reliability and scalability.</li> </ul> <p></p>"},{"location":"resume/#ai-singapore-2022-2023-1-yrs","title":"AI Singapore : 2022 - 2023 : 1 yrs","text":"<p>Associate AI Engineer</p> <ul> <li>Content Generation: Scoped requirements for event planning for a government agency using Langchain and prompt engineering.</li> <li>MLOps: Implemented MLOps using Pytorch and Tensorflow frameworks, developing a highly configurable ML pipeline with Hydra for tasks such as image classification and object detection, adhering to SOLID engineering principles. (PeekingDuck)</li> <li>Industrial Defect Detection: Designed and researched an industrial defect detection proof-of-concept for an American multinational company using OpenVINO, deploying it on the Nvidia Jetson Xavier NX Developer kit.</li> <li>Mentorship: Mentored batches 12 and 13 on Computer Vision.</li> </ul> <p>AI Apprentice</p> <p>(Batch 11, 2 months + 7 months on-the-job training)</p> <ul> <li>Competitive Selection: Selected as one of the top 19 candidates out of hundreds of applicants, demonstrating exceptional potential in AI engineering.</li> <li>Intensive Training: Completed an immersive 2-month deepskilling program in AI engineering, followed by 7 months of hands-on on-the-job training on a real-world industry AI problem.</li> </ul>"},{"location":"resume/#career-transition-2021-2022-1-yrs","title":"Career transition : 2021 - 2022 : 1 yrs","text":"<ul> <li>Self-Hosting: Successfully self-hosted applications and API services on a personal domain (https://furyhawk.lol/) using Docker Swarm on 3 Raspberry Pi devices, demonstrating expertise in containerization and orchestration.</li> <li>Cloud-Native Migration: Transitioning hosted applications and API services to Kubernetes using Talos and Proxmox, showcasing ability to adapt to new technologies and architectures.</li> </ul>"},{"location":"resume/#team-fight-tactics-strategy-application","title":"Team Fight Tactics Strategy Application","text":"<p>github.com/furyhawk/tftchamp</p> <ul> <li>Dockerization: Containerized the application to showcase gamers' meta of current patch using feature importances, utilizing Docker to ensure scalability and reliability.</li> <li>Frontend Development: Implemented the frontend using React and Zustand, demonstrating proficiency in building responsive and efficient user interfaces.</li> </ul> <p></p>"},{"location":"resume/#ncs-2020-2021-1-yrs","title":"NCS : 2020 - 2021 : 1 yrs","text":"<p>Fiori developer</p> <ul> <li>SAP Edge Development: Implemented SAP Edge applications using Agile methodology, demonstrating ability to work iteratively and deliver results in a fast-paced environment.</li> <li>Maintenance Dashboard: Developed a Maintenance Dashboard for the Singapore Air Force F16/Apache Squadron on Edge devices, improving turnaround reliability and showcasing expertise in building tailored solutions for complex industries.</li> </ul> <p> </p> <p> </p>"},{"location":"resume/#bhp-2019-2020-1-yr-2-mos","title":"BHP : 2019 - 2020 : 1 yr 2 mos","text":"<p>Developer</p> <ul> <li>Global Rollout: Successfully implemented the Resource Scheduler application globally, enabling mass scheduling of work to personnel while considering work restrictions and capacity availability.</li> <li>Process Improvement: Achieved significant reductions in Time-on-task, User Error Rate, and improved safety compliance, demonstrating ability to develop solutions that drive business value and enhance operational efficiency.</li> </ul> <p></p>"},{"location":"resume/#ncs-2008-2019-10-yrs-7-mos","title":"NCS : 2008 - 2019 : 10 yrs 7 mos","text":"<p>Senior Consultant</p> <ul> <li>ERP Implementation: Successfully led 11 cycles of end-to-end Enterprise Resource Planning (SAP) projects, totaling over $100 million in value, across various business domains (Material Planning, Procurement, Logistics, Finance and Control, Human Resource, and Plant Maintenance).</li> <li>Productivity Excellence: Consistently improved productivity and added value after each project cycle by applying best practices in Software Engineering.</li> <li>Technical Expertise: Demonstrated proficiency in implementing projects using both Frontend (Fiori) and Backend (ABAP) frameworks, showcasing versatility in SAP development.</li> <li>Agile Leadership: Spearheaded Agile Scrum methodology adoption among project team members, fostering collaborative and iterative development.</li> <li>Crisis Management: Successfully restored a critical production database outage under time pressure by applying root cause analysis techniques, ensuring business continuity and minimizing downtime.</li> </ul> <p></p>"},{"location":"resume/#creative-2001-2008-7-yrs-1-mos","title":"Creative : 2001 - 2008 : 7 yrs 1 mos","text":"<p>Associate Engineer</p> <ul> <li>Pioneering QA: Contributed to the development of the world's first MP3 devices, ensuring high-quality software and hardware through rigorous Quality Assurance processes.</li> </ul> <p> </p>"},{"location":"resume/#education-qualifications","title":"Education Qualifications","text":"Period Discipline/University 2011-2017 Bachelor of Science IT and Business (ERP) Singapore University of Social Sciences"},{"location":"resume/#professional-qualification","title":"Professional Qualification","text":"<ul> <li> <p>Certificate Verification \u2013 AI Professionals Association (AIP)</p> </li> <li> <p>Udacity Nanodegree Program - Machine Learning Engineer</p> </li> <li> <p>SMU Certificate in Artificial Intelligence Module 1 - Building AI Capability with Basic Coding for Business</p> </li> <li> <p>SAP Certified Application Associate \u2013 Procurement with SAP ERP 6.0 EHP6</p> </li> <li> <p>C_FIORDEV_20 Development Associate \u2013 SAP Fiori Application Developer</p> </li> </ul>"},{"location":"resume/#hobbies","title":"Hobbies","text":"<pre><code>- Open source projects\n</code></pre>"},{"location":"scrape_pad/","title":"majaro","text":"<pre><code>\u201croot=PARTUUID=1d7d1003-8f39-41da-9db4-f46a07e06335 rw rootwait audit=0 splash plymouth.ignore-serial-consoles\u201d\n</code></pre>"},{"location":"scrape_pad/#sway","title":"sway","text":"<pre><code>\u201croot=PARTUUID=e9389d07-71a8-44a0-b383-1fbe0c22001a\" \"rw rootwait audit=0 splash plymouth.ignore-serial-consoles\u201d\n</code></pre> Full Name as per passport: Wong Teck Meng Nationality: Singaporean \"Email: \"gfuryhawk@gmail.com"},{"location":"scrape_pad/#yolox","title":"Yolox","text":"<p>python tools/train.py -f exps/example/custom/nano.py -d 1 -b 2 -c yolox_nano.pth targets.shape torch.Size([2, 120, 5]) inps.shape torch.Size([2, 3, 416, 416])</p>"},{"location":"scrape_pad/#question","title":"question","text":"<ul> <li>org, dept, position level.</li> <li>what are the expectation of me after 6 months.</li> <li>when do I expectate a reply.</li> <li>weak point briefly.</li> </ul>"},{"location":"scrape_pad/#stage-of-job-interview","title":"stage of job interview","text":""},{"location":"scrape_pad/#before","title":"before","text":"<p>preparation</p>"},{"location":"scrape_pad/#during","title":"during","text":"<p>connection how are you? Thanks for you for asking, I have being looking forward to meeting you. Smile before exit.</p>"},{"location":"scrape_pad/#tell-me-about-yourself","title":"tell me about yourself","text":"<p>2-3 stories relevant to jobs. 90-120s. STARS. aspiration.</p>"},{"location":"scrape_pad/#overqualifed","title":"overqualifed","text":"<p>immediately fulfill the role, take more roles.</p>"},{"location":"scrape_pad/#ideal-job","title":"ideal job","text":"<p>work life balance</p>"},{"location":"scrape_pad/#yrself-in-2-yrs","title":"yrself in 2 yrs","text":"<p>growing to fill in others roles. (never about title, promotion)</p> <p>I will really appreciate it if you make the first offer.</p>"},{"location":"scrape_pad/#after","title":"after","text":"<ul> <li>follow up the next day on thank you note.</li> </ul>"},{"location":"scrape_pad/#misc","title":"misc","text":"<pre><code>cp /etc/i3status.conf ~/.config/i3status/config\n\nsystemctl --user start docker-desktop\nsudo groupadd docker\nsudo usermod -aG docker $USER\n</code></pre>"},{"location":"smb/","title":"Samba","text":"<p>Samba is the standard Windows interoperability suite of programs for Linux and Unix. Since 1992, Samba has provided secure, stable and fast file and print services for all clients using the SMB/CIFS protocol, such as all versions of DOS and Windows, OS/2, Linux and many others.</p> <p>To share files through Samba, see #Server section; to access files shared through Samba on other machines, please see #Client section.</p>"},{"location":"smb/#server","title":"Server","text":"<pre><code>cd /mnt/\nsudo mkdir media\nnano /home/user/.credentials\nsudo chmod 400 /home/user/.credentials\nsudo mount -t cifs -o rw,vers=3.0,credentials=/home/user/.credentials //coco.local/media/ /mnt/media\nsudo nano /etc/fstab\n# smbclient -L hostname -U%\n# //coco.local/media    /mnt/media  cifs    vers=3.0,credentials=/home/user/.credentials\n</code></pre>"},{"location":"smb/#installation","title":"Installation","text":"<p>Install the  package.</p> <p>Samba is configured in the  configuration file, which is extensively documented in .</p> <p>Because the  package does not provide this file, one needs to create it before starting .</p> <p>A documented example as in  from the Samba git repository may be used to setup .</p>"},{"location":"smb/#enabling-and-starting-services","title":"Enabling and starting services","text":"<p>To provide basic file sharing through SMB, enable/start . See  for details.</p> <p>If you want to make your server accessible via NetBIOS host name, set the desired name in the  option in  and enable/start . See  for details.</p>"},{"location":"smb/#make-the-server-discoverable","title":"Make the server discoverable","text":"<p>Install the  package, then enable/start  to make the samba server discoverable with Zeroconf. It should work for most non-Windows file managers (macOS Finder, various GUI-based file managers on Linux &amp; BSD etc.)</p> <p>If  is not running, the server will still be accessible, just not discoverable, i.e. it will not show up in file managers, but you can still connect to the server directly by IP or domain.</p> <p>Windows Explorer relies on the WS-Discovery protocol instead; see #Windows 1709 or up does not discover the samba server in Network view.</p>"},{"location":"smb/#configure-firewall","title":"Configure firewall","text":"<p>If you are using a firewall, do not forget to open required ports (usually 137-139 + 445). For a complete list, see Samba port usage.</p>"},{"location":"smb/#ufw-rule","title":"UFW Rule","text":"<p>A Ufw App Profile for SMB/CIFS is included by default with the default installation of UFW in .</p> <p>Allow Samba by running  as root.</p> <p>If you deleted the profile, create/edit  and add the following content:</p> <p><code>[Samba]</code> <code>title=LanManager-like\u00a0file\u00a0and\u00a0printer\u00a0server\u00a0for\u00a0Unix</code> <code>description=The\u00a0Samba\u00a0software\u00a0suite\u00a0is\u00a0a\u00a0collection\u00a0of\u00a0programs\u00a0that\u00a0implements\u00a0the\u00a0SMB/CIFS\u00a0protocol\u00a0for\u00a0unix\u00a0systems,\u00a0allowing\u00a0you\u00a0to\u00a0serve\u00a0files\u00a0and\u00a0printers\u00a0to\u00a0Windows,\u00a0NT,\u00a0OS/2\u00a0and\u00a0DOS\u00a0clients.\u00a0This\u00a0protocol\u00a0is\u00a0sometimes\u00a0also\u00a0referred\u00a0to\u00a0as\u00a0the\u00a0LanManager\u00a0or\u00a0NetBIOS\u00a0protocol.</code> <code>ports=137,138/udp|139,445/tcp</code></p> <p>Then load the profile into UFW run  as root.</p> <p>Then finally, allow Samba by running  as root.</p>"},{"location":"smb/#firewalld-service","title":"firewalld service","text":"<p>To configure firewalld to allow Samba in the home zone, run:</p> <p><code>#\u00a0firewall-cmd\u00a0--permanent\u00a0--add-service={samba,samba-client,samba-dc}\u00a0--zone=home</code></p> <p>The three services listed are:</p> <ul> <li> <p>: for sharing files with others.</p> </li> <li> <p>: to browse shares on other machines on the network.</p> </li> <li> <p>: for Samba/Active Directory domain   controller.</p> </li> </ul> <p>ensures the changes remain after  is restarted.</p>"},{"location":"smb/#basic-configuration","title":"Basic configuration","text":""},{"location":"smb/#user-management","title":"User management","text":"<p>The following section describes creating a local (tdbsam) database of Samba users. For user authentication and other purposes, Samba can also be bound to an Active Directory domain, can itself serve as an Active Directory domain controller, or can be used with an LDAP server.</p>"},{"location":"smb/#adding-a-user","title":"Adding a user","text":"<p>Samba requires a Linux user account - you may use an existing user account or create a new one.</p> <p>Although the user name is shared with Linux system, Samba uses a password separate from that of the Linux user accounts. Replace  with the chosen Samba user account:</p> <p><code>#\u00a0smbpasswd\u00a0-a</code><code>samba_user</code></p> <p>Depending on the server role, existing File permissions and attributes may need to be altered for the Samba user account.</p> <p>If you want the new user only to be allowed to remotely access the file server shares through Samba, you can restrict other login options\uff1a</p> <ul> <li>disabling shell - </li> <li>disabling SSH logons - edit , change option </li> </ul> <p>Also see Security for hardening your system.</p>"},{"location":"smb/#listing-users","title":"Listing users","text":"<p>Samba users can be listed using the  command:</p> <p><code>#\u00a0pdbedit\u00a0-L\u00a0-v</code></p>"},{"location":"smb/#changing-user-password","title":"Changing user password","text":"<p>To change a user password, use :</p> <p><code>#\u00a0smbpasswd</code><code>samba_user</code></p>"},{"location":"smb/#creating-an-anonymous-share","title":"Creating an anonymous share","text":"<p>1. Create a Linux user which anonymous Samba users will be mapped to.</p> <p><code>#\u00a0useradd\u00a0guest\u00a0-s\u00a0/bin/nologin</code></p> <p>2. Add the following to :</p> <p>Anonymous users will now be mapped to the Linux user  and have the ability to access any directories defined in , which is configured to be  in the example above.</p> <p>Make sure that the Linux user  has the proper permissions to access files in .</p> <p>Also, make sure shares have been properly defined as per the Share Definitions section of smb.conf.default.</p>"},{"location":"smb/#advanced-configuration","title":"Advanced configuration","text":""},{"location":"smb/#enable-symlink-following","title":"Enable symlink following","text":"<p>Then, restart .</p>"},{"location":"smb/#enable-server-side-copy-for-macos-clients","title":"Enable server-side copy for macOS clients","text":"<p>Server-side copy eliminates the need to transfer data between the server and the client when copying files on the server. This is enabled by default, but it doesn't work with macOS clients. If you have macOS clients, you need to add the following configuration to  and then restart .</p>"},{"location":"smb/#enable-usershares","title":"Enable Usershares","text":"<p>Usershares is a feature that gives non-root users the capability to add, modify, and delete their own share definitions. See .</p> <ol> <li>Create a directory for usershares: </li> <li>Create a user group: </li> <li>Change the owner of the directory to  and the group to : </li> <li>Change the permissions of the  directory so that users in the group     can create files. This command also sets sticky    bit, which is important to prevent    users from deleting usershares of other users: </li> </ol> <p>Set the following parameters in the  configuration file:</p> <p>Add the user to the sambashare group. Replace  with the name of your user:</p> <p><code>#\u00a0gpasswd\u00a0sambashare\u00a0-a</code><code>your_username</code></p> <p>Restart  and  services.</p> <p>Log out and log back in.</p> <p>If you want to share paths inside your home directory you must make it accessible for the group others.</p> <p>In the GUI, you can use Thunar or Dolphin - right click on any directory and share it on the network.</p> <p>In the CLI, use one of the following commands, replacing italic sharename, user, ... :</p> <p><code>#\u00a0net\u00a0usershare\u00a0add</code><code>sharename</code><code></code><code>abspath</code><code>[</code><code>comment</code><code>]\u00a0[</code><code>user</code><code>:{R|D|F}]\u00a0[guest_ok={y|n}]</code> <code>#\u00a0net\u00a0usershare\u00a0delete</code><code>sharename</code> <code>#\u00a0net\u00a0usershare\u00a0list</code><code>wildcard-sharename</code> <code>#\u00a0net\u00a0usershare\u00a0info</code><code>wildcard-sharename</code></p>"},{"location":"smb/#set-and-forcing-permissions","title":"Set and forcing permissions","text":"<p>Permissions may be applied to both the server and shares:</p> <p>See  for a full overview of possible permission flags and settings.</p>"},{"location":"smb/#restrict-protocols-for-better-security","title":"Restrict protocols for better security","text":"<p>Append  and  in  to force usage of a minimum and maximum protocol:</p> <p>See  in  for an overview of supported protocols.</p> <p>For compatibility with older clients and/or servers, you might need to set  or , but please note that this makes you vulnerable to exploits in SMB1 including ransomware attacks.</p> <p>Clients using  may need to specify the correct , e.g.:</p> <p><code>#\u00a0mount\u00a0-t\u00a0cifs\u00a0//</code><code>SERVER</code><code>/</code><code>sharename</code><code>/mnt/</code><code>mountpoint</code><code>-o\u00a0username=</code><code>username</code><code>,password=</code><code>password</code><code>,iocharset=</code><code>utf8</code><code>,vers=</code><code>3.1.1</code></p> <p>See  for more information.</p>"},{"location":"smb/#use-native-smb-transport-encryption","title":"Use native SMB transport encryption","text":"<p>Native SMB transport encryption is available in SMB version 3.0 or newer. Clients supporting this type of encryption include Windows 8 and newer, Windows server 2012 and newer, and smbclient of Samba 4.1 and newer.</p> <p>To use native SMB transport encryption by default, set the  parameter globally and/or by share. Possible values are ,  (default value), , or :</p> <p>To configure encryption for on the client side, use the option .</p> <p>See  for more information, especially the paragraphs Effects for SMB1 and Effects for SMB2.</p>"},{"location":"smb/#disable-printer-sharing","title":"Disable printer sharing","text":"<p>By default Samba shares printers configured using CUPS.</p> <p>If you do not want printers to be shared, use the following settings:</p>"},{"location":"smb/#block-certain-file-extensions-on-samba-share","title":"Block certain file extensions on Samba share","text":"<p>Samba offers an option to block files with certain patterns, like file extensions. This option can be used to prevent dissemination of viruses or to dissuade users from wasting space with certain files. More information about this option can be found in .</p>"},{"location":"smb/#improve-throughput","title":"Improve throughput","text":"<p>The default settings should be sufficient for most users. However setting the 'socket options' correct can improve performance, but getting them wrong can degrade it by just as much. Test the effect before making any large changes.</p> <p>Read the  man page before applying any of the options listed below.</p> <p>The following settings should be appended to the  section of .</p> <p>Setting a deadtime is useful to stop a server's resources from being exhausted by a large number of inactive connections:</p> <p><code>deadtime\u00a0=\u00a030</code></p> <p>The usage of sendfile may make more efficient use of the system CPU's and cause Samba to be faster:</p> <p><code>use\u00a0sendfile\u00a0=\u00a0yes</code></p> <p>Setting min receivefile size allows zero-copy writes directly from network socket buffers into the filesystem buffer cache (if available). It may improve performance but user testing is recommended:</p> <p><code>min\u00a0receivefile\u00a0size\u00a0=\u00a016384</code></p> <p>Increasing the receive/send buffers size and socket optimize flags might be useful to improve throughput. It is recommended to test each flag separately as it may cause issues on some networks:</p> <p><code>socket\u00a0options\u00a0=\u00a0IPTOS_LOWDELAY\u00a0TCP_NODELAY\u00a0IPTOS_THROUGHPUT\u00a0SO_RCVBUF=131072\u00a0SO_SNDBUF=131072</code></p>"},{"location":"smb/#enable-access-for-old-clientsdevices","title":"Enable access for old clients/devices","text":"<p>Latest versions of Samba no longer offer older authentication methods and protocols which are still used by some older clients (IP cameras, etc). These devices usually require Samba server to allow NTMLv1 authentication and NT1 version of the protocol, known as CIFS. For these devices to work with latest Samba, you need to add these two configuration parameters into  section:</p> <p><code>server\u00a0min\u00a0protocol\u00a0=\u00a0NT1</code> <code>ntlm\u00a0auth\u00a0=\u00a0yes</code></p> <p>Anonymous/guest access to a share requires just the first parameter. If the old device will access with username and password, you also need the add the second line too.</p>"},{"location":"smb/#enable-spotlight-searching","title":"Enable Spotlight searching","text":"<p>Spotlight allows supporting clients (e.g. MacOS Finder) to quickly search shared files.</p> <p>Install and start/enable OpenSearch. Install , configure the directories you want to index in , and start/enable  for periodic indexing.</p> <p>Edit  as described in the Samba wiki to enable Spotlight per share, and restart  to apply the changes.</p>"},{"location":"smb/#client","title":"Client","text":"<p>Install  for an -like command line interface. See  for commonly used commands.</p> <p>For a lightweight alternative (without support for listing public shares, etc.), install  that provides .</p> <p>Depending on the desktop environment, GUI methods may be available. See #File manager configuration for use with a file manager.</p>"},{"location":"smb/#list-public-shares","title":"List public shares","text":"<p>The following command lists public shares on a server:</p> <p><code>$\u00a0smbclient\u00a0-L</code><code>hostname</code><code>-U%</code></p> <p>Alternatively, running  will show a tree diagram of all the shares. It uses broadcast queries and is therefore not advisable on a network with a lot of computers, but can be helpful for diagnosing if you have the correct sharename. The  () option suppresses the password prompt.</p>"},{"location":"smb/#netbioswins-host-names","title":"NetBIOS/WINS host names","text":"<p>Samba clients handle NetBIOS host names automatically by default (the behavior is controlled by the  option in ). Other programs (including ) typically use Name Service Switch, which does not handle NetBIOS by default.</p> <p>The  package provides a libnss driver to resolve NetBIOS host names. To use it, install it along with the  package (which provides the winbindd daemon), start/enable  and add  to the  line in :</p> <p>Now, during host resolving (e.g. when using  or just ), winbindd will resolve the host name by sending queries using NetBIOS Name Service (NBNS, also known as WINS) protocol.</p> <p>By default it sends a broadcast query to your local network. If you have a WINS server, you can add  to  and restart , then winbindd and other Samba clients will send unicast queries to the specified IP.</p> <p>If you want to resolve your local host name (specified in the  option in ), start/enable , which will handle incoming queries.</p> <p>You can test WINS resolution with . By default it sends broadcast queries to your local network regardless of the  option.</p> <p>Note that WINS resolution requires incoming traffic originating from port 137.</p>"},{"location":"smb/#disable-netbioswins-support","title":"Disable NetBIOS/WINS support","text":"<p>When not using NetBIOS/WINS host name resolution, it may be preferred to disable this protocol:</p> <p><code>/etc/samba/smb.conf</code></p> <pre><code>[global]\n  disable netbios = yes\n  dns proxy = no\n</code></pre> <p>Finally disable/stop .</p>"},{"location":"smb/#manual-mounting","title":"Manual mounting","text":"<p>Mount the share using  as . Not all the options listed below are needed or desirable:</p> <p><code>#\u00a0mount\u00a0--mkdir\u00a0-t\u00a0cifs\u00a0//</code><code>SERVER</code><code>/</code><code>sharename</code><code>/mnt/</code><code>mountpoint</code><code>-o\u00a0username=</code><code>username</code><code>,password=</code><code>password</code><code>,workgroup=</code><code>workgroup</code><code>,iocharset=</code><code>utf8</code><code>,uid=</code><code>username</code><code>,gid=</code><code>group</code></p> <p>The options <code>uid</code> and <code>gid</code> corresponds to the local (e.g. client) user/user group to have read/write access on the given path.</p> <p>Note: If the uid and gid being used does not match the user of the server, the forceuid and forcegid options may be helpful. However note permissions assigned to a file when forceuid or forcegid are in effect may not reflect the the real (server) permissions. See the File And Directory Ownership And Permissions section in mount.cifs(8) \u00a7\u202fFILE AND DIRECTORY OWNERSHIP AND PERMISSIONS for more information. To mount a Windows share without authentication, use \"username=*\".</p> <p>Warning: Using uid and/or gid as mount options may cause I/O errors, it is recommended to set/check correct File permissions and attributes instead.</p> <ul> <li> <p><code>SERVER</code> \u2014 The server name.</p> </li> <li> <p><code>sharename</code> \u2014 The shared directory.</p> </li> <li> <p><code>mountpoint</code> \u2014 The local directory where the share will be mounted.</p> </li> <li> <p><code>[-o options]</code> \u2014 See  for more information.</p> </li> </ul> <p>Note: Abstain from using a trailing /. //SERVER/sharename/ will not work. If your mount does not work stable, stutters or freezes, try to enable different SMB protocol version with vers= option. For example, vers=2.0 for Windows Vista mount. If having timeouts on a mounted network share with cifs on a shutdown, see wpa_supplicant#Problem with mounted network shares (cifs) and shutdown.</p>"},{"location":"smb/#storing-share-passwords","title":"Storing share passwords","text":"<p>Storing passwords in a world readable file is not recommended. A safer method is to use a credentials file instead, e.g. inside <code>/etc/samba/credentials</code>:</p> <p><code>/etc/samba/credentials/share</code></p> <pre><code>username=myuser\npassword=mypass\n</code></pre> <p>For the mount command replace <code>username=myuser,password=mypass</code> with <code>credentials=/etc/samba/credentials/share</code>.</p> <p>The credential file should explicitly readable/writeable to root:</p> <p><code>#\u00a0chown\u00a0root:root\u00a0/etc/samba/credentials</code> <code>#\u00a0chmod\u00a0700\u00a0/etc/samba/credentials</code> <code>#\u00a0chmod\u00a0600\u00a0/etc/samba/credentials/share</code></p>"},{"location":"smb/#automatic-mounting","title":"Automatic mounting","text":"<p>Note: You may need to enable systemd-networkd-wait-online.service or NetworkManager-wait-online.service (depending on your setup) to proper enable booting on start-up.</p>"},{"location":"smb/#using-networkmanager-and-giogvfs","title":"Using NetworkManager and GIO/gvfs","text":"<p>NetworkManager can be configured to run a script on network status change. This script uses the gio command so that it mounts the Samba shares automatically, the same way your file manager does, as explained below. The script also safely unmounts the Samba shares before the relevant network connection is disabled by listening for the  and  events. Make the script is executable after creating it.</p> <p><code>/etc/NetworkManager/dispatcher.d/30-samba.sh</code></p> <pre><code>#!/bin/sh\n\n# Find the connection UUID with \"nmcli con show\" in terminal.\n# All NetworkManager connection types are supported: wireless, VPN, wired...\nWANTED_CON_UUID=\"CHANGE-ME-NOW-9c7eff15-010a-4b1c-a786-9b4efa218ba9\"\n\n# The user the share will be mounted under\nUSER=\"yourusername\"\n# The path that appears in your file manager when you manually mount the share you want\nSMB_URL=\"smb://servername/share\"\n\n# Get runtime user directory. If it does not exist, do nothing and just exit\nXDG_RUNTIME_DIR=$(loginctl show-user --property=RuntimePath --value \"$USER\") || exit 0\n\nif [ \"$CONNECTION_UUID\" = \"$WANTED_CON_UUID\" ]; then\n\n    # Script parameter $1: network interface name, not used\n    # Script parameter $2: dispatched event\n\n    case \"$2\" in\n        \"up\"|\"vpn-up\")\n            su $USER -c \"DBUS_SESSION_BUS_ADDRESS=unix:path=$XDG_RUNTIME_DIR/bus gio mount $SMB_URL\"\n            ;;\n        \"pre-down\"|\"vpn-pre-down\")\n            su $USER -c \"DBUS_SESSION_BUS_ADDRESS=unix:path=$XDG_RUNTIME_DIR/bus gio mount -uf $SMB_URL\"\n            ;;\n    esac\nfi\n</code></pre> <p>Create a symlink inside  to catch the  events:</p> <p><code>#\u00a0ln\u00a0-s\u00a0/etc/NetworkManager/dispatcher.d/30-samba.sh\u00a0/etc/NetworkManager/dispatcher.d/pre-down.d/30-samba.sh</code></p>"},{"location":"smb/#as-mount-entry","title":"As mount entry","text":"<p>This is a simple example of a  mount entry that requires authentication:</p>"},{"location":"smb/#as-systemd-unit","title":"As systemd unit","text":"<p>Create a new  file inside , e.g. . See  for details.</p> <p>path to share</p> <p>path to mount the share</p> <p>share mounting options</p> <p>To use , start the unit and enable it to run on system boot.</p>"},{"location":"smb/#automount","title":"automount","text":"<p>To automatically mount a share (when accessed, like autofs), one may use the following automount unit:</p> <p>Disable/stop the  unit, and enable/start  to automount the share when the mount path is being accessed.</p>"},{"location":"smb/#smbnetfs","title":"smbnetfs","text":"<p>First, check if you can see all the shares you are interested in mounting:</p> <p><code>$\u00a0smbtree\u00a0-U</code><code>remote_user</code></p> <p>If that does not work, find and modify the following line in  accordingly:</p> <p><code>domain\u00a0master\u00a0=\u00a0auto</code></p> <p>Now restart  and .</p> <p>If everything works as expected, install .</p> <p>Then, add the following line to :</p> <p><code>user_allow_other</code></p> <p>Now copy the directory  to your home directory:</p> <p><code>$\u00a0cp\u00a0-a\u00a0/etc/smbnetfs/.smb\u00a0~</code></p> <p>Then create a link to :</p> <p><code>$\u00a0ln\u00a0-sf\u00a0/etc/samba/smb.conf\u00a0~/.smb/smb.conf</code></p> <p>If a username and a password are required to access some of the shared folders, edit  to include one or more entries like this:</p> <p>It is also possible to add entries for specific hosts to be mounted by smbnetfs, if necessary. More details can be found in .</p> <p>If you are using the Dolphin or GNOME Files, you may want to add the following to  to avoid \"Disk full\" errors as smbnetfs by default will report 0 bytes of free space:</p> <p>When you are done with the configuration, you need to run</p> <p><code>$\u00a0chmod\u00a0600\u00a0~/.smb/smbnetfs.*</code></p> <p>Otherwise, smbnetfs complains about 'insecure config file permissions'.</p> <p>Finally, to mount your Samba network neighbourhood to a directory of your choice, call</p> <p><code>$\u00a0smbnetfs</code><code>mount_point</code></p>"},{"location":"smb/#daemon","title":"Daemon","text":"<p>The Arch Linux package also maintains an additional system-wide operation mode for smbnetfs. To enable it, you need to make the said modifications in the directory .</p> <p>Then, you can start and/or enable the  daemon as usual. The system-wide mount point is at .</p>"},{"location":"smb/#autofs","title":"autofs","text":"<p>See Autofs for information on the kernel-based automounter for Linux.</p>"},{"location":"smb/#file-manager-configuration","title":"File manager configuration","text":""},{"location":"smb/#gnome-files-nemo-caja-thunar-and-pcmanfm","title":"GNOME Files, Nemo, Caja, Thunar and PCManFM","text":"<p>In order to access samba shares through GNOME Files, Nemo, Caja, Thunar or PCManFM, install the  package.</p> <p>Press  and enter  in the location bar to access your share.</p> <p>The mounted share is likely to be present at  or  in the filesystem.</p>"},{"location":"smb/#kde","title":"KDE","text":"<p>KDE applications (like Dolphin) has the ability to browse Samba shares built in. Use the path  to browse the files. If you want to access files from on non-KDE application, you can install .</p> <p>To use a GUI in the KDE System Settings, you will need to install the  package.</p>"},{"location":"smb/#other-graphical-environments","title":"Other graphical environments","text":"<p>There are a number of useful programs, but they may need to have packages created for them. This can be done with the Arch package build system. The good thing about these others is that they do not require a particular environment to be installed to support them, and so they bring along less baggage.</p> <ul> <li>LinNeighborhood, RUmba, xffm-samba plugin for Xffm are not available   in the official repositories or the AUR. As they are not officially   (or even unofficially supported), they may be obsolete and may not   work at all.</li> </ul>"},{"location":"smb/#tips-and-tricks","title":"Tips and tricks","text":""},{"location":"smb/#discovering-network-shares","title":"Discovering network shares","text":"<p>If nothing is known about other systems on the local network, and automated tools such as smbnetfs are not available, you can manually probe for Samba shares.</p> <p>First, install the  and  packages.</p> <p>Use nmap to scan your local network to find systems with TCP port 445 open, which is the port used by the SMB protocol. Note that you may need to use  or set a custom ping scan type (e.g. ) because Windows systems are usually firewalled.</p> <p>The first result is another system; the second happens to be the client from where this scan was performed.</p> <p>Now you can connect to there IP addresses directly, but if you want to use NetBIOS host names, you can use  to check for NetBIOS names. Note that this will not work if NetBIOS is disabled on the server.</p> <p>Regardless of the output, look for \\&lt;20&gt;, which shows the host with open services.</p> <p>Use  to list which services are shared on these systems. You can use NetBIOS host name ( in this example) instead of IP when available. If prompted for a password, pressing enter should still display the list:</p>"},{"location":"smb/#remote-control-of-windows-computer","title":"Remote control of Windows computer","text":"<p>Samba offers a set of tools for communication with Windows. These can be handy if access to a Windows computer through remote desktop is not an option, as shown by some examples.</p> <p>Send shutdown command with a comment:</p> <p><code>$\u00a0net\u00a0rpc\u00a0shutdown\u00a0-C\u00a0\"comment\"\u00a0-I\u00a0IPADDRESS\u00a0-U\u00a0USERNAME%PASSWORD</code></p> <p>A forced shutdown instead can be invoked by changing -C with comment to a single -f. For a restart, only add -r, followed by a -C or -f.</p> <p>Stop and start services:</p> <p><code>$\u00a0net\u00a0rpc\u00a0service\u00a0stop\u00a0SERVICENAME\u00a0-I\u00a0IPADDRESS\u00a0-U\u00a0USERNAME%PASSWORD</code></p> <p>To see all possible net rpc command:</p> <p><code>$\u00a0net\u00a0rpc</code></p>"},{"location":"smb/#troubleshooting","title":"Troubleshooting","text":""},{"location":"smb/#failed-to-start-samba-smbcifs-server","title":"Failed to start Samba SMB/CIFS server","text":"<p>Possible solutions:</p> <ul> <li>Check  on syntactic errors with .</li> <li>Set correct permissions for  and restart :</li> </ul> <p><code>#\u00a0chmod\u00a00755\u00a0/var/cache/samba/msg</code></p>"},{"location":"smb/#permission-issues-on-selinux","title":"Permission issues on SELinux","text":"<p>SELinux not allow samba to access user home directories by default, to solve this, run:</p> <p><code>#\u00a0setsebool\u00a0-P\u00a0samba_enable_home_dirs\u00a01</code></p> <p>Similarly,  and  make Samba has the ability to read or \"read and write\" all files.</p>"},{"location":"smb/#permission-issues-on-apparmor","title":"Permission issues on AppArmor","text":"<p>If using a share path located outside of a home or usershares directory, whitelist it in . E.g.:</p>"},{"location":"smb/#no-dialect-specified-on-mount","title":"No dialect specified on mount","text":"<p>The client is using an unsupported SMB/CIFS version that is required by the server.</p> <p>See #Restrict protocols for better security for more information.</p>"},{"location":"smb/#unable-to-overwrite-files-permissions-errors","title":"Unable to overwrite files, permissions errors","text":"<p>Possible solutions:</p> <ul> <li>Append the mount option  to the    entry.</li> <li>Add  to the  section of the server's .</li> </ul>"},{"location":"smb/#windows-clients-keep-asking-for-password-even-if-samba-shares-are-created-with-guest-permissions","title":"Windows clients keep asking for password even if Samba shares are created with guest permissions","text":"<p>Set  inside the  section of :</p> <p><code>map\u00a0to\u00a0guest\u00a0=\u00a0Bad\u00a0Password</code></p> <p>If you are still using Samba \\&lt; 4.10.10, use  instead of .</p>"},{"location":"smb/#windows-7-connectivity-problems-mount-error12-cannot-allocate-memory","title":"Windows 7 connectivity problems - mount error(12): cannot allocate memory","text":"<p>A known Windows 7 bug that causes \"mount error(12): cannot allocate memory\" on an otherwise perfect cifs share on the Linux end can be fixed by setting a few registry keys on the Windows box as follows:</p> <ul> <li> <p>(set to )</p> </li> <li> <p>(set to )</p> </li> </ul> <p>Alternatively, start Command Prompt in Admin Mode and execute the following:</p> <p><code>reg\u00a0add\u00a0\"HKLM\\SYSTEM\\CurrentControlSet\\Control\\Session\u00a0Manager\\Memory\u00a0Management\"\u00a0/v\u00a0\"LargeSystemCache\"\u00a0/t\u00a0REG_DWORD\u00a0/d\u00a01\u00a0/f</code> <code>reg\u00a0add\u00a0\"HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\"\u00a0/v\u00a0\"Size\"\u00a0/t\u00a0REG_DWORD\u00a0/d\u00a03\u00a0/f</code></p> <p>Do one of the following for the settings to take effect:</p> <ul> <li>Restart Windows</li> <li>Restart the Server service via services.msc</li> <li>From the Command Prompt run: 'net stop lanmanserver' and 'net start   lanmanserver' - The server may automatically restart after stopping   it.</li> </ul> <p>Original article.</p>"},{"location":"smb/#windows-10-1709-and-up-connectivity-problems-windows-cannot-access-0x80004005","title":"Windows 10 1709 and up connectivity problems - \"Windows cannot access\" 0x80004005","text":"<p>This error affects some machines running Windows 10 version 1709 and later. It is not related to SMB1 being disabled in this version but to the fact that Microsoft disabled insecure logons for guests on this version for some, but not others.</p> <p>To fix, open Group Policy Editor (). Navigate to Computer configuration\\administrative templates\\network\\Lanman Workstation &gt; Enable insecure guest logons and enable it. Alternatively,change the following value in the registry:</p> <p><code>[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanmanWorkstation\\Parameters]</code> <code>\"AllowInsecureGuestAuth\"=dword:1</code></p>"},{"location":"smb/#error-failed-to-retrieve-printer-list-nt_status_unsuccessful","title":"Error: Failed to retrieve printer list: NT_STATUS_UNSUCCESSFUL","text":"<p>If you are a home user and using samba purely for file sharing from a server or NAS, you are probably not interested in sharing printers through it. If so, you can prevent this error from occurring by adding the following lines to your :</p> <p>Restart the samba service, , and then check your logs:</p> <p><code>#\u00a0cat\u00a0/var/log/samba/smbd.log</code></p> <p>and the error should now no longer be appearing.</p>"},{"location":"smb/#sharing-a-folder-fails","title":"Sharing a folder fails","text":"<p>It means that while you are sharing a folder from Dolphin (file manager) and everything seems ok at first, after restarting Dolphin the share icon is gone from the shared folder, and also some output like this in terminal (Konsole) output:</p> <p><code>\u2018net\u00a0usershare\u2019\u00a0returned\u00a0error\u00a0255:\u00a0net\u00a0usershare:\u00a0usershares\u00a0are\u00a0currently\u00a0disabled</code></p> <p>To fix it, enable usershare as described in #Enable Usershares.</p>"},{"location":"smb/#browsing-network-fails-with-failed-to-retrieve-share-list-from-server","title":"\"Browsing\" network fails with \"Failed to retrieve share list from server\"","text":"<p>And you are using a firewall (iptables) because you do not trust your local (school, university, hotel) network. This may be due to the following: When the smbclient is browsing the local network it sends out a broadcast request on udp port 137. The servers on the network then reply to your client but as the source address of this reply is different from the destination address iptables saw when sending the request for the listing out, iptables will not recognize the reply as being \"ESTABLISHED\" or \"RELATED\", and hence the packet is dropped. A possible solution is to add:</p> <p><code>iptables\u00a0-t\u00a0raw\u00a0-A\u00a0OUTPUT\u00a0-p\u00a0udp\u00a0-m\u00a0udp\u00a0--dport\u00a0137\u00a0-j\u00a0CT\u00a0--helper\u00a0netbios-ns</code></p> <p>to your iptables setup.</p> <p>For Uncomplicated Firewall, you need to add  to the end of the following line in </p> <p><code>IPT_MODULES=\"nf_conntrack_ftp\u00a0nf_nat_ftp\u00a0nf_conntrack_irc\u00a0nf_nat_irc\"</code></p> <p>and then run the following commands as root:</p> <p><code>echo\u00a01\u00a0&gt;\u00a0/proc/sys/net/netfilter/nf_conntrack_helper</code> <code>ufw\u00a0allow\u00a0CIFS</code> <code>ufw\u00a0reload</code></p> <p>To make this change persistent across reboots, add the following line at the end of :</p> <p><code>net.netfilter.nf_conntrack_helper=1</code></p>"},{"location":"smb/#protocol-negotiation-failed-nt_status_invalid_network_response","title":"Protocol negotiation failed: NT_STATUS_INVALID_NETWORK_RESPONSE","text":"<p>The client probably does not have access to shares. Make sure clients' IP address is in  line in .</p> <p>Another problem could be, that the client uses an invalid protocol version. To check this try to connect with the  where you specify the maximum protocol version manually:</p> <p><code>$\u00a0smbclient\u00a0-U</code><code>-L\u00a0//</code><code>-m\u00a0&lt;protocol\u00a0version:\u00a0e.\u00a0g.\u00a0SMB2&gt;\u00a0-W</code> <p>If the command was successful then create a configuration file:</p>"},{"location":"smb/#connection-to-server-failed-error-nt_status_unsuccessful","title":"Connection to SERVER failed: (Error NT_STATUS_UNSUCCESSFUL)","text":"<p>You are probably passing a wrong server name to . To find out the server name, run  on the server and look at \"Transient hostname\" line</p>"},{"location":"smb/#connection-to-server-failed-error-nt_status_connection_refused","title":"Connection to SERVER failed: (Error NT_STATUS_CONNECTION_REFUSED)","text":"<p>Make sure that the server has started. The shared directories should exist and be accessible.</p>"},{"location":"smb/#protocol-negotiation-failed-nt_status_connection_reset","title":"Protocol negotiation failed: NT_STATUS_CONNECTION_RESET","text":"<p>Probably the server is configured not to accept protocol SMB1. Add option  in . Or just pass argument  to .</p>"},{"location":"smb/#password-error-when-correct-credentials-are-given-error-1326","title":"Password Error when correct credentials are given (error 1326)","text":"<p>Samba 4.5 has NTLMv1 authentication disabled by default. It is recommend to install the latest available upgrades on clients and deny access for unsupported clients.</p> <p>If you still need support for very old clients without NTLMv2 support (e.g. Windows XP), it is possible force enable NTLMv1, although this is not recommend for security reasons:</p> <p>If NTLMv2 clients are unable to authenticate when NTLMv1 has been enabled, create the following file on the client: </p> <p>This change also affects samba shares mounted with mount.cifs. If after upgrade to Samba 4.5 your mount fails, add the sec=ntlmssp option to your mount command, e.g.</p> <p><code>mount.cifs\u00a0//server/share\u00a0/mnt/point\u00a0-o\u00a0sec=ntlmssp,...</code></p> <p>See the  man page: ntlmssp - Use NTLMv2 password hashing encapsulated in Raw NTLMSSP message. The default in mainline kernel versions prior to v3.8 was sec=ntlm. In v3.8, the default was changed to sec=ntlmssp.</p>"},{"location":"smb/#mapping-reserved-windows-characters","title":"Mapping reserved Windows characters","text":"<p>Starting with kernel 3.18, the cifs module uses the \"mapposix\" option by default. When mounting a share using unix extensions and a default Samba configuration, files and directories containing one of the seven reserved Windows characters  are listed but cannot be accessed.</p> <p>Possible solutions are:</p> <ul> <li>Use the undocumented  mount option for cifs</li> </ul> <p><code>#\u00a0mount.cifs\u00a0//server/share\u00a0/mnt/point\u00a0-o\u00a0nomapposix</code></p> <ul> <li>Configure Samba to remap  (\"SFM\", Services for Mac) style characters   to the correct native ones using   fruit</li> </ul> <ul> <li>Manually remap forbidden characters using   catia</li> </ul> <p>The latter approach (using catia or fruit) has the drawback of filtering files with unprintable characters.</p>"},{"location":"smb/#folder-shared-inside-graphical-environment-is-not-available-to-guests","title":"Folder shared inside graphical environment is not available to guests","text":"<p>This section presupposes:</p> <ol> <li>Usershares are configured following previous    section</li> <li>A shared folder has been created as a non-root user from GUI</li> <li>Guests access has been set to shared folder during creation</li> <li>Samba service has been restarted at least once since last  file    modification</li> </ol> <p>For clarification purpose only, in the following sub-sections is assumed:</p> <ul> <li>Shared folder is located inside user home directory path ()</li> <li>Shared folder name is MySharedFiles</li> <li>Guest access is read-only.</li> <li>Windows users will access shared folder content without login prompt</li> </ul>"},{"location":"smb/#verify-correct-samba-configuration","title":"Verify correct samba configuration","text":"<p>Run the following command from a terminal to test configuration file correctness:</p> <p><code>$\u00a0testparm</code></p>"},{"location":"smb/#verify-correct-shared-folder-creation","title":"Verify correct shared folder creation","text":"<p>Run the following commands from a terminal:</p> <p><code>$\u00a0cd\u00a0/var/lib/samba/usershares</code> <code>$\u00a0ls</code></p> <p>If everything is fine, you will notice a file named </p> <p>Read the file contents using the following command:</p> <p><code>$\u00a0cat\u00a0mysharedfiles</code></p> <p>The terminal output should display something like this:</p>"},{"location":"smb/#verify-folder-access-by-guest","title":"Verify folder access by guest","text":"<p>Run the following command from a terminal. If prompted for a password, just press Enter:</p> <p><code>$\u00a0smbclient\u00a0-L\u00a0localhost</code></p> <p>If everything is fine, MySharedFiles should be displayed under  column</p> <p>Run the following command in order to access the shared folder as guest (anonymous login)</p> <p><code>$\u00a0smbclient\u00a0-N\u00a0//localhost/MySharedFiles</code></p> <p>If everything is fine samba client prompt will be displayed:</p> <p><code>smb:\u00a0\\&gt;</code></p> <p>From samba prompt verify guest can list directory contents:</p> <p><code>smb:\u00a0\\&gt;\u00a0ls</code></p> <p>If the  error is displayed, the issue is likely to be with Unix directory permissions. Ensure that your samba user has access to the folder and all parent folders. You can test this by sudoing to the user and attempting to list the mount directory, and all of its parents.</p>"},{"location":"smb/#mount-error-host-is-down","title":"Mount error: Host is down","text":"<p>This error might be seen when mounting shares of Synology NAS servers. Use the mount option  to solve it.</p>"},{"location":"smb/#software-caused-connection-abort","title":"Software caused connection abort","text":"<p>File managers that utilizes  can show the error  when writing a file to a share/server. This may be due to the server running SMB/CIFS version 1, which many routers use for USB drive sharing (e.g. Belkin routers). To write to these shares specify the CIFS version with the option . E.g.:</p> <p>This can also happen after updating Samba to version 4.11, which deactivates SMB1 as default, and accessing any Samba share. You can reenable it by adding</p>"},{"location":"smb/#connection-problem-due-to-authentification-error","title":"Connection problem (due to authentification error)","text":"<p>Be sure that you do not leave any space characters before your username in Samba client configuration file as follows:</p> <p>The correct format is:</p>"},{"location":"smb/#windows-1709-or-up-does-not-discover-the-samba-server-in-network-view","title":"Windows 1709 or up does not discover the samba server in Network view","text":"<p>With Windows 10 version 1511, support for SMBv1 and thus NetBIOS device discovery was disabled by default. Depending on the actual edition, later versions of Windows starting from version 1709 (\"Fall Creators Update\") do not allow the installation of the SMBv1 client anymore. This causes hosts running Samba not to be listed in the Explorer's \"Network (Neighborhood)\" views. While there is no connectivity problem and Samba will still run fine, users might want to have their Samba hosts to be listed by Windows automatically.  implements a Web Service Discovery host daemon. This enables (Samba) hosts, like your local NAS device, to be found by Web Service Discovery Clients like Windows. The default settings should work for most installations, all you need to do is start enable .</p> <p>If the default configuration (advertise itself as the machine hostname in group \"WORKGROUP\") should be all you need in most cases. If you need, you can change configuration options by passing additional arguments to wsdd by adding them in  (see the manual page for wsdd for details).</p> <p>does the same thing, but is written in C instead of Python. By default, it will look for the  and  values in .</p>"},{"location":"smb/#ios-files-can-no-longer-copy-to-samba-share-on-arch-linux-beginning-with-ios-145","title":"IOS Files can no longer copy-to Samba share on Arch Linux beginning with IOS 14.5","text":"<p>Beginning with IOS 14.5 attempting to transfer from a device running IOS using the \"Files\" app to a samba share on Arch Linux will result in the error:</p> <p><code>The\u00a0operation\u00a0couldn't\u00a0be\u00a0completed</code> <code>Operation\u00a0canceled</code></p> <p>To correct this problem, add add the following to the global section of your  and restart . Comment optional:</p> <p><code>##\u00a0addition\u00a0for\u00a0IOS\u00a0Files\u00a0transfer-to\u00a0server</code> <code>vfs\u00a0object\u00a0=\u00a0fruit\u00a0streams_xattr</code></p> <p>See https://apple.stackexchange.com/q/424681 Apple.Stackexchange.com - \"The operation couldn't be completed\"/\"Operation canceled\" error message when saving to a Samba share via Files app.</p>"},{"location":"smb/#slow-initial-connections-from-certain-clients-without-other-performance-problems","title":"Slow initial connections from certain clients without other performance problems","text":"<p>Some SMB clients, such as Solid Explorer for Android, take significantly longer to connect to Samba if they fail to resolve the NetBIOS name. Enabling  will greatly speed up initial connections if this is the case. Since this is a bug in the client software, please report such cases to the authors of conflicting software.</p>"},{"location":"smb/#see-also","title":"See also","text":"<ul> <li>Official website</li> <li>Samba: An   Introduction</li> <li>Samba 3.2.x HOWTO and Reference   Guide   (outdated but still most extensive documentation)</li> <li>Wikipedia</li> <li>Gentoo:Samba/Guide</li> <li>Debian:Samba/ServerSimple</li> <li>KSMBD - A   linux kernel server which implements SMB3 protocol in kernel space   for sharing files over network.</li> </ul> <p>Category:Network sharing Category:Servers</p>"},{"location":"smb2/","title":"Samba","text":"<p>This document describes how to mount CIFS shares permanently. The shares might be hosted on a Windows computer/server, or on a Linux/UNIX server running Samba. This document also applies to SMBFS shares, which are similar to CIFS but are deprecated and should be avoided if possible (link).</p> <p>(This document does not describe how to host the shares yourself, only how to access shares that are hosted somewhere else. For hosting shares, use Samba.)</p>"},{"location":"smb2/#prerequisites","title":"Prerequisites","text":"<p>We're assuming that:</p> <p>-\u00a0Network\u00a0connections\u00a0have\u00a0been\u00a0configured\u00a0properly. -\u00a0Your\u00a0local\u00a0(Ubuntu)\u00a0username\u00a0is\u00a0<code>ubuntuusername</code>. -\u00a0Share\u00a0username\u00a0on\u00a0Windows\u00a0computer\u00a0is\u00a0<code>msusername</code>. -\u00a0Share\u00a0password\u00a0on\u00a0Windows\u00a0computer\u00a0is\u00a0<code>mspassword</code>. -\u00a0The\u00a0Windows\u00a0computer's\u00a0name\u00a0is\u00a0<code>servername</code> this\u00a0can\u00a0be\u00a0either\u00a0an\u00a0IP\u00a0address\u00a0or\u00a0an\u00a0assigned\u00a0name). -\u00a0The\u00a0name\u00a0of\u00a0the\u00a0share\u00a0is\u00a0<code>sharename</code>. -\u00a0You\u00a0want\u00a0to\u00a0mount\u00a0the\u00a0share\u00a0in\u00a0<code>/media/windowsshare</code>.</p>"},{"location":"smb2/#cifs-installation","title":"CIFS installation","text":"<p>On older systems:</p>"},{"location":"smb2/#mounting-unprotected-guest-network-folders","title":"Mounting unprotected (guest) network folders","text":"<p>First, let's create the mount directory. You will need a separate directory for each mount. </p> <p>Then edit your /etc/fstab file (with root privileges) to add this line: </p> <p>Where</p> <p>-\u00a0guest\u00a0indicates\u00a0you\u00a0don't\u00a0need\u00a0a\u00a0password\u00a0to\u00a0access\u00a0the\u00a0share, -\u00a0uid=1000\u00a0makes\u00a0the\u00a0Linux\u00a0user\u00a0specified\u00a0by\u00a0the\u00a0id\u00a0the\u00a0owner\u00a0of\u00a0the\u00a0mounted\u00a0share,\u00a0allowing\u00a0them\u00a0to\u00a0rename\u00a0files, -\u00a0iocharset=utf8\u00a0allows\u00a0access\u00a0to\u00a0files\u00a0with\u00a0names\u00a0in\u00a0non-English\u00a0languages.\u00a0This\u00a0doesn't\u00a0work\u00a0with\u00a0shares\u00a0of\u00a0devices\u00a0like\u00a0the\u00a0Buffalo\u00a0Tera\u00a0Station,\u00a0or\u00a0Windows\u00a0machines\u00a0that\u00a0export\u00a0their\u00a0shares\u00a0using\u00a0ISO8895-15. -\u00a0If\u00a0there\u00a0is\u00a0any\u00a0space in the server path,\u00a0you\u00a0need\u00a0to\u00a0replace\u00a0it\u00a0by\u00a0\\040,\u00a0for\u00a0example\u00a0//servername/My\\040Documents`</p> <p>After you add the entry to /etc/fstab type:  This will (re)mount all entries listed in /etc/fstab.</p>"},{"location":"smb2/#mount-password-protected-network-folders","title":"Mount password protected network folders","text":"<p>The quickest way to auto-mounting a password-protected share is to edit /etc/fstab (with root privileges), to add this line: </p> <p>This is not a good idea however: /etc/fstab is readable by everyone and so is your Windows password in it. The way around this is to use a credentials file. This is a file that contains just the username and password.</p> <p>Using a text editor, create a file for your remote servers logon credential:</p> <p>Enter your Windows username and password in the file:</p> <p>Save the file, exit the editor.</p> <p>Change the permissions of the file to prevent unwanted access to your credentials:</p> <p>Then edit your /etc/fstab file (with root privileges) to add this line (replacing the insecure line in the example above, if you added it):</p> <p>Save the file, exit the editor.</p> <p>Finally, test the fstab entry by issuing:</p> <p>If there are no errors, you should test how it works after a reboot. Your remote share should mount automatically.</p>"},{"location":"smb2/#special-permissions","title":"Special permissions","text":"<p>If you need special permission (like chmod etc.), you'll need to add a uid (short for 'user id') or gid (for 'group id') parameter to the share's mount options.</p>"},{"location":"smb2/#mount-password-protected-shares-using-libpam_mount-ubuntu-904","title":"Mount password protected shares using libpam_mount (Ubuntu 9.04)","text":"<p>In addition to the initial assumptions, we're assuming that</p> <p>-\u00a0Your username and password are the same on the Ubuntu machine and on the network drive.</p> <p>Install libpam-mount: </p> <p>Edit /etc/security/pam_mount.conf.xml using your preferred text editor.</p> <p>First, we're moving the user specific config bits to a file which users can actually edit themselves: remove the commenting tags ( ) surrounding the section called . Save the file when done. With this in place, users can create their own \\~/.pam_mount.conf.xml.</p> <p>Add the following:</p>"},{"location":"smb2/#troubleshooting","title":"Troubleshooting","text":""},{"location":"smb2/#login-errors","title":"Login errors","text":"<p>If you get the error \"mount error(13) permission denied\", then the server denied your access. Here are the first things to check:</p> <p>-\u00a0Are\u00a0you\u00a0using\u00a0a\u00a0valid\u00a0username\u00a0and\u00a0password?\u00a0Does\u00a0that\u00a0account\u00a0really\u00a0have\u00a0access\u00a0to\u00a0this\u00a0folder? -\u00a0Do\u00a0you\u00a0have\u00a0whitespace\u00a0in\u00a0your\u00a0credentials\u00a0file?\u00a0It\u00a0should\u00a0be\u00a0<code>,\u00a0not</code>. -\u00a0Do\u00a0you\u00a0need\u00a0a\u00a0domain?\u00a0For\u00a0example,\u00a0if\u00a0you\u00a0are\u00a0told\u00a0that\u00a0your\u00a0username\u00a0is\u00a0<code>,\u00a0then\u00a0actually\u00a0your\u00a0username\u00a0is</code>\u00a0and\u00a0your\u00a0domain\u00a0is\u00a0<code>.\u00a0The\u00a0fstab\u00a0entry\u00a0should\u00a0read:</code>\u00a0Or: -\u00a0The\u00a0security\u00a0and\u00a0version\u00a0settings\u00a0are\u00a0interrelated.\u00a0SMB1\u00a0is\u00a0insecure\u00a0and\u00a0no\u00a0longer\u00a0supported\u00a0by\u00a0default.\u00a0At\u00a0first,\u00a0try\u00a0to\u00a0not\u00a0specify\u00a0either\u00a0security\u00a0or\u00a0version:\u00a0do\u00a0not\u00a0specify\u00a0<code>or</code>.\u00a0If\u00a0you\u00a0still\u00a0have\u00a0authentication\u00a0errors\u00a0then\u00a0you\u00a0may\u00a0need\u00a0to\u00a0specify\u00a0either\u00a0<code>or</code>\u00a0or\u00a0both.\u00a0You\u00a0can\u00a0try\u00a0the\u00a0options\u00a0listed\u00a0at\u00a0the\u00a0<code>[</code>mount.cifs<code></code>man<code></code>page<code>](http://manpages.ubuntu.com/manpages/raring/en/man8/mount.cifs.8.html \"wikilink\")</code>.\u00a0The\u00a0man\u00a0page\u00a0list\u00a0leaves\u00a0out\u00a0the\u00a0option\u00a0<code>for\u00a0some\u00a0reason,\u00a0but\u00a0you\u00a0should\u00a0try\u00a0that\u00a0one\u00a0as\u00a0well\u00a0(`[`see</code> <code>`discussion</code>](https://bugs.launchpad.net/ubuntu/+source/cifs-utils/+bug/1113395 \"wikilink\")<code>).</code></p>"},{"location":"smb2/#unprotected-network-folder-wont-automount","title":"Unprotected network folder won't automount","text":"<p>I've had a situation where an unprotected network folder wouldn't automount during bootup, but after manually entering \"sudo mount -a\" was mounted correctly. I solved this by replacing the \"guest\" option by \"username=guest,password=\". If anyone has an explanation for this, please leave a comment.</p>"},{"location":"smb2/#mount-during-login-instead-of-boot","title":"Mount during login instead of boot","text":"<p>If for some reason/etc/rc0.d/S31umountnfs.sh (networking problems for example) the automatic mounting during boot doesn't work, you can add the \"noauto\" parameter to your smbfs fstab entry and then have the share mounted at login.</p> <p>In /etc/fstab: </p> <p>In /etc/rc.local: </p>"},{"location":"smb2/#slow-shutdown-due-to-a-cifsnetwork-manager-bug","title":"Slow shutdown due to a CIFS/Network Manager bug","text":"<p>If you use Network Manager, and are getting really slow shutdowns, it's probably because NM shuts down before unmounting the network shares. That will cause CIFS to hang and wait for 60 seconds or so. Here's how to fix it:/etc/rc0.d/S31umountnfs.sh</p> <p>Ubuntu 12.04 already runs umountnfs.sh at reboot and shutdown by default (/etc/rc0.d/S31umountnfs.sh and /etc/rc6.d/S31umountnfs.sh) so this is no longer necessary.</p>"},{"location":"smb2/#cifs-options-deprecated","title":"CIFS Options Deprecated","text":"<p>20 Feb 2008 TW</p> <p>Using dmask or fmask in the fstab file produces the following warnings: WARNING: CIFS mount option 'dmask' is deprecated. Use 'dir_mode' instead. WARNING: CIFS mount option 'fmask' is deprecated. Use 'file_mode' instead.</p> <p>Instead use this format: file_mode=0777,dir_mode=0777 . Or in some cases you might need to use file_mode=0777,dir_mode=0777,nounix (see discussion)</p>"},{"location":"smb2/#use-of-tilde-in-pathnames-such-as-credentialssmbcredentials","title":"\\== Use of tilde in pathnames such as \"credentials=\\~/.smbcredentials\"","text":"<p>20 Feb 2008 TW</p> <p>Curiously, using credentials=\\~/.smbcredentials in fstab didn't work. I had to use the full path, i.e. /home/username/.smbcredentials</p> <p>(This is likely because the tilde \"\\~\" is only a shell short-hand alias for \"$HOME\"; it isn't something recognized system-wide by all programs, especially not in a system file table where the concept of \"HOME\" doesn't really exist. -Ian!)</p> <p>CategoryDocumentation</p>"},{"location":"softwarearchitecture/","title":"software architecture","text":"<p>Software   Architecture:   The Hard Parts Modern Trade-Off Analyses for Distributed  Architectures</p>"},{"location":"softwarearchitecture/#introduction","title":"Introduction","text":"<p>There are no easy decisions in software architecture. Instead, there are many hard parts -- difficult problems or issues with no best practices -- that force you to choose among various compromises. The best design an architect can create is the least worst collection of trade-offs -- no single architecture characteristic excels as it would alone, but the balance of all the competing architecture characteristics promote project success.</p>"},{"location":"softwarearchitecture/#the-importance-of-data-in-architecture","title":"The Importance of Data in Architecture","text":"<p>It has been said that data is the most important asset in a company. Businesses want to extract value from the data that they have and are finding new ways to deploy data in decision making.</p> <ul> <li> <p>Operational data</p> <p>Data that is used to run the business. This data is defined as Online Transactional Processing (OLTP) data. Involves Create, Read, Update, Delete (CRUD) operations.</p> </li> <li> <p>Analytical data</p> <p>Data that is used to analyze the business. This data is defined as Online Analytical Processing (OLAP) data. Involves Read operations.</p> </li> </ul>"},{"location":"softwarearchitecture/#architectural-decisions-records","title":"Architectural Decisions Records","text":"<p>ADR: A short noun phrase containing the architecture decision</p> <p>Context In this section of the ADR we will add a short one- or two-sentence description of the problem, and list the alternative solutions.</p> <p>Decision In this section we will state the architecture decision and provide a detailed justification of the decision.</p> <p>Consequences In this section of the ADR we will describe any consequences after the decision is applied, and also discuss the trade-offs that were considered.</p>"},{"location":"sprint/","title":"sprint","text":""},{"location":"sprint/#s3","title":"s3","text":""},{"location":"sprint/#vegfru","title":"VegFru","text":"<pre><code>25 classes\n</code></pre>"},{"location":"sprint/#s4","title":"S4","text":"<pre><code>full datasets: time, results torch/tf\ncustom data training: duration\nobj det\ncoco\nyolox\n</code></pre>"},{"location":"sprint/#s5","title":"s5","text":"<pre><code>doc\n</code></pre>"},{"location":"ssh/","title":"ssh","text":"<pre><code>sudo pacman -S openssh\nsudo systemctl enable --now sshd\n</code></pre> <p>If the username on your local machine matches the one on the server you are trying to connect to, you can just type: ssh host_ip_address And hit Enter.</p> <pre><code>ssh your_username@host_ip_address\n</code></pre> <p>To open SSH port on Manjaro, you can follow these steps 1:</p> <p>Make sure sshd (ssh daemon) is active and listening to incoming connections on the computer you are trying to access: systemctl status sshd If it\u2019s inactive, start it using: systemctl start sshd To automatically start it on boot: systemctl enable sshd</p> <p>Also allow incoming connections in your firewall.</p> <pre><code>ssh-keygen -t rsa -b 2048\n</code></pre> <p>Generating public/private rsa key pair. Enter file in which to save the key (/home/username/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/username/.ssh/id_rsa. Your public key has been saved in /home/username/.ssh/id_rsa.pub.</p> <pre><code>$ ssh-copy-id id@server\nid@server's password:\n</code></pre>"},{"location":"stable_diffusion/","title":"stable diffusion","text":""},{"location":"stable_diffusion/#negative-prompt","title":"negative prompt","text":"<p>\"longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality\"</p>"},{"location":"stable_diffusion/#examples","title":"Examples","text":"Source Input Output (no preprocessor) (no preprocessor)"},{"location":"sway/","title":"sway","text":"<p>You may combine output commands into one, like so:</p> <pre><code>output HDMI-A-1 mode 1920x1080 pos 1920 0 bg ~/wallpaper.png stretch\n</code></pre> <p>You can get a list of output names with swaymsg -t get_outputs. You may also match any output by using the output name \"*\". Additionally, \"-\" can be used to match the focused output by name and \"--\" can be used to match the focused output by its identifier.</p> <p>Some outputs may have different names when disconnecting and reconnecting. To identify these, the name can be substituted for a string consisting of the make, model and serial which you can get from swaymsg -t get_outputs. Each value must be separated by one space. For example:</p> <pre><code>output \"Some Company ABC123 0x00000000\" pos 1920 0\n</code></pre> <pre><code>swaymsg -t get_outputs\n</code></pre>"},{"location":"sway/#output-moderesolutionres-custom-hz","title":"output  mode|resolution|res [--custom] [@[Hz]] <pre><code>Configures the specified output to use the given mode. Modes are a combination of\nwidth and height (in pixels) and a refresh rate that your display can be configured to\nuse. For a list of available modes for each output, use swaymsg -t get_outputs.\n\nTo set a custom mode not listed in the list of available modes, use --custom. You\nshould probably only use this if you know what you're doing.\n\nExamples:\n\n    output HDMI-A-1 mode 1920x1080\n\n    output HDMI-A-1 mode 1920x1080@60Hz\n</code></pre>","text":""},{"location":"sway/#output-positionpos","title":"output  position|pos   <pre><code>Places the specified output at the specific position in the global coordinate space.\nThe cursor may only be moved between immediately adjacent outputs. If scaling is\nactive, it has to be considered when positioning. For example, if the scaling factor\nfor the left output is 2, the relative position for the right output has to be divided\nby 2.  The reference point is the top left corner so if you want the bottoms aligned\nthis has to be considered as well.\n\nExample:\n\n    output HDMI1 scale 2\n\n    output HDMI1 pos 0 1020 res 3200x1800\n\n    output eDP1 pos 1600 0 res 1920x1080\n\nNote that the left x-pos of eDP1 is 1600 = 3200/2 and the bottom y-pos is 1020 + (1800\n/ 2) = 1920 = 0 + 1920\n</code></pre>","text":""},{"location":"sway/#output-scale","title":"output  scale  <pre><code>Scales the specified output by the specified scale factor. An integer is recommended,\nbut fractional values are also supported. If a fractional value are specified, be\nwarned that it is not possible to faithfully represent the contents of your windows -\nthey will be rendered at the next highest integer scale factor and downscaled. You may\nbe better served by setting an integer scale factor and adjusting the font size of\nyour applications to taste. HiDPI isn't supported with Xwayland clients (windows will\nblur).\n</code></pre>","text":""},{"location":"sway/#output-scale_filter-linearnearestsmart","title":"output  scale_filter linear|nearest|smart <pre><code>Indicates how to scale application buffers that are rendered at a scale lower than the\noutput's configured scale, such as lo-dpi applications on hi-dpi screens. Linear is\nsmoother and blurrier, nearest (also known as nearest neighbor) is sharper and\nblockier. Setting \"smart\" will apply nearest scaling when the output has an integer\nscale factor, otherwise linear. The default is \"smart\".\n</code></pre>","text":""},{"location":"sway/#output-subpixel-rgbbgrvrgbvbgrnone","title":"output  subpixel rgb|bgr|vrgb|vbgr|none <pre><code>Manually sets the subpixel hinting for the specified output. This value is usually\nauto-detected, but some displays may misreport their subpixel geometry. Using the\ncorrect subpixel hinting allows for sharper text.  Incorrect values will result in\nblurrier text. When changing this via swaymsg, some applications may need to be\nrestarted to use the new value.\n</code></pre>","text":""},{"location":"sway/#output-backgroundbg","title":"output  background|bg   [] <pre><code>Sets the wallpaper for the given output to the specified file, using the given scaling\nmode (one of \"stretch\", \"fill\", \"fit\", \"center\", \"tile\"). If the specified file cannot\nbe accessed or if the image does fill the entire output, a fallback color may be\nprovided to cover the rest of the output.  fallback_color should be specified as\n#RRGGBB. Alpha is not supported.\n</code></pre>","text":""},{"location":"sway/#output-backgroundbg-solid_color","title":"output  background|bg  solid_color <pre><code>Sets the background of the given output to the specified color. color should be\nspecified as #RRGGBB. Alpha is not supported.\n</code></pre>","text":""},{"location":"sway/#output-transform-clockwiseanticlockwise","title":"output  transform  [clockwise|anticlockwise] <pre><code>Sets the background transform to the given value. Can be one of \"90\", \"180\", \"270\" for\nrotation; or \"flipped\", \"flipped-90\", \"flipped-180\", \"flipped-270\" to apply a rotation\nand flip, or \"normal\" to apply no transform. If a single output is chosen and a\nrotation direction is specified (clockwise or anticlockwise) then the transform is\nadded or subtracted from the current transform.\n</code></pre>","text":""},{"location":"sway/#output-disableenable","title":"output  disable|enable <pre><code>Enables or disables the specified output (all outputs are enabled by default).\n</code></pre>","text":""},{"location":"sway/#output-toggle","title":"output  toggle <pre><code>Toggle the specified output.\n</code></pre>","text":""},{"location":"sway/#output-dpms-onoff","title":"output  dpms on|off <pre><code>Enables or disables the specified output via DPMS. To turn an output off (ie. blank\nthe screen but keep workspaces as-is), one can set DPMS to off.\n</code></pre>","text":""},{"location":"sway/#output-max_render_time-off","title":"output  max_render_time off| <pre><code>When set to a positive number of milliseconds, enables delaying output rendering to\nreduce latency. The rendering is delayed in such a way as to leave the specified\nnumber of milliseconds before the next presentation for rendering.\n\nThe output rendering normally takes place immediately after a presentation (vblank,\nbuffer flip, etc.) and the frame callbacks are sent to surfaces immediately after the\nrendering to give surfaces the most time to draw their next frame. This results in\nslightly below 2 frames of latency between the surface rendering and committing new\ncontents, and the contents being shown on screen, on average. When the output\nrendering is delayed, the frame callbacks are sent immediately after presentation, and\nthe surfaces have a small timespan (1 / (refresh rate) - max_render_time) to render\nand commit new contents to be shown on the next presentation, resulting in below 1\nframe of latency.\n\nTo set this up for optimal latency:\n1.   Launch some full-screen application that renders continuously, like glxgears.\n2.   Start with max_render_time 1. Increment by 1 if you see frame drops.\n\nTo achieve even lower latency, see the max_render_time surface property in sway(5).\n\nNote that this property has an effect only on backends which report the presentation\ntimestamp and the predicted output refresh rate\u2014the DRM and the Wayland backends.\nFurthermore, under the Wayland backend the optimal max_render_time value may vary\nbased on the parent compositor rendering timings.\n</code></pre> <p>.config/sway/config.d/output.conf</p> <pre><code>output DP-1 resolution 3440x1440@144Hz position 0,0 adaptive_sync off\noutput DP-4 resolution 2560x1440@59.951Hz transform 270 position 3440,0\n</code></pre> <p>.config/sway/definitions.d/custom.conf</p> <pre><code>set $idle_timeout 240\nset $locking_timeout 1200\nset $screen_timeout 1200\nset $swayidle swayidle -w \\\n    timeout $idle_timeout 'light -G &gt; /tmp/brightness &amp;&amp; light -S 10' resume 'light -S $([ -f /tmp/brightness ] &amp;&amp; cat /tmp/brightness || echo 100%)' \\\n    timeout $locking_timeout 'exec $locking' \\\n    timeout $screen_timeout 'swaymsg \"output * dpms off\"' \\\n    resume 'swaymsg \"output * dpms on\"' \\\n    before-sleep 'playerctl pause' \\\n    before-sleep 'exec $locking'\n</code></pre> <p><code>.config/waybar/config.jsonc</code></p> <pre><code>// =============================================================================\n//\n// Waybar configuration\n//\n// Configuration reference: https://github.com/Alexays/Waybar/wiki/Configuration\n//\n// =============================================================================\n\n{\n    \"include\": [\n        \"/usr/share/sway/templates/waybar/config.jsonc\"\n    ],\n    // -------------------------------------------------------------------------\n    // Global configuration\n    // -------------------------------------------------------------------------\n\n    \"layer\": \"top\",\n\n    // If height property would be not present, it'd be calculated dynamically\n    \"height\": 30,\n    \"position\": \"top\",\n\n    \"modules-left\": [\"custom/menu\", \"sway/workspaces\", \"custom/scratchpad\"],\n    \"modules-center\": [\"custom/wf-recorder\", \"sway/mode\", \"custom/weather\"],\n    \"modules-right\": [\n        // informational\n        \"sway/language\",\n        \"custom/github\",\n        \"custom/clipboard\",\n        \"custom/zeit\",\n        \"cpu\",\n        \"memory\",\n        \"battery\",\n        \"temperature\",\n\n        // connecting\n        \"network\",\n        \"bluetooth\",\n\n        // media\n        \"custom/playerctl\",\n        \"idle_inhibitor\",\n        \"custom/dnd\",\n        \"pulseaudio\",\n        \"backlight\",\n\n        // system\n        \"custom/adaptive-light\",\n        \"custom/sunset\",\n        \"custom/pacman\",\n\n        \"tray\",\n        \"clock\"\n    ],\n\n    // -------------------------------------------------------------------------\n    // Modules\n    // -------------------------------------------------------------------------\n\n    \"battery\": {\n        \"interval\": 30,\n        \"states\": {\n            \"warning\": 30,\n            \"critical\": 15\n        },\n        \"format-charging\": \"\uf583 {capacity}%\",\n        \"format\": \"{icon} {capacity}%\",\n        \"format-icons\": [\"\uf582\", \"\uf579\", \"\uf57a\", \"\uf57d\", \"\uf57f\", \"\uf578\"],\n        \"tooltip\": true\n    },\n\n    \"clock\": {\n        \"interval\": 60,\n        \"format\": \"{:%e %b %Y %H:%M}\",\n        \"tooltip\": true,\n        \"tooltip-format\": \"&lt;big&gt;{:%B %Y}&lt;/big&gt;\\n&lt;tt&gt;{calendar}&lt;/tt&gt;\",\n        \"on-click\": \"swaymsg exec \\\\$calendar\"\n    },\n\n    \"cpu\": {\n        \"interval\": 5,\n        \"format\": \"\ufb19 {usage}%\",\n        \"states\": {\n            \"warning\": 70,\n            \"critical\": 90\n        },\n        \"on-click\": \"swaymsg exec \\\\$term_float htop\"\n    },\n\n    \"memory\": {\n        \"interval\": 5,\n        \"format\": \"\uf85a {}%\",\n        \"states\": {\n            \"warning\": 70,\n            \"critical\": 90\n        },\n        \"on-click\": \"swaymsg exec \\\\$term_float htop\"\n    },\n\n    \"network\": {\n        \"interval\": 5,\n        \"format-wifi\": \"\uf1eb \",\n        \"format-ethernet\": \"\uf6ff\",\n        \"format-disconnected\": \"\ufaa9\",\n        \"tooltip-format\": \"{ifname} ({essid}): {ipaddr}\",\n        \"on-click\": \"swaymsg exec \\\\$term_float nmtui\"\n    },\n\n    \"sway/mode\": {\n        \"format\": \"&lt;span style=\\\"italic\\\"&gt;{}&lt;/span&gt;\",\n        \"tooltip\": false\n    },\n\n    \"idle_inhibitor\": {\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"activated\": \"\uf9b2\",\n            \"deactivated\": \"\uf9b1\"\n        },\n        \"tooltip\": true,\n        \"tooltip-format-activated\": \"power-saving disabled\",\n        \"tooltip-format-deactivated\": \"power-saving enabled\"\n    },\n\n    \"backlight\": {\n        \"format\": \"{icon} {percent}%\",\n        \"format-icons\": [\"\uf5dd\", \"\uf5de\", \"\uf5df\"],\n        \"on-scroll-up\": \"swaymsg exec \\\\$brightness_up\",\n        \"on-scroll-down\": \"swaymsg exec \\\\$brightness_down\"\n    },\n\n    \"pulseaudio\": {\n        \"scroll-step\": 5,\n        \"format\": \"{icon} {volume}%{format_source}\",\n        \"format-muted\": \"\ufa80 {format_source}\",\n        \"format-source\": \"\",\n        \"format-source-muted\": \" \uf86c\",\n        \"format-icons\": {\n            \"headphone\": \"\uf7ca\",\n            \"headset\": \"\uf7cd\",\n            \"default\": [\"\ufa7e\", \"\ufa7f\", \"\ufa7d\"]\n        },\n        \"tooltip-format\": \"{icon}\u200a{volume}% {format_source}\",\n        \"on-click\": \"swaymsg exec \\\\$pulseaudio\",\n        \"on-click-middle\": \"swaymsg exec \\\\$volume_mute\",\n        \"on-scroll-up\": \"swaymsg exec \\\\$volume_up\",\n        \"on-scroll-down\": \"swaymsg exec \\\\$volume_down\"\n    },\n\n    \"temperature\": {\n        \"critical-threshold\": 90,\n        \"interval\": 5,\n        \"format\": \"{icon} {temperatureC}\u00b0\",\n        \"format-icons\": [\"\uf2cb\", \"\uf2c9\", \"\uf2c8\"],\n        \"tooltip\": false,\n        \"on-click\": \"swaymsg exec \\\"\\\\$term_float watch sensors\\\"\"\n    },\n\n    \"tray\": {\n        \"icon-size\": 21,\n        \"spacing\": 5\n    },\n\n    \"custom/pacman\": {\n        \"format\": \"\uf53b {}\",\n        \"interval\": 3600,\n        \"exec-if\": \"[ $(pamac checkupdates -q | wc -l) -gt 0 ]\",\n        \"exec\": \"pamac checkupdates -q | wc -l\",\n        \"on-click\": \"pamac-manager --updates; pkill -RTMIN+4 waybar\",\n        \"signal\": 4\n    },\n\n    \"custom/menu\": {\n        \"format\": \"\uf312\",\n        \"on-click\": \"swaymsg exec \\\\$menu\",\n        \"tooltip\": false\n    },\n\n    \"bluetooth\": {\n        \"format\": \"\uf5ae\",\n        \"format-disabled\": \"\uf5b1\",\n        \"on-click\": \"swaymsg exec \\\\$bluetooth\",\n        \"on-click-right\": \"rfkill toggle bluetooth\",\n        \"tooltip-format\": \"{}\"\n    },\n\n    \"sway/language\": {\n        \"format\": \"\uf11c {}\",\n        \"min-length\": 5,\n        \"tooltip\": false,\n        \"on-click\": \"swaymsg input $(swaymsg -t get_inputs --raw | jq '[.[] | select(.type == \\\"keyboard\\\")][0] | .identifier') xkb_switch_layout next\"\n    },\n\n    \"custom/scratchpad\": {\n        \"interval\": \"once\",\n        \"return-type\": \"json\",\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"one\": \"\ufaae\",\n            \"many\": \"\ufab1\"\n        },\n        \"exec\": \"/bin/sh /usr/share/sway/scripts/scratchpad.sh\",\n        \"on-click\": \"swaymsg 'scratchpad show'\",\n        \"signal\": 7\n    },\n\n    \"custom/sunset\": {\n        \"interval\": \"once\",\n        \"tooltip\": true,\n        \"return-type\": \"json\",\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"on\": \"\uf834\",\n            \"off\": \"\uf400\"\n        },\n        \"exec\": \"fallback_latitude=50.1 fallback_longitude=8.7 latitude= longitude= /usr/share/sway/scripts/sunset.sh\",\n        \"on-click\": \"/usr/share/sway/scripts/sunset.sh toggle; pkill -RTMIN+6 waybar\",\n        \"exec-if\": \"/usr/share/sway/scripts/sunset.sh check\",\n        \"signal\": 6\n    },\n\n    \"custom/wf-recorder\": {\n        \"interval\": \"once\",\n        \"return-type\": \"json\",\n        \"format\": \"{}\",\n        \"tooltip-format\": \"{tooltip}\",\n        \"exec\": \"echo '{\\\"class\\\": \\\"recording\\\",\\\"text\\\":\\\"\uf949\\\",\\\"tooltip\\\":\\\"press $mod+Esc to stop recording\\\"}'\",\n        \"exec-if\": \"pgrep wf-recorder\",\n        \"on-click\": \"killall -s SIGINT wf-recorder\",\n        \"signal\": 8\n    },\n\n    \"custom/github\": {\n        \"interval\": 300,\n        \"tooltip\": false,\n        \"return-type\": \"json\",\n        \"format\": \"\uf408 {}\",\n        \"exec\": \"gh api '/notifications' -q '{ text: length }' | cat -\",\n        \"exec-if\": \"[ -x \\\"$(command -v gh)\\\" ] &amp;&amp; gh auth status 2&gt;&amp;1 | grep -q -m 1 'Logged in' &amp;&amp; gh api '/notifications' -q 'length' | grep -q -m 1 '0' ; test $? -eq 1\",\n        \"on-click\": \"xdg-open https://github.com/notifications &amp;&amp; sleep 30 &amp;&amp; pkill -RTMIN+4 waybar\",\n        \"signal\": 4\n    },\n\n    \"custom/playerctl\": {\n        \"interval\": \"once\",\n        \"tooltip\": true,\n        \"return-type\": \"json\",\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"Playing\": \"\uf8e5\",\n            \"Paused\": \"\uf90c\"\n        },\n        \"exec\": \"playerctl metadata --format '{\\\"alt\\\": \\\"{{status}}\\\", \\\"tooltip\\\": \\\"{{playerName}}:  {{markup_escape(title)}} - {{markup_escape(artist)}}\\\" }'\",\n        \"on-click\": \"playerctl play-pause; pkill -RTMIN+5 waybar\",\n        \"on-click-right\": \"playerctl next; pkill -RTMIN+5 waybar\",\n        \"on-scroll-up\": \"playerctl position 10+; pkill -RTMIN+5 waybar\",\n        \"on-scroll-down\": \"playerctl position 10-; pkill -RTMIN+5 waybar\",\n        \"signal\": 5\n    },\n\n    \"custom/clipboard\": {\n        \"format\": \"\uf691\",\n        \"interval\": \"once\",\n        \"return-type\": \"json\",\n        \"on-click\": \"swaymsg -q exec '$clipboard'; pkill -RTMIN+9 waybar\",\n        \"on-click-right\": \"swaymsg -q exec '$clipboard-del'; pkill -RTMIN+9 waybar\",\n        \"on-click-middle\": \"rm -f ~/.cache/cliphist/db; pkill -RTMIN+9 waybar\",\n        \"exec\": \"printf '{\\\"tooltip\\\":\\\"%s\\\"}' $(cliphist list | wc -l)' item(s) in the clipboard\\r(Mid click to clear)'\",\n        \"exec-if\": \"[ -x \\\"$(command -v cliphist)\\\" ] &amp;&amp; [ $(cliphist list | wc -l) -gt 0 ]\",\n        \"signal\": 9\n    },\n\n    \"custom/weather\": {\n        \"icon-size\": 42,\n        \"format\": \"{icon} {}\",\n        \"tooltip\": true,\n        \"interval\": 3600,\n        // accepts -c/--city &lt;city&gt; -t/--temperature &lt;C/F&gt; -d/--distance &lt;km/miles&gt;\n        \"exec\": \"/usr/share/sway/scripts/weather.py -c sg\",\n        \"return-type\": \"json\",\n        \"format-icons\": {\n            \"Unknown\": \"\ue370\",\n            \"Cloudy\": \"\ufa8f\",\n            \"Fog\": \"\ue313\",\n            \"HeavyRain\": \"\ue318\",\n            \"HeavyShowers\": \"\ue319\",\n            \"HeavySnow\": \"\ue35e\",\n            \"HeavySnowShowers\": \"\ufc15\",\n            \"LightRain\": \"\ue306\",\n            \"LightShowers\": \"\ue309\",\n            \"LightSleet\": \"\ue3ad\",\n            \"LightSleetShowers\": \"\ue31a\",\n            \"LightSnow\": \"\ue31a\",\n            \"LightSnowShowers\": \"\ufb7d\",\n            \"PartlyCloudy\": \"\ue30c\",\n            \"Sunny\": \"\ue30d\",\n            \"ThunderyHeavyRain\": \"\ufb7c\",\n            \"ThunderyShowers\": \"\ue30e\",\n            \"ThunderySnowShowers\": \"\ue366\",\n            \"VeryCloudy\": \"\ue33d\"\n        }\n    },\n\n    \"custom/zeit\": {\n        \"return-type\": \"json\",\n        \"interval\": \"once\",\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"tracking\": \"\ufab4\",\n            \"stopped\": \"\uf236\"\n        },\n        \"exec\": \"/bin/sh /usr/share/sway/scripts/zeit.sh status\",\n        \"on-click\": \"/bin/sh /usr/share/sway/scripts/zeit.sh click; pkill -RTMIN+10 waybar\",\n        \"exec-if\": \"[ -x \\\"$(command -v zeit)\\\" ]\",\n        \"signal\": 10\n    },\n\n    \"custom/dnd\": {\n        \"interval\": \"once\",\n        \"return-type\": \"json\",\n        \"format\": \"{}{icon}\",\n        \"format-icons\": {\n            \"default\": \"\uf868\",\n            \"dnd\": \"\ufba1\"\n        },\n        \"on-click\": \"makoctl mode | grep 'do-not-disturb' &amp;&amp; makoctl mode -r do-not-disturb || makoctl mode -a do-not-disturb; pkill -RTMIN+11 waybar\",\n        \"on-click-right\": \"makoctl restore\",\n        \"exec\": \"printf '{\\\"alt\\\":\\\"%s\\\",\\\"tooltip\\\":\\\"mode: %s\\\"}' $(makoctl mode | grep -q 'do-not-disturb' &amp;&amp; echo dnd || echo default) $(makoctl mode | tail -1)\",\n        \"signal\": 11\n    },\n\n    \"custom/adaptive-light\": {\n        \"interval\": \"once\",\n        \"tooltip\": true,\n        \"return-type\": \"json\",\n        \"format\": \"{icon}\",\n        \"format-icons\": {\n            \"on\": \"\uf5e0\",\n            \"off\": \"\uf5df\"\n        },\n        \"exec\": \"/usr/share/sway/scripts/wluma.sh\",\n        \"on-click\": \"/usr/share/sway/scripts/wluma.sh toggle; pkill -RTMIN+12 waybar\",\n        \"exec-if\": \"/usr/share/sway/scripts/wluma.sh check\",\n        \"signal\": 12\n    }\n}\n\n</code></pre>","text":""},{"location":"time_travel/","title":"Time Travel","text":"<p>The first time travel machine was built in the past to replicate embedded state from the future into a stateless machine built in the past. The state machine have to account for errors during state transfer from the future and restore using error correction.</p>"},{"location":"time_travel/#the-first-time-travel","title":"The First Time Travel","text":"<p>The year was 2050, and humanity had finally cracked the code to time travel. But it wasn\u2019t what anyone had imagined. The invention of the first time travel machine wasn\u2019t born from a desire to explore the past or the future. Instead, it was born out of necessity\u2014a desperate attempt to fix a mistake that could unravel the very fabric of reality.</p> <p>Dr. Elara Voss, a brilliant but reclusive quantum physicist, had spent her entire career studying the nature of time. She believed that time wasn\u2019t a linear concept but a web of interconnected states, each existing in parallel dimensions. Her theory, known as the \"Echo Universe,\" proposed that every decision, every event, created a new universe, a new \"echo\" of reality.</p> <p>But when her team accidentally sent a stateless machine into the past, something went terribly wrong. The machine, designed to replicate embedded states from the future, began malfunctioning. It pulled not just data but entire fragments of reality from different timelines. The result was chaos. The past, present, and future began to collide, threatening to destroy the integrity of the timestream.</p>"},{"location":"time_travel/#the-machines-purpose","title":"The Machine's Purpose","text":"<p>The time travel machine was never meant to transport people. It was a state transfer device, designed to pull information from the future and embed it into the past. The idea was revolutionary\u2014humans could learn from their future selves, avoid mistakes, and create a utopian society. But the machine had one flaw: it couldn\u2019t account for human error.</p> <p>When the machine was activated for the first time, it pulled more than just data. It pulled fragments of consciousness, memories, and emotions from countless timelines. The team soon realized that the machine wasn\u2019t just transferring information\u2014it was merging realities.</p>"},{"location":"time_travel/#the-first-error","title":"The First Error","text":"<p>The first time the machine was used, it worked perfectly. It pulled a state from the future, embedded it into the past, and the present shifted accordingly. But the second time, something went wrong. The machine encountered an error during the state transfer, and instead of correcting it, it amplified the problem.</p> <p>The error was small at first\u2014a minor discrepancy in the timeline. But as the machine tried to correct it, the error grew. It began to ripple through time, causing bizarre occurrences. People from different timelines started appearing in the wrong eras. Events from the future began happening in the past. The team realized that the machine had created a rift, a tear in the fabric of time that threatened to consume everything.</p>"},{"location":"time_travel/#the-restoration","title":"The Restoration","text":"<p>The team raced against time to fix the machine. They knew that if they couldn\u2019t restore the timeline, the universe would collapse into chaos. The machine\u2019s error correction system was overwhelmed, unable to handle the sheer magnitude of the problem. The team had to think outside the box, combining their knowledge of quantum mechanics, artificial intelligence, and even philosophy to find a solution.</p> <p>They discovered that the machine could be used in reverse. Instead of pulling states from the future, it could push states into the future. The idea was to create a new timeline, one that would overwrite the damaged one. But there was a risk: the process could erase entire universes, including their own.</p>"},{"location":"time_travel/#the-sacrifice","title":"The Sacrifice","text":"<p>In the end, there was no other choice. The team activated the machine, sending a corrected state into the future. The rift began to close, and the timeline began to heal. But the cost was high. The machine, overloaded with energy, exploded in a blinding flash of light. When the light faded, the team was gone. The lab was destroyed, and the machine was nothing more than a pile of rubble.</p> <p>But the world was saved. The timeline was restored, and the timestream was intact. The machine had fulfilled its purpose, even if it meant sacrificing itself.</p>"},{"location":"time_travel/#the-legacy","title":"The Legacy","text":"<p>The invention of the time travel machine changed humanity forever. It proved that time was not just a linear concept but a complex web of possibilities. It also taught humans a valuable lesson: the power of time was not to be trifled with. The machine was never rebuilt, but its legacy lived on. It inspired a new generation of scientists, philosophers, and dreamers to explore the mysteries of time.</p> <p>And though the machine was gone, its impact remained. It reminded humanity that the future was not set in stone, and that every decision had the power to shape the universe.</p> <p>SEO Optimization for the Article: \"The First Time Travel Machine: A Journey Through Time\"</p>"},{"location":"time_travel/#keyword-research","title":"Keyword Research","text":"<ol> <li>Primary Keywords:</li> <li>\"Time travel\"</li> <li>\"Time travel machine\"</li> <li>\"First time travel\"</li> <li>\"State transfer\"</li> <li>\"Error correction in time travel\"</li> <li>\"Parallel universes\"</li> <li> <p>\"Quantum physics and time travel\"</p> </li> <li> <p>Secondary Keywords:</p> </li> <li>\"Time travel story\"</li> <li>\"Future technology\"</li> <li>\"Time machine invention\"</li> <li>\"Sci-fi time travel\"</li> <li>\"Time travel theories\"</li> <li>\"Dr. Elara Voss\"</li> <li> <p>\"Time travel and parallel universes\"</p> </li> <li> <p>Long-Tail Keywords:</p> </li> <li>\"How does time travel work?\"</li> <li>\"First time travel machine story\"</li> <li>\"Time travel and error correction\"</li> <li>\"The science behind time travel\"</li> <li>\"Time travel and parallel universes explained\"</li> </ol>"},{"location":"time_travel/#meta-title","title":"Meta Title","text":"<p>\"The First Time Travel Machine: A Journey Through Time | Sci-Fi Story\"</p>"},{"location":"time_travel/#meta-description","title":"Meta Description","text":"<p>\"Discover the fascinating story of humanity's first time travel machine. Learn how scientists navigated the challenges of state transfer, error correction, and parallel universes to save the timestream. A gripping sci-fi tale of innovation and sacrifice.\"</p>"},{"location":"time_travel/#header-tags","title":"Header Tags","text":"<ol> <li>H1: \"The First Time Travel Machine: A Journey Through Time\"</li> <li>H2: \"The First Time Travel Machine\"</li> <li>H2: \"The Machine's Purpose\"</li> <li>H2: \"The First Error\"</li> <li>H2: \"The Restoration\"</li> <li>H2: \"The Sacrifice\"</li> <li>H2: \"The Legacy\"</li> </ol>"},{"location":"time_travel/#image-alt-text","title":"Image Alt Text","text":"<ol> <li>\"Time travel machine activation\"</li> <li>\"Dr. Elara Voss working on the time machine\"</li> <li>\"Error correction system in time travel\"</li> <li>\"Parallel universes and time travel\"</li> <li>\"Time machine exploding to restore the timeline\"</li> </ol>"},{"location":"time_travel/#internal-linking","title":"Internal Linking","text":"<ol> <li>Link to articles about \"Theories of Time Travel\"</li> <li>Link to articles about \"Parallel Universes and Quantum Physics\"</li> <li>Link to articles about \"The Ethics of Time Travel\"</li> <li>Link to articles about \"The History of Quantum Mechanics\"</li> </ol>"},{"location":"time_travel/#content-optimization","title":"Content Optimization","text":"<ol> <li>Introduction: Highlight the uniqueness of the story, the invention of the first time travel machine, and its purpose.</li> <li>Body: Use keywords naturally within the content. Focus on explaining the science behind time travel, the challenges faced by Dr. Elara Voss and her team, and the consequences of their invention.</li> <li>Conclusion: Emphasize the legacy of the time travel machine and its impact on humanity.</li> </ol>"},{"location":"time_travel/#call-to-action-cta","title":"Call-to-Action (CTA)","text":"<p>\"Ready to dive deeper into the world of time travel? Explore more stories and theories about the science and ethics of time travel. Share your thoughts on the implications of this groundbreaking invention in the comments below!\"</p>"},{"location":"time_travel/#social-media-meta-tags","title":"Social Media Meta Tags","text":"<ol> <li>Twitter Card:</li> <li>Title: \"The First Time Travel Machine: A Journey Through Time\"</li> <li>Description: \"Discover the gripping sci-fi story of humanity's first time travel machine. Learn how scientists navigated the challenges of state transfer and parallel universes.\"</li> <li> <p>Hashtags: #TimeTravel #SciFi #QuantumPhysics #ParallelUniverses</p> </li> <li> <p>Facebook Meta Tags:</p> </li> <li>Title: \"The First Time Travel Machine: A Journey Through Time\"</li> <li>Description: \"Explore the fascinating story of the first time travel machine and its impact on humanity. A must-read for sci-fi fans and science enthusiasts!\"</li> <li>Hashtags: #TimeTravelStory #SciFiStory #QuantumPhysics</li> </ol>"},{"location":"time_travel/#structured-data-schema-markup","title":"Structured Data (Schema Markup)","text":"<pre><code>{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"Article\",\n  \"mainEntityOfPage\": {\n    \"@type\": \"WebPage\",\n    \"@id\": \"https://furyhawk.lol/time_travel/\"\n  },\n  \"headline\": \"The First Time Travel Machine: A Journey Through Time\",\n  \"image\": [\n    \"https://furyhawk.lol/time-machine-activation.jpg\"\n  ],\n  \"author\": {\n    \"@type\": \"Person\",\n    \"name\": \"furyhawk\"\n  },\n  \"publisher\": {\n    \"@type\": \"Organization\",\n    \"name\": \"Your Website Name\",\n    \"logo\": {\n      \"@type\": \"ImageObject\",\n      \"url\": \"https://furyhawk.lol/logo.jpg\"\n    }\n  },\n  \"datePublished\": \"2023-10-01\",\n  \"articleBody\": \"The first time travel machine was built in the past to replicate embedded state from the future into a stateless machine built in the past. The state machine had to account for errors during state transfer from the future and restore using error correction...\"\n}\n</code></pre> <p>This SEO strategy will help improve the article's visibility, ranking, and engagement on search engines and social media platforms.</p>"},{"location":"training_pipeline/","title":"Training pipeline","text":"<p>trainer.train</p> <p>trainer-stage train, valid, test</p> <p>dict_keys(['train_loss', 'valid_loss', 'valid_trues', 'valid_logits', 'valid_preds', 'valid_probs', 'valid_elapsed_time', 'val_MulticlassAccuracy', 'val_MulticlassPrecision', 'val_MulticlassRecall', 'val_MulticlassAUROC', 'val_MulticlassCalibrationError', ('val_MulticlassCalibrationError', 'train_loss')])</p> <p>python tools/train.py -f exps/example/custom/nano.py -d 1 -b 8 -c yolox_nano.pth</p>"},{"location":"venv/","title":"venv","text":"<pre><code>sudo apt install python3-venv\npython3 -m venv foobar\nsource foobar/bin/activate\ndeactivate\n</code></pre>"},{"location":"wandb/","title":"Weights &amp; Biases","text":"<p>Machine learning experiment tracking, dataset versioning, and model evaluation</p> <pre><code>import wandb\nfrom omegaconf import DictConfig\nimport pandas as pd\n\n\nclass WeightsAndBiases:\n    def __init__(self, cfg: DictConfig) -&gt; None:\n        self.cfg: DictConfig = cfg\n        if cfg.debug:\n            wandb.init(mode=\"disabled\")\n        else:\n            wandb.init(project=cfg.project, entity=\"peekingduck\", config=cfg)\n\n    def watch(self, model) -&gt; None:\n        wandb.watch(model)\n\n    def log(self, loss) -&gt; None:\n        wandb.log(loss)\n\n    def log_history(self, history) -&gt; None:\n        selected_history = {\n            key: history[key]\n            for key in [\n                \"train_loss\",\n                \"valid_loss\",\n                \"valid_elapsed_time\",\n                \"val_MulticlassAccuracy\",\n                \"val_MulticlassPrecision\",\n                \"val_MulticlassRecall\",\n                \"val_MulticlassAUROC\",\n            ]\n        }\n\n        df: pd.DataFrame = pd.DataFrame(selected_history)\n        for row_dict in df.to_dict(orient=\"records\"):\n            wandb.log(row_dict)\n\n    def log_training_loss(self, loss) -&gt; None:\n        wandb.log({\"train_loss\": loss})\n\n    def log_validation_loss(self, loss) -&gt; None:\n        wandb.log({\"val_loss\": loss})\n</code></pre> <p>Your personal account has 100 GB of free storage and artifacts.</p> <p>Usage Pricing Storage $0.08 per GB up to 10 TB $0.06 per GB up to 100 TB $0.05 per GB up to 1000 TB Over 1000 TB, contact us Artifact tracking $0.05 per GB up to 10 TB $0.03 per GB up to 100 TB $0.02 per GB up to 1000 TB Over 1000 TB, contact us</p> <p>One team, up to 10 users</p> <p>Email and chat support</p> <p>100 GB storage and artifacts tracking included. For additional storage, see prices.</p>"},{"location":"yolox/","title":"yolox","text":"<pre><code>python tools/train.py -f exps/example/custom/nano.py -d 1 -b 2 -c yolox_nano.pth\n</code></pre> <pre><code>2023-04-20 08:49:15.731 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 12.       98.56714 250.26144  70.88641   9.62624]\n2023-04-20 08:49:15.733 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 13.       130.93268  229.41734   91.643555  72.7481  ]\n2023-04-20 08:49:16 | INFO     | yolox.core.trainer:261 - epoch: 5/5, iter: 60/62, gpu mem: 0Mb, mem: 5.4Gb, iter_time: 3.179s, data_time: 2.856s, total_loss: 1.6, iou_loss: 0.6, l1_loss: 0.1, conf_loss: 0.4, cls_loss: 0.4, lr: 3.085e-04, size: 416, ETA: 0:00:06\n2023-04-20 08:49:18.890 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 58.       133.07756  166.66658    5.388448   4.927013]\n2023-04-20 08:49:18.890 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [  6.      138.9172  213.91843  94.45138 352.15067]\n2023-04-20 08:49:18.890 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [  4.      218.88423 140.31888 104.04545 165.01555]\n2023-04-20 08:49:18.891 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 44.      141.09167 260.7022  282.48337 301.27512]\n2023-04-20 08:49:18.893 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 14.       130.99757   47.066467  56.686657  20.449068]\n2023-04-20 08:49:18.895 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 64.       220.6489   303.2769   114.6341   102.452896]\n2023-04-20 08:49:18.895 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 61.       256.1682    55.158962  42.048447  45.89014 ]\n2023-04-20 08:49:18.895 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [24.       19.571447 57.297344 19.864103 34.632   ]\n2023-04-20 08:49:18.899 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 40.        178.63289   129.9869      7.916896    7.5660305]\n2023-04-20 08:49:18.901 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 66.      319.8782  183.105   111.56579 109.044  ]\n2023-04-20 08:49:18.901 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 54.      269.932   236.27823  85.54    143.03235]\n2023-04-20 08:49:18.901 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 49.      340.53177 187.7362  147.19244 134.72554]\n2023-04-20 08:49:18.903 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 69.      283.95578 123.04812 243.99066 180.18655]\n2023-04-20 08:49:18.904 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 26.       183.09532  116.72701   26.500448  15.249037]\n2023-04-20 08:49:18.904 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 12.       98.56714 250.26144  70.88641   9.62624]\n2023-04-20 08:49:18.905 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 13.       285.06732  229.41734   91.643555  72.7481  ]\n2023-04-20 08:49:22.045 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [  6.      138.0828  213.91843  94.45138 352.15067]\n2023-04-20 08:49:22.045 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 58.       282.92242  166.66658    5.388448   4.927013]\n2023-04-20 08:49:22.046 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 44.      242.90833 260.7022  282.48337 301.27512]\n2023-04-20 08:49:22.047 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [  4.      218.88423 140.31888 104.04545 165.01555]\n2023-04-20 08:49:22.049 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 14.       285.00244   47.066467  56.686657  20.449068]\n2023-04-20 08:49:22.050 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 64.       220.6489   303.2769   114.6341   102.452896]\n2023-04-20 08:49:22.050 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 24.       292.42856   57.297344  19.864103  34.632   ]\n2023-04-20 08:49:22.051 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 61.       159.83177   55.158962  42.048447  45.89014 ]\n2023-04-20 08:49:22.054 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 40.        237.36711   129.9869      7.916896    7.5660305]\n2023-04-20 08:49:22.056 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 49.       75.46822 187.7362  147.19244 134.72554]\n2023-04-20 08:49:22.056 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 54.      269.932   236.27823  85.54    143.03235]\n2023-04-20 08:49:22.058 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 69.      283.95578 123.04812 243.99066 180.18655]\n2023-04-20 08:49:22.059 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 26.       183.09532  116.72701   26.500448  15.249037]\n2023-04-20 08:49:22.060 | INFO     | yolox.data.datasets.mosaicdetection:__getitem__:161 - [ 13.       285.06732  229.41734   91.643555  72.7481  ]\n2023-04-20 08:49:22 | INFO     | yolox.core.trainer:364 - Save weights to ./YOLOX_outputs/nano\n  0%|          | 0/3 [00:00&lt;?, ?it/s]2023-04-20 08:49:23.548 | INFO     | yolox.data.datasets.coco:__getitem__:189 - [[0. 0. 0. 0. 0.]]\n2023-04-20 08:49:23.549 | INFO     | yolox.data.datasets.coco:__getitem__:189 - [[0. 0. 0. 0. 0.]]\n2023-04-20 08:49:23.552 | INFO     | yolox.data.datasets.coco:__getitem__:189 - [[0. 0. 0. 0. 0.]]\n2023-04-20 08:49:23.557 | INFO     | yolox.data.datasets.coco:__getitem__:189 - [[0. 0. 0. 0. 0.]]\n2023-04-20 08:49:23.560 | INFO     | yolox.data.datasets.coco:__getitem__:189 - [[0. 0. 0. 0. 0.]]\n2023-04-20 08:49:23 | INFO     | yolox.utils.boxes:42 - tensor([[[-3.0691e-02, -6.9531e-01,  1.7874e+01,  ...,  7.3838e-03,\n           2.3374e-03,  9.7559e-03],\n         [ 1.1258e-01, -1.7617e+00,  3.6079e+01,  ...,  4.4751e-03,\n           2.4137e-03,  1.6975e-02],\n         [ 1.1568e+00, -5.3255e-01,  4.4746e+01,  ...,  4.3620e-03,\n           2.2308e-03,  1.6169e-02],\n         ...,\n         [ 2.0542e+02,  3.2890e+02,  4.0200e+02,  ...,  2.4142e-02,\n           1.8872e-02,  4.6836e-03],\n         [ 2.5580e+02,  3.3263e+02,  4.0311e+02,  ...,  2.3758e-02,\n           1.5198e-02,  1.0437e-02],\n         [ 2.8720e+02,  3.2424e+02,  4.5185e+02,  ...,  2.1452e-02,\n           1.5419e-02,  1.3066e-02]],\n\n        [[-1.8283e+00, -2.5546e+00,  2.2447e+01,  ...,  5.3017e-03,\n           1.2330e-03,  2.6441e-03],\n         [-3.4582e+00, -3.6768e+00,  4.1270e+01,  ...,  2.6849e-03,\n           1.1189e-03,  2.4038e-03],\n         [-5.6546e+00, -3.1051e+00,  4.5746e+01,  ...,  2.2974e-03,\n           5.3034e-04,  1.1495e-03],\n         ...,\n         [ 2.1253e+02,  3.0931e+02,  4.0027e+02,  ...,  1.1962e-02,\n           2.6160e-02,  1.0538e-02],\n         [ 2.2916e+02,  3.0754e+02,  4.5759e+02,  ...,  1.1956e-02,\n           3.1521e-02,  1.2290e-02],\n         [ 2.5522e+02,  2.9314e+02,  4.7906e+02,  ...,  1.3841e-02,\n           2.9837e-02,  8.0685e-03]]])\n 33%|###3      | 1/3 [00:01&lt;00:02,  1.14s/it]2023-04-20 08:49:23 | INFO     | yolox.utils.boxes:42 - tensor([[[-1.9547e-01, -2.6602e-01,  1.9520e+01,  ...,  1.5079e-02,\n           1.5027e-03,  1.1642e-02],\n         [-4.5387e-01, -1.2133e+00,  2.7151e+01,  ...,  1.5102e-02,\n           2.2074e-03,  1.4446e-02],\n         [ 6.5304e-01, -1.3691e+00,  4.4025e+01,  ...,  1.7528e-02,\n           2.2192e-03,  1.3043e-02],\n         ...,\n         [ 2.0673e+02,  3.0448e+02,  4.0279e+02,  ...,  7.8812e-03,\n           1.2321e-02,  6.5607e-03],\n         [ 2.3585e+02,  3.1618e+02,  4.4467e+02,  ...,  8.3829e-03,\n           1.4222e-02,  7.0587e-03],\n         [ 2.6112e+02,  3.0265e+02,  4.7150e+02,  ...,  9.6596e-03,\n           2.5569e-02,  5.9508e-03]],\n\n        [[-4.4389e-01, -8.9837e-01,  1.4791e+01,  ...,  4.5179e-03,\n</code></pre>"}]}